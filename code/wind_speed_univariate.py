# -*- coding: utf-8 -*-
"""wind_speed_univariate.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VDZqQc0gZQE6gprSc-S9g6ispJA-aZ4D
"""

import copy
import numpy as np
import sklearn
import pandas as pd
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers import Bidirectional
from keras.layers import RepeatVector
from keras.layers import TimeDistributed
from numpy import hstack
from sklearn.preprocessing import StandardScaler
import datetime
import time
import joblib
from datetime import timedelta, date
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from numpy import array
import matplotlib.pyplot as plt
import os
import seaborn as sns; sns.set_theme() 
import errno
from keras.layers.convolutional import Conv1D
from keras.layers.convolutional import MaxPooling1D
from keras.layers import Flatten
from keras.layers import ConvLSTM2D

url = "https://raw.githubusercontent.com/rohitash-chandra/CMTL_dynamictimeseries/master/IndianOcean/rawtrain1985-2001.txt"
df = pd.read_csv(url, sep = "\t", header = None)
df.columns = ['id','date','longitude','latitude','speed']
df = df.drop(['date'], axis = 1)
df.to_csv('adjusted.csv')
speed = df['speed'].tolist()

def split_sequence(sequence, n_steps_in, n_steps_out):
    X, y = list(), list()
    for i in range(len(sequence)):
        # find the end of this pattern
        end_ix = i + n_steps_in
        out_end_ix = end_ix + n_steps_out
        # check if we are beyond the sequence
        if out_end_ix > len(sequence):
            break
        # gather input and output parts of the pattern
        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)
 
def rmse(pred, actual):
	return np.sqrt(((pred - actual) ** 2).mean())

def vanilla(hidden,n_steps_in,n_steps_out,n_features):
    model = Sequential()
    model.add(LSTM(Hidden, activation='relu', input_shape=(n_steps_in, n_features), dropout=0.2))
    model.add(Dense(n_steps_out))
    model.compile(optimizer='adam', loss='mse')
    return model

def bidirectional(hidden,n_steps_in,n_steps_out,n_features):
  model = Sequential()
  model.add(Bidirectional(LSTM(Hidden, activation='relu'), input_shape=(n_steps_in, n_features)))
  model.add(Dense(1))
  model.compile(optimizer='adam', loss='mse')
  return model

def cnn_lstm(hidden,n_steps_in,n_steps_out,n_features,n_seq):
  model = Sequential()
  model.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None, n_seq, n_features)))
  model.add(TimeDistributed(MaxPooling1D(pool_size=2)))
  model.add(TimeDistributed(Flatten()))
  model.add(LSTM(Hidden, activation='relu'))
  model.add(Dense(n_steps_out))
  model.compile(optimizer='adam', loss='mse')
  return model

def conv_lstm(hidden,n_steps_in,n_steps_out,n_features,n_seq):
  model = Sequential()
  model.add(ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu', input_shape=(n_seq, 1, n_seq, n_features)))
  model.add(Flatten())
  model.add(Dense(1))
  model.compile(optimizer='adam', loss='mse')
  return model

#all models
def MODEL_LSTM(model_name, univariate, x_train, x_test, y_train, y_test, Num_Exp, n_steps_in, n_steps_out, Epochs, Hidden):

    train_acc = np.zeros(Num_Exp)
    test_acc = np.zeros(Num_Exp)

    if model_name == 'vanilla':
      model = vanilla(Hidden,n_steps_in,n_steps_out,n_features)
    elif model_name == 'bidirectional':
      model = bidirectional(Hidden,n_steps_in,n_steps_out,n_features)
    elif model_name == 'cnn-lstm':
      model = cnn_lstm(Hidden,n_steps_in,n_steps_out,n_features,n_seq)
    elif model_name == 'conv-lstm':
      model = conv_lstm(Hidden,n_steps_in,n_steps_out,n_features, n_seq)
    
    model.summary()

    y_predicttest_allruns = np.zeros([Num_Exp, x_test.shape[0], x_test.shape[1]])

    print(y_predicttest_allruns.shape, ' shape ')


    Best_RMSE = 1000  # Assigning a large number

    start_time = time.time()
    for run in range(Num_Exp):
        print("Experiment", run + 1, "in progress")
        # fit model
        model.fit(x_train, y_train, epochs=Epochs, batch_size=10, verbose=0, shuffle=False)
        y_predicttrain = model.predict(x_train)
        y_predicttest = model.predict(x_test)
        y_predicttest_allruns[run,:,:] = y_predicttest
        train_acc[run] = rmse(y_predicttrain, y_train)
        print(train_acc[run], 'train accuracy')
        test_acc[run] = rmse(y_predicttest, y_test)
        if test_acc[run] < Best_RMSE:
            Best_RMSE = test_acc[run]
            Best_Predict_Test = y_predicttest

    print("Total time for", Num_Exp, "experiments", time.time() - start_time)
    return train_acc, test_acc, Best_Predict_Test, y_predicttrain, y_predicttest, y_predicttest_allruns

models = ['vanilla', 'bidirectional', 'cnn-lstm', 'conv-lstm']
models

univariate = True # if false, its multivariate case
n_steps_in = 4
n_seq = 2
n_steps_out = 1
n_features = 1 # for univariate
Hidden = 10
Epochs = 50
Num_Exp = 5

mean_train = {'vanilla':1 , 'bidirectional': 1, 'cnn-lstm': 1, 'conv-lstm': 1}
mean_test = {'vanilla':1 , 'bidirectional': 1, 'cnn-lstm': 1, 'conv-lstm': 1}
best_predict_test = {'vanilla':[] , 'bidirectional': [], 'cnn-lstm': [], 'conv-lstm': []}
y_predict_train = {'vanilla':[] , 'bidirectional': [], 'cnn-lstm': [], 'conv-lstm': []}
y_predict_test = {'vanilla':[] , 'bidirectional': [], 'cnn-lstm': [], 'conv-lstm': []}

for i in models:
  if i == 'vanilla' or i=='bidirectional':
      train = speed[0:8628]
      test = speed[8629:9364]
      x_train, y_train = split_sequence(train, n_steps_in, n_steps_out)
      x_test, y_test = split_sequence(test, n_steps_in, n_steps_out)
      x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], n_features))
      x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], n_features))
      y_train = y_train.reshape((y_train.shape[0],1))
      y_test = y_test.reshape((y_test.shape[0],1))
  elif i == 'cnn-lstm':
      train = speed[0:8628]
      test = speed[8629:9361]
      x_train, y_train = split_sequence(train, n_steps_in, n_steps_out)
      x_test, y_test = split_sequence(test, n_steps_in, n_steps_out)
      x_train = x_train.reshape((x_train.shape[0], n_seq, n_seq, n_features))
      x_test = x_test.reshape((x_test.shape[0], n_seq, n_seq, n_features))
  elif i=='conv-lstm':
      train = speed[0:8628]
      test = speed[8629:9361]
      x_train, y_train = split_sequence(train, n_steps_in, n_steps_out)
      x_test, y_test = split_sequence(test, n_steps_in, n_steps_out)
      x_train = x_train.reshape((x_train.shape[0], n_seq, 1, n_seq, n_features))
      x_test = x_test.reshape((x_test.shape[0], n_seq, 1, n_seq, n_features))
  
  print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)
  train_acc, test_acc,Best_Predict_Test, y_predicttrain, y_predicttest, y_predicttest_allruns = MODEL_LSTM(i, univariate,x_train,x_test,y_train,y_test,Num_Exp,n_steps_in,n_steps_out,Epochs, Hidden)
  print("for " + i + ":")
  mean_train[i] = np.mean(train_acc, axis=0)
  mean_test[i] = np.mean(test_acc, axis=0)
  best_predict_test[i] = Best_Predict_Test.tolist()
  y_predict_train[i] = y_predicttrain.tolist()
  y_predict_test[i] = y_predicttest.tolist()
  print(mean_train[i], 'mean rmse train') 
  print(mean_test[i], 'mean rmse test')

mean_train

mean_test

res = pd.DataFrame.from_dict(best_predict_test, orient='index')
res=res.transpose()

x_test, y_test = split_sequence(speed[8629:9364], n_steps_in, n_steps_out)
res['actual'] = y_test.tolist()

y_test_for_cnn_conv = split_sequence(speed[8629:9361], n_steps_in, n_steps_out)[1].tolist()
y_test_for_cnn_conv.append("")
y_test_for_cnn_conv.append("")
y_test_for_cnn_conv.append("")
res['actual_for_cnn_conv'] = y_test_for_cnn_conv 
res.to_csv('predictions.csv')

barWidth = 0.2
fig = plt.subplots(figsize =(15, 10))

vanilla = mean_train['vanilla'], mean_test['vanilla']
bidirectional = mean_train['bidirectional'], mean_test['bidirectional']
cnn_lstm = mean_train['cnn-lstm'], mean_test['cnn-lstm']
conv_lstm = mean_train['conv-lstm'], mean_test['conv-lstm']

# Set position of bar on X axis
br1 = np.arange(len(vanilla))
br2 = [x + barWidth for x in br1]
br3 = [x + barWidth for x in br2]
br4 = [x + barWidth for x in br3]

# Make the plot
plt.bar(br1, vanilla, color ='r', width = barWidth,
        edgecolor ='grey', label ='vanilla')
plt.bar(br2, bidirectional, color ='g', width = barWidth,
        edgecolor ='grey', label ='bidirectional')
plt.bar(br3, cnn_lstm, color ='b', width = barWidth,
        edgecolor ='grey', label ='cnn-lstm')
plt.bar(br4, conv_lstm, color ='y', width = barWidth,
        edgecolor ='grey', label ='conv-lstm')
 
# Adding Xticks
plt.xlabel('', fontweight ='bold', fontsize = 15)
plt.ylabel('RMSE', fontweight ='bold', fontsize = 15)
plt.xticks([r + barWidth for r in range(len(vanilla))],
        ['train', 'test'])
plt.grid(axis='both')

plt.legend()
plt.savefig('result.png')
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from numpy import hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime\n",
    "import time\n",
    "import joblib\n",
    "from datetime import timedelta, date\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numpy import array\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns; sns.set_theme()\n",
    "import errno\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, classification_report, confusion_matrix\n",
    "from scipy import interp\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import imblearn\n",
    "import collections\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from matplotlib import pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_data_south_indian(url):\n",
    "    \"\"\"\n",
    "    Load and preprocess data for South Indian region.\n",
    "\n",
    "    Parameters:\n",
    "    - url (str): URL or file path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Processed DataFrame with a 'category' column.\n",
    "    \"\"\"\n",
    "    # Load data from CSV\n",
    "    df = pd.read_csv(url)\n",
    "\n",
    "    # Add a 'category' column based on speed ranges\n",
    "    df['category'] = df['Speed(knots)'].apply(lambda x:\n",
    "        0 if x <= 33 else\n",
    "        1 if 34 <= x <= 47 else\n",
    "        2 if 48 <= x <= 63 else\n",
    "        3 if 64 <= x <= 89 else\n",
    "        4 if 90 <= x <= 115 else\n",
    "        5\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_data_south_pacific(url):\n",
    "    \"\"\"\n",
    "    Load and preprocess data for South Pacific region.\n",
    "\n",
    "    Parameters:\n",
    "    - url (str): URL or file path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Processed DataFrame with a 'category' column.\n",
    "    \"\"\"\n",
    "    # Load data from CSV\n",
    "    df = pd.read_csv(url)\n",
    "\n",
    "    # Add a 'category' column based on speed ranges\n",
    "    df['category'] = df['Speed(knots)'].apply(lambda x:\n",
    "        0 if x <= 33 else\n",
    "        1 if 34 <= x <= 47 else\n",
    "        2 if 48 <= x <= 63 else\n",
    "        3 if 64 <= x <= 85 else\n",
    "        4 if 86 <= x <= 107 else\n",
    "        5\n",
    "    )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean = 'south_indian'\n",
    "\n",
    "# Display the selected ocean\n",
    "print(f\"Selected ocean: {ocean}\")\n",
    "\n",
    "# Set the data URL and function based on the selected ocean\n",
    "if ocean == 'south_indian':\n",
    "    url_data = 'https://raw.githubusercontent.com/sydney-machine-learning/cyclonedatasets/main/SouthIndian-SouthPacific-Ocean/South_indian_hurricane.csv'\n",
    "    data_loading_function = load_data_south_indian\n",
    "    hot_encoded_result_file_name = 'south_indian'\n",
    "    category_result_file_name = 'roc_data_south_indian'\n",
    "else:\n",
    "    url_data = 'https://raw.githubusercontent.com/sydney-machine-learning/cyclonedatasets/main/SouthIndian-SouthPacific-Ocean/South_pacific_hurricane.csv'\n",
    "    data_loading_function = load_data_south_pacific\n",
    "    hot_encoded_result_file_name = 'south_pacific'\n",
    "    category_result_file_name = 'roc_data_south_pacific'\n",
    "\n",
    "# Display the data URL for verification\n",
    "print(f\"Data URL: {url_data}\")\n",
    "\n",
    "# Display the result file names\n",
    "print(f\"Hot-encoded result file name: {hot_encoded_result_file_name}\")\n",
    "print(f\"Category result file name: {category_result_file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data using the specified function and URL\n",
    "df = data_loading_function(url_data)\n",
    "\n",
    "df['Lat'] = df['Lat'].apply(lambda x: -int(x[:-1]) * 0.1 if x.endswith('N') else int(x[:-1]) * 0.1 if x.endswith('S') else 0)\n",
    "df['Lon'] = df['Lon'].apply(lambda x: -int(x[:-1]) * 0.1 if x.endswith('W') else int(x[:-1]) * 0.1 if x.endswith('E') else 0)\n",
    "\n",
    "# Extract 'Speed(knots)' and 'category' columns as lists\n",
    "speed = df['Speed(knots)'].tolist()\n",
    "categories = df['category'].tolist()\n",
    "latitude = df['Lat'].tolist()\n",
    "longitude = df['Lon'].tolist()\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df_head = df.head()\n",
    "print(\"DataFrame Head:\")\n",
    "print(df_head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def split_sequence(sequences, n_steps_in, n_steps_out):\n",
    "    \"\"\"\n",
    "    Split multivariate sequences into input and output parts.\n",
    "\n",
    "    Parameters:\n",
    "    - sequences (numpy.ndarray): Multivariate time series data.\n",
    "    - n_steps_in (int): Number of input time steps.\n",
    "    - n_steps_out (int): Number of output time steps.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Input sequences (X) and output sequences (y) as numpy arrays.\n",
    "    \"\"\"\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def uni_split_sequence(sequence, n_steps):\n",
    "    \"\"\"\n",
    "    Split univariate sequence into input and output parts.\n",
    "\n",
    "    Parameters:\n",
    "    - sequence (list): Univariate time series data.\n",
    "    - n_steps (int): Number of input time steps.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Input sequences (X) and output sequences (y) as numpy arrays.\n",
    "    \"\"\"\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(sequence) - 1:\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def rmse(pred, actual):\n",
    "    \"\"\"\n",
    "    Calculate the Root Mean Squared Error (RMSE) between two arrays.\n",
    "\n",
    "    Parameters:\n",
    "    - pred (numpy.ndarray): Predicted values.\n",
    "    - actual (numpy.ndarray): Actual values.\n",
    "\n",
    "    Returns:\n",
    "    - float: Root Mean Squared Error.\n",
    "    \"\"\"\n",
    "    return np.sqrt(((pred - actual) ** 2).mean())\n",
    "\n",
    "def categorical(pred, actual):\n",
    "    \"\"\"\n",
    "    Compute classification metrics for categorical values.\n",
    "\n",
    "    Parameters:\n",
    "    - pred (numpy.ndarray): Predicted categorical values.\n",
    "    - actual (numpy.ndarray): Actual categorical values.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Accuracy, AUC, Confusion Matrix, Precision, Recall, F1 Score.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(pred, actual)\n",
    "    acc = accuracy_score(actual, pred, normalize=True, sample_weight=None)\n",
    "    ps1 = precision_score(pred, actual, average='micro')\n",
    "    rs1 = recall_score(pred, actual, average='micro')\n",
    "    f11 = f1_score(pred, actual, average='micro')\n",
    "    auc = roc_auc_score(actual, pred)\n",
    "    return acc, auc, cm, ps1, rs1, f11\n",
    "\n",
    "def make_confusion_matrix_chart(cf_matrix_test, cmap='Blues', annot_kws=None):\n",
    "    \"\"\"\n",
    "    Generate and display a heatmap-style confusion matrix chart.\n",
    "\n",
    "    Parameters:\n",
    "    - cf_matrix_test (numpy.ndarray): Confusion matrix.\n",
    "    - cmap (str): Colormap for the heatmap.\n",
    "    - annot_kws (dict): Additional keyword arguments for annotation customization.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Set up the figure and axes\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Customize the heatmap using seaborn\n",
    "    sns.heatmap(cf_matrix_test, annot=True, cmap=cmap,\n",
    "                yticklabels=['0', '1'], xticklabels=['0', '1'],\n",
    "                fmt='g', annot_kws=annot_kws)\n",
    "\n",
    "    # Customize axis labels and title\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.title('Confusion Matrix - Test Data')\n",
    "\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define whether it's a univariate or multivariate case\n",
    "univariate = True  # If False, it's a multivariate case\n",
    "\n",
    "# Define sequence and time step parameters\n",
    "n_steps_in = 8\n",
    "n_seq = 2\n",
    "n_steps_out = 1\n",
    "\n",
    "# Define the number of features for input and output\n",
    "n_features_in = 1  # Speed\n",
    "n_features_out = 2  # One-hot encoding of category\n",
    "\n",
    "# Define the number of hidden layers in the model\n",
    "hidden_layers = 50\n",
    "\n",
    "# Define training parameters\n",
    "epochs = 100\n",
    "No_exp = 30 # Number of experiments\n",
    "\n",
    "# Display the configuration\n",
    "print(\"Configuration:\")\n",
    "print(f\"Univariate: {univariate}\")\n",
    "print(f\"Number of Input Time Steps: {n_steps_in}\")\n",
    "print(f\"Number of Input Sequences: {n_seq}\")\n",
    "print(f\"Number of Output Time Steps: {n_steps_out}\")\n",
    "print(f\"Number of Input Features: {n_features_in}\")\n",
    "print(f\"Number of Output Features: {n_features_out}\")\n",
    "print(f\"Number of Hidden Layers: {hidden_layers}\")\n",
    "print(f\"Epochs: {epochs}\")\n",
    "print(f\"Number of Experiments: {No_exp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize variables\n",
    "cyclone_id = df['No. of Cycl'][0]\n",
    "X = []\n",
    "Y = []\n",
    "start_index = 0\n",
    "end_index = 0\n",
    "\n",
    "# Iterate through the DataFrame\n",
    "for i in range(1, df.shape[0]):\n",
    "    # Check if the cyclone ID is the same as the previous row\n",
    "    if df['No. of Cycl'][i] == cyclone_id:\n",
    "        end_index += 1\n",
    "    else:\n",
    "        # Split the sequence and append to X and Y\n",
    "        x, y = uni_split_sequence(speed[start_index:end_index + 1], n_steps_in)\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "\n",
    "        # Update start and end indices for the new cyclone\n",
    "        cyclone_id = df['No. of Cycl'][i]\n",
    "        start_index = i\n",
    "        end_index = i\n",
    "\n",
    "    # Check if it's the last row of the DataFrame\n",
    "    if i == df.shape[0] - 1:\n",
    "        # Split the sequence and append to X and Y\n",
    "        x, y = uni_split_sequence(speed[start_index:end_index + 1], n_steps_in)\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "print(X[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "cyclone_id = df['No. of Cycl'][0]\n",
    "X_lat = []\n",
    "Y_lat = []\n",
    "start_index_lat = 0\n",
    "end_index_lat = 0\n",
    "\n",
    "# Iterate through the DataFrame\n",
    "for i in range(1, df.shape[0]):\n",
    "    # Check if the cyclone ID is the same as the previous row\n",
    "    if df['No. of Cycl'][i] == cyclone_id:\n",
    "        end_index_lat += 1\n",
    "    else:\n",
    "        # Split the sequence and append to X_lat and Y_lat\n",
    "        x_lat, y_lat = uni_split_sequence(latitude[start_index_lat:end_index_lat + 1], n_steps_in)\n",
    "        X_lat.append(x_lat)\n",
    "        Y_lat.append(y_lat)\n",
    "\n",
    "        # Update start and end indices for the new cyclone\n",
    "        cyclone_id = df['No. of Cycl'][i]\n",
    "        start_index_lat = i\n",
    "        end_index_lat = i\n",
    "\n",
    "    # Check if it's the last row of the DataFrame\n",
    "    if i == df.shape[0] - 1:\n",
    "        # Split the sequence and append to X_lat and Y_lat\n",
    "        x_lat, y_lat = uni_split_sequence(latitude[start_index_lat:end_index_lat + 1], n_steps_in)\n",
    "        X_lat.append(x_lat)\n",
    "        Y_lat.append(y_lat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "cyclone_id = df['No. of Cycl'][0]\n",
    "X_lon = []\n",
    "Y_lon = []\n",
    "start_index_lon = 0\n",
    "end_index_lon = 0\n",
    "\n",
    "# Iterate through the DataFrame\n",
    "for i in range(1, df.shape[0]):\n",
    "    # Check if the cyclone ID is the same as the previous row\n",
    "    if df['No. of Cycl'][i] == cyclone_id:\n",
    "        end_index_lon += 1\n",
    "    else:\n",
    "        # Split the sequence and append to X_lon and Y_lon\n",
    "        x_lon, y_lon = uni_split_sequence(longitude[start_index_lon:end_index_lon + 1], n_steps_in)\n",
    "        X_lon.append(x_lon)\n",
    "        Y_lon.append(y_lon)\n",
    "\n",
    "        # Update start and end indices for the new cyclone\n",
    "        cyclone_id = df['No. of Cycl'][i]\n",
    "        start_index_lon = i\n",
    "        end_index_lon = i\n",
    "\n",
    "    # Check if it's the last row of the DataFrame\n",
    "    if i == df.shape[0] - 1:\n",
    "        # Split the sequence and append to X_lon and Y_lon\n",
    "        x_lon, y_lon = uni_split_sequence(longitude[start_index_lon:end_index_lon + 1], n_steps_in)\n",
    "        X_lon.append(x_lon)\n",
    "        Y_lon.append(y_lon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the initial lengths of X and Y\n",
    "print(len(X), len(Y))\n",
    "# Flattening X and Y\n",
    "X = [item for sublist in X for item in sublist]\n",
    "Y = [item for sublist in Y for item in sublist]\n",
    "#Print lengths of X and Y after flattening\n",
    "print(len(X), len(Y))\n",
    "print(X[0], Y[0], X[1], Y[1])\n",
    "print(speed[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the initial lengths of X_lat and Y_lat\n",
    "print(len(X_lat), len(Y_lat))\n",
    "\n",
    "# Flattening X_lat and Y_lat\n",
    "X_lat = [item for sublist in X_lat for item in sublist]\n",
    "Y_lat = [item for sublist in Y_lat for item in sublist]\n",
    "\n",
    "# Print lengths of X_lat and Y_lat after flattening\n",
    "print(len(X_lat), len(Y_lat))\n",
    "print(X_lat[0], Y_lat[0], X_lat[1], Y_lat[1])\n",
    "print(latitude[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating a list for RI cyclone classifcation\n",
    "intensify_y = []\n",
    "\n",
    "for i in range(len(X)):\n",
    "  # Classification based on difference in speeds\n",
    "  if Y[i]-X[i][0]>=30:\n",
    "    intensify_y.append(1)\n",
    "  else:\n",
    "    intensify_y.append(0)\n",
    "\n",
    "print(len(intensify_y))\n",
    "\n",
    "speed_y = Y\n",
    "Y=intensify_y\n",
    "Y_lon = intensify_y\n",
    "Y_lat = intensify_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating a list for RI cyclone classification\n",
    "intensify_y = []\n",
    "for i in range(len(X)):\n",
    "  intensify_y.append(0)\n",
    "\n",
    "\n",
    "    # Iterate through each column in X[i]\n",
    "for i in range(len(X)):\n",
    "   for j in range(len(X[0])):\n",
    "        # Iterate through k from 1 to 4\n",
    "        for k in range(1, 5):\n",
    "            # Check if the difference is greater than 30\n",
    "            if (j - k) >= 0 and (X[i][j] - X[i][j-k]) >= 30:\n",
    "                # Set Y[i] to 1 and break the loop\n",
    "                intensify_y[i] = 1\n",
    "                break\n",
    "\n",
    "\n",
    "print(len(intensify_y))\n",
    "\n",
    "# Use 'intensify_y' as the updated target variable\n",
    "Y = intensify_y\n",
    "Y_lat = Y\n",
    "Y_lon = Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the training limit as 75% of the total length of X\n",
    "train_limit = int(len(X) * 0.75)\n",
    "\n",
    "# Display the calculated training limit\n",
    "print(\"Training Limit:\", train_limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the training limit based on latitude\n",
    "train_limit_lat = int(len(X_lat) * 0.75)\n",
    "\n",
    "# Display the calculated training limit for latitude\n",
    "print(\"Training Limit (Latitude):\", train_limit_lat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the training limit based on longitude\n",
    "train_limit_lon = int(len(X_lon) * 0.75)\n",
    "\n",
    "# Display the calculated training limit for longitude\n",
    "print(\"Training Limit (Longitude):\", train_limit_lon)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract test data for evaluation\n",
    "test_X_original = X[train_limit + 1:]\n",
    "test_Y_original = Y[train_limit + 1:]\n",
    "\n",
    "# Display the lengths of the datasets\n",
    "print(\"Length of X:\", len(X))\n",
    "print(\"Length of Y:\", len(Y))\n",
    "print(\"Length of Test X (for evaluation):\", len(test_X_original))\n",
    "print(\"Length of Test Y (for evaluation):\", len(test_Y_original))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract test data for evaluation based on latitude\n",
    "test_X_original_lat = X_lat[train_limit_lat + 1:]\n",
    "test_Y_original_lat = Y_lat[train_limit_lat + 1:]\n",
    "\n",
    "# Display the lengths of the datasets for latitude\n",
    "print(\"Length of X (Latitude):\", len(X_lat))\n",
    "print(\"Length of Y (Latitude):\", len(Y_lat))\n",
    "print(\"Length of Test X (for evaluation, Latitude):\", len(test_X_original_lat))\n",
    "print(\"Length of Test Y (for evaluation, Latitude):\", len(test_Y_original_lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract test data for evaluation based on longitude\n",
    "test_X_original_lon = X_lon[train_limit_lon + 1:]\n",
    "test_Y_original_lon = Y_lon[train_limit_lon + 1:]\n",
    "\n",
    "# Display the lengths of the datasets for longitude\n",
    "print(\"Length of X (Longitude):\", len(X_lon))\n",
    "print(\"Length of Y (Longitude):\", len(Y_lon))\n",
    "print(\"Length of Test X (for evaluation, Longitude):\", len(test_X_original_lon))\n",
    "print(\"Length of Test Y (for evaluation, Longitude):\", len(test_Y_original_lon))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the sequences in X using Min-Max scaling\n",
    "X = MinMaxScaler().fit_transform(np.asarray(X))\n",
    "# Apply MinMaxScaler to latitude\n",
    "X_lat = MinMaxScaler().fit_transform(np.asarray(X_lat))\n",
    "# Apply MinMaxScaler to longitude\n",
    "X_lon = MinMaxScaler().fit_transform(np.asarray(X_lon))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the original X (speed) values before splitting\n",
    "speed_x = X\n",
    "test_X = X[train_limit+1:]\n",
    "test_X = np.asarray(test_X).astype(float)\n",
    "test_Y = Y[train_limit+1:]\n",
    "X = X[:train_limit]\n",
    "X = np.asarray(X).astype(float)\n",
    "Y = Y[:train_limit]\n",
    "print(test_Y)\n",
    "len(X), len(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign latitude data to latitude_x\n",
    "latitude_x = X_lat\n",
    "\n",
    "# Extract test data for latitude\n",
    "test_X_lat = X_lat[train_limit_lat + 1:]\n",
    "test_X_lat = np.asarray(test_X_lat).astype(float)\n",
    "test_Y_lat = Y_lat[train_limit_lat + 1:]\n",
    "X_lat = X_lat[:train_limit_lat]\n",
    "X_lat = np.asarray(X_lat).astype(float)\n",
    "Y_lat = Y_lat[:train_limit_lat]\n",
    "test_Y_lat\n",
    "len(X_lat), len(Y_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign latitude data to latitude_x\n",
    "longitude_x = X_lon\n",
    "\n",
    "# Extract test data for latitude\n",
    "test_X_lon = X_lon[train_limit_lon + 1:]\n",
    "test_X_lon = np.asarray(test_X_lon).astype(float)\n",
    "test_Y_lon = Y_lon[train_limit_lon + 1:]\n",
    "X_lon = X_lon[:train_limit_lat]\n",
    "X_lon = np.asarray(X_lon).astype(float)\n",
    "Y_lon = Y_lon[:train_limit_lon]\n",
    "test_Y_lon\n",
    "len(X_lon), len(Y_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the class distribution for training and test data\n",
    "counter_train = Counter(Y)\n",
    "counter_test = Counter(test_Y)\n",
    "\n",
    "# Display the class distribution for training data\n",
    "print(\"Class Distribution - Training Data:\")\n",
    "print(counter_train)\n",
    "\n",
    "# Display the class distribution for test data\n",
    "print(\"\\nClass Distribution - Test Data:\")\n",
    "print(counter_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the class distribution for training and test data for latitude\n",
    "counter_train_lat = Counter(Y_lat)\n",
    "counter_test_lat = Counter(test_Y_lat)\n",
    "\n",
    "# Display the class distribution for training data for latitude\n",
    "print(\"Class Distribution - Training Data (Latitude):\")\n",
    "print(counter_train_lat)\n",
    "\n",
    "# Display the class distribution for test data for latitude\n",
    "print(\"\\nClass Distribution - Test Data (Latitude):\")\n",
    "print(counter_test_lat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the class distribution for training and test data for longitude\n",
    "counter_train_lon = Counter(Y_lon)\n",
    "counter_test_lon = Counter(test_Y_lon)\n",
    "\n",
    "# Display the class distribution for training data for longitude\n",
    "print(\"Class Distribution - Training Data (Longitude):\")\n",
    "print(counter_train_lon)\n",
    "\n",
    "# Display the class distribution for test data for longitude\n",
    "print(\"\\nClass Distribution - Test Data (Longitude):\")\n",
    "print(counter_test_lon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming counter_train is already defined\n",
    "\n",
    "# Set\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "# Bar plot with red bars\n",
    "bars = plt.bar(range(len(counter_train)), list(counter_train.values()), color='lightcoral', edgecolor='black', align='center')\n",
    "\n",
    "# Customizing individual bars\n",
    "for bar in bars:\n",
    "    yvar = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yvar + 50, round(yvar, 2), ha='center', va='bottom', fontsize=12, color='#2E4053')\n",
    "\n",
    "# X-axis and Y-axis labels\n",
    "plt.xlabel('Category', size=16, labelpad=15)\n",
    "plt.ylabel('Number of cyclones', size=16, labelpad=15)\n",
    "\n",
    "# Title\n",
    "plt.title('Majority and Minority class distribution in Training Data', size=20, pad=20)\n",
    "\n",
    "# Tick parameters with only '0' and '1' on the x-axis\n",
    "plt.xticks(range(2), ['0', '1'], fontsize=12)\n",
    "\n",
    "# Tick parameters for y-axis\n",
    "ax.tick_params(axis='y', which='major', labelsize=12)\n",
    "\n",
    "# Adding grid lines\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Save figure\n",
    "plt.savefig('class_distribution_red.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, concatenate\n",
    "\n",
    "\n",
    "def stacked_lstm(n_steps_in, n_features_in):\n",
    "    input_1 = Input(shape=(n_steps_in, n_features_in))\n",
    "    lstm_1 = LSTM(50, activation='relu')(input_1)\n",
    "\n",
    "    input_2 = Input(shape=(n_steps_in, n_features_in))\n",
    "    lstm_2 = LSTM(50, activation='relu')(input_2)\n",
    "\n",
    "    input_3 = Input(shape=(n_steps_in, n_features_in))\n",
    "    lstm_3 = LSTM(50, activation='relu')(input_3)\n",
    "\n",
    "    concat = concatenate([lstm_1, lstm_2, lstm_3])\n",
    "    output = Dense(2, activation='softmax')(concat)\n",
    "\n",
    "    model = Model(inputs=[input_1, input_2, input_3], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features_in_speed = 1\n",
    "n_features_in_latitude = 1\n",
    "n_features_in_longitude = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "\n",
    "def lstm(stacked_model,  x_train_lat, x_train_lon, x_train, y_train, x_test_lat, x_test_lon, x_test, y_test, Num_Exp, n_steps_in, n_steps_out, Epochs):\n",
    "    # Initialize arrays to store accuracy metrics\n",
    "    train_acc = np.zeros(Num_Exp)\n",
    "    test_acc = np.zeros(Num_Exp)\n",
    "\n",
    "    # Initialize arrays to store predictions and classification reports\n",
    "    y_predicttest_allruns = np.zeros([Num_Exp, x_test_lat.shape[0], y_test.shape[1]])\n",
    "    Best_f1 = 0  # Initialize the best F1 score\n",
    "    Best_Predict_Test = 0\n",
    "\n",
    "    # Extract the actual classes from one-hot encoded vectors for both test and train sets\n",
    "    act_test = [y_test[i].argmax() for i in range(y_test.shape[0])]\n",
    "    act_train = [y_train[i].argmax() for i in range(y_train.shape[0])]\n",
    "\n",
    "    # Initialize dictionaries to store classification reports\n",
    "    Best_report_train = dict()\n",
    "    Best_report_test = dict()\n",
    "    all_report_train = dict()\n",
    "    all_report_test = dict()\n",
    "\n",
    "    # Loop through experiment runs\n",
    "    start_time = time.time()\n",
    "    for run in range(Num_Exp):\n",
    "        print(\"Experiment\", run + 1, \"in progress\")\n",
    "\n",
    "        # Fit the stacked model\n",
    "        stacked_model.fit([x_train_lat, x_train_lon, x_train], y_train, epochs=Epochs, batch_size=10, verbose=1, shuffle=False)\n",
    "        y_predicttrain = stacked_model.predict([x_train_lat, x_train_lon, x_train])\n",
    "        y_predicttest = stacked_model.predict([x_test_lat, x_test_lon, x_test])\n",
    "        print(y_predicttrain[0])\n",
    "        print(y_predicttest[0])\n",
    "\n",
    "        # Extract predicted classes from one-hot encoded vectors\n",
    "        pred_test = [y_predicttest[i].argmax() for i in range(y_predicttest.shape[0])]\n",
    "        pred_train = [y_predicttrain[i].argmax() for i in range(y_predicttrain.shape[0])]\n",
    "\n",
    "        c = 0\n",
    "        for i in pred_test:\n",
    "          if(i==1):\n",
    "            c = c+1\n",
    "        print(c)\n",
    "        d = 0\n",
    "        for i in pred_train:\n",
    "          if(i==1):\n",
    "            d = d+1\n",
    "        print(d)\n",
    "\n",
    "\n",
    "        # Generate classification reports\n",
    "        report_train = classification_report(act_train, pred_train, labels=[0, 1], output_dict=True)\n",
    "        report_test = classification_report(act_test, pred_test, labels=[0, 1], output_dict=True)\n",
    "\n",
    "        # Store classification reports in dictionaries\n",
    "        all_report_train[run] = report_train\n",
    "        all_report_test[run] = report_test\n",
    "\n",
    "        # Calculate F1-score for the test set\n",
    "        train_acc[run] = report_train['1']['f1-score']\n",
    "        test_acc[run] = report_test['1']['f1-score']\n",
    "        print(\"train acc: \", train_acc[run])\n",
    "        print(\"test acc: \", test_acc[run])\n",
    "\n",
    "    # Update the best F1 score and associated predictions and reports\n",
    "    if test_acc[run] > Best_f1:\n",
    "        Best_f1 = test_acc[run]\n",
    "        Best_Predict_Test = y_predicttest\n",
    "        Best_report_train, Best_report_test = report_train, report_test\n",
    "\n",
    "    # Save the trained model (assuming you have the 'ocean' variable)\n",
    "    stacked_model.save(\"model_\" + ocean + \"_stacked_lstm.h5\")\n",
    "\n",
    "    # Calculate standard deviations of train and test accuracies\n",
    "    train_std = np.std(train_acc)\n",
    "    test_std = np.std(test_acc)\n",
    "\n",
    "    # Display experiment summary\n",
    "    print(\"Total time for\", Num_Exp, \"experiments\", time.time() - start_time)\n",
    "    print(\"F1 scores for test data: \", test_acc)\n",
    "    print(\"Mean: \", np.mean(test_acc), \"Std Dev: \", test_std)\n",
    "\n",
    "    # Return relevant information\n",
    "    return train_acc, test_acc, train_std, test_std, Best_Predict_Test, y_predicttrain, y_predicttest, all_report_train, all_report_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random permutation of indices for shuffling\n",
    "# idx = np.random.permutation(len(X_smote))\n",
    "idx = np.random.permutation(len(X))\n",
    "print(len(idx))\n",
    "\n",
    "# Initialize lists to store shuffled data\n",
    "x_shuffled = []\n",
    "y_shuffled = []\n",
    "\n",
    "# Iterate through the shuffled indices\n",
    "for i in idx:\n",
    "    # Append shuffled data to the lists\n",
    "    # x_shuffled.append(X_smote[i])\n",
    "    # y_shuffled.append(Y_smote[i])\n",
    "    x_shuffled.append(X[i])\n",
    "    y_shuffled.append(Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random permutation of indices for shuffling\n",
    "# idx = np.random.permutation(len(X_smote))\n",
    "idx = np.random.permutation(len(X_lat))\n",
    "print(len(idx))\n",
    "\n",
    "# Initialize lists to store shuffled data\n",
    "x_shuffled_lat = []\n",
    "y_shuffled_lat = []\n",
    "\n",
    "# Iterate through the shuffled indices\n",
    "for i in idx:\n",
    "    # Append shuffled data to the lists\n",
    "    # x_shuffled.append(X_smote[i])\n",
    "    # y_shuffled.append(Y_smote[i])\n",
    "    x_shuffled_lat.append(X_lat[i])\n",
    "    y_shuffled_lat.append(Y_lat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random permutation of indices for shuffling\n",
    "# idx = np.random.permutation(len(X_smote))\n",
    "idx = np.random.permutation(len(X_lon))\n",
    "print(len(idx))\n",
    "\n",
    "# Initialize lists to store shuffled data\n",
    "x_shuffled_lon = []\n",
    "y_shuffled_lon = []\n",
    "\n",
    "# Iterate through the shuffled indices\n",
    "for i in idx:\n",
    "    # Append shuffled data to the lists\n",
    "    # x_shuffled.append(X_smote[i])\n",
    "    # y_shuffled.append(Y_smote[i])\n",
    "    x_shuffled_lon.append(X_lon[i])\n",
    "    y_shuffled_lon.append(Y_lon[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the shuffled labels to one-hot encoded format for training data\n",
    "Y_hot_encoded_train = np.asarray(to_categorical(y_shuffled))\n",
    "\n",
    "# Convert the test labels to one-hot encoded format\n",
    "Y_hot_encoded_test = np.asarray(to_categorical(test_Y))\n",
    "\n",
    "# Print the shapes of the one-hot encoded training and test labels\n",
    "print(Y_hot_encoded_train.shape, Y_hot_encoded_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hot_encoded_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hot_encoded_train_lat = np.asarray(to_categorical(y_shuffled_lat))\n",
    "\n",
    "# Convert the test labels to one-hot encoded format\n",
    "Y_hot_encoded_test_lat = np.asarray(to_categorical(test_Y_lat))\n",
    "\n",
    "# Print the shapes of the one-hot encoded training and test labels\n",
    "print(Y_hot_encoded_train_lat.shape, Y_hot_encoded_test_lat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hot_encoded_train_lon = np.asarray(to_categorical(y_shuffled_lon))\n",
    "\n",
    "# Convert the test labels to one-hot encoded format\n",
    "Y_hot_encoded_test_lon = np.asarray(to_categorical(test_Y_lon))\n",
    "\n",
    "# Print the shapes of the one-hot encoded training and test labels\n",
    "print(Y_hot_encoded_train_lon.shape, Y_hot_encoded_test_lon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = dict()\n",
    "actual_train = dict()\n",
    "predictions_test = dict()\n",
    "actual_test = dict()\n",
    "metrics_train = dict()\n",
    "metrics_test = dict()\n",
    "test_acc_all = dict()\n",
    "test_stddev = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over different values of n_steps_out (in this case, only 1)\n",
    "for j in range(1):\n",
    "    # Initialize dictionaries to store results for the ensemble model\n",
    "    predictions_train_per_step = dict()\n",
    "    actual_train_per_step = dict()\n",
    "    predictions_test_per_step = dict()\n",
    "    actual_test_per_step = dict()\n",
    "    metrics_train_per_step = dict()\n",
    "    metrics_test_per_step = dict()\n",
    "    test_acc_per_step = dict()\n",
    "    test_stddev_per_step = dict()\n",
    "    n_steps_out = j + 1\n",
    "\n",
    "    print('---------------------------------------------------------')\n",
    "    print('Number of steps out:', n_steps_out)\n",
    "\n",
    "    # Reshape data based on the ensemble model type\n",
    "    x_train, y_train = np.asarray(x_shuffled), np.asarray(Y_hot_encoded_train)\n",
    "    x_test, y_test = np.asarray(test_X), np.asarray(Y_hot_encoded_test)\n",
    "\n",
    "    x_train_lat, y_train_lat = np.asarray(x_shuffled_lat), np.asarray(Y_hot_encoded_train_lat)\n",
    "    x_test_lat, y_test_lat = np.asarray(test_X_lat), np.asarray(Y_hot_encoded_test_lat)\n",
    "\n",
    "    x_train_lon, y_train_lon = np.asarray(x_shuffled_lon), np.asarray(Y_hot_encoded_train_lon)\n",
    "    x_test_lon, y_test_lon = np.asarray(test_X_lon), np.asarray(Y_hot_encoded_test_lon)\n",
    "\n",
    "    # Call ensemble_lstm to create the ensemble model\n",
    "\n",
    "    stacked_model = stacked_lstm(n_steps_in, n_features_in)\n",
    "    # Call the lstm function with the ensemble model and retrieve results\n",
    "    train_acc, test_acc, train_std_dev, test_std_dev, Best_Predict_Test, y_predicttrain, y_predicttest, report_train, report_test = lstm(stacked_model,  x_train_lat, x_train_lon, x_train, y_train, x_test_lat, x_test_lon, x_test, y_test, No_exp, n_steps_in, n_steps_out, epochs)\n",
    "\n",
    "    # Store results in respective dictionaries\n",
    "    predictions_train_per_step['ensemble'] = Best_Predict_Test\n",
    "    actual_train_per_step['ensemble'] = y_train\n",
    "    predictions_test_per_step['ensemble'] = Best_Predict_Test\n",
    "    actual_test_per_step['ensemble'] = y_test\n",
    "    metrics_train_per_step['ensemble'] = report_train\n",
    "    metrics_test_per_step['ensemble'] = report_test\n",
    "    test_acc_per_step['ensemble'] = test_acc\n",
    "    test_stddev_per_step['ensemble'] = test_std_dev\n",
    "\n",
    "    # Store results for the current n_steps_out in the overall dictionaries\n",
    "    predictions_train[str(j + 1)] = predictions_train_per_step\n",
    "    actual_train[str(j + 1)] = actual_train_per_step\n",
    "    predictions_test[str(j + 1)] = predictions_test_per_step\n",
    "    actual_test[str(j + 1)] = actual_test_per_step\n",
    "    metrics_train[str(j + 1)] = metrics_train_per_step\n",
    "    metrics_test[str(j + 1)] = metrics_test_per_step\n",
    "    test_acc_all[str(j + 1)] = test_acc_per_step\n",
    "    test_stddev[str(j + 1)] = test_stddev_per_step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"predictions_\" + ocean + '_original' + '.pkl', 'wb') as f:\n",
    "    pickle.dump([predictions_train,actual_train,predictions_test,actual_test,metrics_train,metrics_test,test_acc,test_stddev], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def make_confusion_matrix_chart(cf_matrix, name):\n",
    "    \"\"\"\n",
    "    Create and save a well-formatted confusion matrix heatmap.\n",
    "\n",
    "    Parameters:\n",
    "    - cf_matrix: Confusion matrix\n",
    "    - name: Name of the file to save the plot\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "\n",
    "    # Set a Seaborn style with dark grid\n",
    "    sns.set(style=\"darkgrid\", font_scale=1.5)\n",
    "\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    # Customize the appearance of the heatmap with green colors\n",
    "    sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Greens',\n",
    "                linewidths=.5, square=True, cbar=False,\n",
    "                annot_kws={\"size\": 16}, ax=ax)\n",
    "\n",
    "    # Set labels and title\n",
    "    plt.ylabel(\"Actual\", size=18)\n",
    "    plt.xlabel(\"Predicted\", size=18)\n",
    "    plt.title(\"Confusion Matrix\", size=20)\n",
    "\n",
    "    # Set tick parameters\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "    # Save the plot as an image\n",
    "    plt.savefig(name + '.png', dpi=300, transparent=False, bbox_inches='tight')\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Return None\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [i.argmax() for i in actual_test_per_step['ensemble']]\n",
    "pred = [i.argmax() for i in predictions_test_per_step['ensemble']]\n",
    "cf_matrix_test = confusion_matrix(y, pred)\n",
    "make_confusion_matrix_chart(cf_matrix_test, ocean + '_ensemble_cm_original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store precision, recall, and F1-score metrics for class 0, class 1, overall accuracy,\n",
    "# macro average, and weighted average across multiple experiments\n",
    "precision0 = []\n",
    "precision1 = []\n",
    "precisionacc = []\n",
    "precisionmacavg = []\n",
    "precisionweighavg = []\n",
    "recall0 = []\n",
    "recall1 = []\n",
    "recallacc = []\n",
    "recallmacavg = []\n",
    "recallweighavg = []\n",
    "f10 = []\n",
    "f11 = []\n",
    "f1acc = []\n",
    "f1macavg = []\n",
    "f1weighavg = []\n",
    "\n",
    "# Loop through the results of multiple experiments\n",
    "for i in range(No_exp):\n",
    "    # Append precision, recall, and F1-score metrics for class 0, class 1, overall accuracy,\n",
    "    # macro average, and weighted average from the 'vanilla' model results\n",
    "    precision0.append(metrics_test_per_step['ensemble'][i]['0']['precision'])\n",
    "    precision1.append(metrics_test_per_step['ensemble'][i]['1']['precision'])\n",
    "    precisionacc.append(metrics_test_per_step['ensemble'][i]['accuracy'])\n",
    "    precisionmacavg.append(metrics_test_per_step['ensemble'][i]['macro avg']['precision'])\n",
    "    precisionweighavg.append(metrics_test_per_step['ensemble'][i]['weighted avg']['precision'])\n",
    "\n",
    "    recall0.append(metrics_test_per_step['ensemble'][i]['0']['recall'])\n",
    "    recall1.append(metrics_test_per_step['ensemble'][i]['1']['recall'])\n",
    "    recallacc.append(metrics_test_per_step['ensemble'][i]['accuracy'])\n",
    "    recallmacavg.append(metrics_test_per_step['ensemble'][i]['macro avg']['recall'])\n",
    "    recallweighavg.append(metrics_test_per_step['ensemble'][i]['weighted avg']['recall'])\n",
    "\n",
    "    f10.append(metrics_test_per_step['ensemble'][i]['0']['f1-score'])\n",
    "    f11.append(metrics_test_per_step['ensemble'][i]['1']['f1-score'])\n",
    "    f1acc.append(metrics_test_per_step['ensemble'][i]['accuracy'])\n",
    "    f1macavg.append(metrics_test_per_step['ensemble'][i]['macro avg']['f1-score'])\n",
    "    f1weighavg.append(metrics_test_per_step['ensemble'][i]['weighted avg']['f1-score'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(round(np.mean(precision0),4)) + \"±\" + str(round(np.std(precision0),4)),\" & \" + str(round(np.mean(recall0),4)) + \"±\" + str(round(np.std(recall0),4)), \" & \" + str(round(np.mean(f10),4)) + \"±\" + str(round(np.std(f10),4)))\n",
    "print(str(round(np.mean(precision1),4)) + \"±\" + str(round(np.std(precision1),4)),\" & \" + str(round(np.mean(recall1),4)) + \"±\" + str(round(np.std(recall1),4)), \" & \" + str(round(np.mean(f11),4)) + \"±\" + str(round(np.std(f11),4)))\n",
    "print(str(round(np.mean(precisionacc),4)) + \"±\" + str(round(np.std(precisionacc),4)),\" & \" + str(round(np.mean(recallacc),4)) + \"±\" + str(round(np.std(recallacc),4)), \" & \" + str(round(np.mean(f1acc),4)) + \"±\" + str(round(np.std(f1acc),4)))\n",
    "print(str(round(np.mean(precisionmacavg),4)) + \"±\" + str(round(np.std(precisionmacavg),4)),\" & \" + str(round(np.mean(recallmacavg),4)) + \"±\" + str(round(np.std(recallmacavg),4)), \" & \" + str(round(np.mean(f1macavg),4)) + \"±\" + str(round(np.std(f1macavg),4)))\n",
    "print(str(round(np.mean(precisionweighavg),4)) + \"±\" + str(round(np.std(precisionweighavg),4)),\" & \" + str(round(np.mean(recallweighavg),4)) + \"±\" + str(round(np.std(recallweighavg),4)), \" & \" + str(round(np.mean(f1weighavg),4)) + \"±\" + str(round(np.std(f1weighavg),4)))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

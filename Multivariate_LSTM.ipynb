{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YI-BRUdpY__N"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import copy\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Activation\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "from numpy import hstack\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import datetime\n",
        "import time\n",
        "import joblib\n",
        "from datetime import timedelta, date\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from numpy import array\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import seaborn as sns; sns.set_theme()\n",
        "import errno\n",
        "\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import ConvLSTM2D\n",
        "from keras.models import load_model\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score, roc_curve, auc, classification_report, confusion_matrix\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "import imblearn\n",
        "import collections\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import f1_score\n",
        "from matplotlib import pyplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOKIE8fMZavh"
      },
      "outputs": [],
      "source": [
        "# Function to load and categorise the data\n",
        "import pandas as pd\n",
        "\n",
        "def load_data_south_indian(url):\n",
        "\n",
        "    df = pd.read_csv(url)\n",
        "\n",
        "    df['category'] = df['Speed(knots)'].apply(lambda x:\n",
        "        0 if x <= 33 else\n",
        "        1 if 34 <= x <= 47 else\n",
        "        2 if 48 <= x <= 63 else\n",
        "        3 if 64 <= x <= 89 else\n",
        "        4 if 90 <= x <= 115 else\n",
        "        5\n",
        "    )\n",
        "    return df\n",
        "\n",
        "def load_data_south_pacific(url):\n",
        "\n",
        "   df = pd.read_csv(url)\n",
        "   df['category'] = df['Speed(knots)'].apply(lambda x:\n",
        "        0 if x <= 33 else\n",
        "        1 if 34 <= x <= 47 else\n",
        "        2 if 48 <= x <= 63 else\n",
        "        3 if 64 <= x <= 85 else\n",
        "        4 if 86 <= x <= 107 else\n",
        "        5\n",
        "    )\n",
        "   return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTndeC9TZj9H",
        "outputId": "4b62c74e-e1fe-482a-c543-64edf150c521"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected ocean: south_indian\n",
            "Data URL: https://raw.githubusercontent.com/sydney-machine-learning/cyclonedatasets/main/SouthIndian-SouthPacific-Ocean/South_indian_hurricane.csv\n",
            "Hot-encoded result file name: south_indian\n",
            "Category result file name: roc_data_south_indian\n"
          ]
        }
      ],
      "source": [
        "ocean = 'south_indian'\n",
        "\n",
        "# Display the selected ocean\n",
        "print(f\"Selected ocean: {ocean}\")\n",
        "\n",
        "# Set the data URL and function based on the selected ocean\n",
        "if ocean == 'south_indian':\n",
        "    url_data = 'https://raw.githubusercontent.com/sydney-machine-learning/cyclonedatasets/main/SouthIndian-SouthPacific-Ocean/South_indian_hurricane.csv'\n",
        "    data_loading_function = load_data_south_indian\n",
        "    hot_encoded_result_file_name = 'south_indian'\n",
        "    category_result_file_name = 'roc_data_south_indian'\n",
        "else:\n",
        "    url_data = 'https://raw.githubusercontent.com/sydney-machine-learning/cyclonedatasets/main/SouthIndian-SouthPacific-Ocean/South_pacific_hurricane.csv'\n",
        "    data_loading_function = load_data_south_pacific\n",
        "    hot_encoded_result_file_name = 'south_pacific'\n",
        "    category_result_file_name = 'roc_data_south_pacific'\n",
        "\n",
        "# Display the data URL\n",
        "print(f\"Data URL: {url_data}\")\n",
        "\n",
        "# Display the result file names\n",
        "print(f\"Hot-encoded result file name: {hot_encoded_result_file_name}\")\n",
        "print(f\"Category result file name: {category_result_file_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7K3WM18ZoYt",
        "outputId": "9994ddbb-b10e-444d-d5fd-ce293a7a45e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame Head:\n",
            "  Basin  No. of Cycl        Time     V5  V6   Lat   Lon  Speed(knots)  \\\n",
            "0    SI            1  1981072512   BEST   0  11.8  86.7            20   \n",
            "1    SI            1  1981072518   BEST   0  11.6  86.4            25   \n",
            "2    SI            1  1981072600   BEST   0  11.3  86.2            25   \n",
            "3    SI            1  1981072606   BEST   0  10.9  86.2            25   \n",
            "4    SI            1  1981072612   BEST   0  10.4  86.1            25   \n",
            "\n",
            "   lat_tenth  lon_tenth  category  \n",
            "0       11.8       86.7         0  \n",
            "1       11.6       86.4         0  \n",
            "2       11.3       86.2         0  \n",
            "3       10.9       86.2         0  \n",
            "4       10.4       86.1         0  \n"
          ]
        }
      ],
      "source": [
        "# Load data using the specified function and URL\n",
        "df = data_loading_function(url_data)\n",
        "\n",
        "# Latitude and longitude values into int\n",
        "df['Lat'] = df['Lat'].apply(lambda x: -int(x[:-1]) * 0.1 if x.endswith('N') else int(x[:-1]) * 0.1 if x.endswith('S') else 0)\n",
        "df['Lon'] = df['Lon'].apply(lambda x: -int(x[:-1]) * 0.1 if x.endswith('W') else int(x[:-1]) * 0.1 if x.endswith('E') else 0)\n",
        "\n",
        "# Extract 'Speed(knots)' and 'category' columns as lists\n",
        "speed = df['Speed(knots)'].tolist()\n",
        "categories = df['category'].tolist()\n",
        "latitude = df['Lat'].tolist()\n",
        "longitude = df['Lon'].tolist()\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "df_head = df.head()\n",
        "print(\"DataFrame Head:\")\n",
        "print(df_head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5muktqFkq7l"
      },
      "outputs": [],
      "source": [
        "# Functions to split cyclone sequences\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def multivariate_split_sequence(sequence, n_steps):\n",
        "\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(sequence)):\n",
        "        end_ix = i + n_steps\n",
        "        if end_ix > len(sequence) - 1:\n",
        "            break\n",
        "        seq_x, seq_y = sequence[i:end_ix, :], sequence[end_ix, -1]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "features_columns = ['Lat', 'Lon','Speed(knots)']\n",
        "target_column = 'category'\n",
        "\n",
        "# Extract features and target\n",
        "features = df[features_columns].values\n",
        "target = df[target_column].values\n",
        "\n",
        "n_steps = 5  # Number of input time steps\n",
        "\n",
        "X, y = multivariate_split_sequence(features, n_steps)\n",
        "\n",
        "# Now X contains sequences of 'Latitude', 'Longitude', and 'Speed(knots)' for each time step,\n",
        "# and y contains the corresponding 'category' values.\n",
        "\n",
        "def rmse(pred, actual):\n",
        "\n",
        "    return np.sqrt(((pred - actual) ** 2).mean())\n",
        "\n",
        "def categorical(pred, actual):\n",
        "\n",
        "    cm = confusion_matrix(pred, actual)\n",
        "    acc = accuracy_score(actual, pred, normalize=True, sample_weight=None)\n",
        "    ps1 = precision_score(pred, actual, average='micro')\n",
        "    rs1 = recall_score(pred, actual, average='micro')\n",
        "    f11 = f1_score(pred, actual, average='micro')\n",
        "    auc = roc_auc_score(actual, pred)\n",
        "    return acc, auc, cm, ps1, rs1, f11\n",
        "def make_confusion_matrix_chart(cf_matrix_test, cmap='Blues', annot_kws=None):\n",
        "\n",
        "    # Set up the figure and axes\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Customize the heatmap using seaborn\n",
        "    sns.heatmap(cf_matrix_test, annot=True, cmap=cmap,\n",
        "                yticklabels=['0', '1'], xticklabels=['0', '1'],\n",
        "                fmt='g', annot_kws=annot_kws)\n",
        "\n",
        "    # Customize axis labels and title\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.title('Confusion Matrix - Test Data')\n",
        "\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7tfrs81lDun",
        "outputId": "e70e7c6f-1a92-4dfa-e1b0-9ef982166dec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Univariate: False\n",
            "Number of Input Time Steps: 6\n",
            "Number of Input Sequences: 3\n",
            "Number of Output Time Steps: 1\n",
            "Number of Input Features: 3\n",
            "Number of Output Features: 2\n",
            "Number of Hidden Layers: 50\n",
            "Epochs: 100\n",
            "Number of Experiments: 1\n"
          ]
        }
      ],
      "source": [
        "# Define whether it's a univariate or multivariate case\n",
        "univariate = False\n",
        "\n",
        "# Define sequence and time step parameters\n",
        "n_steps_in = 6\n",
        "n_seq = 3\n",
        "n_steps_out = 1\n",
        "\n",
        "# Define the number of features for input and output\n",
        "n_features_in = 3  # Latitude, Longitude, Speed\n",
        "n_features_out = 2  # Considering one-hot encoding\n",
        "\n",
        "# Define the number of hidden layers in the model\n",
        "hidden_layers = 50\n",
        "\n",
        "# Define training parameters\n",
        "epochs = 100\n",
        "No_exp = 30 # Number of experiments\n",
        "\n",
        "# Display the configuration\n",
        "print(f\"Univariate: {univariate}\")\n",
        "print(f\"Number of Input Time Steps: {n_steps_in}\")\n",
        "print(f\"Number of Input Sequences: {n_seq}\")\n",
        "print(f\"Number of Output Time Steps: {n_steps_out}\")\n",
        "print(f\"Number of Input Features: {n_features_in}\")\n",
        "print(f\"Number of Output Features: {n_features_out}\")\n",
        "print(f\"Number of Hidden Layers: {hidden_layers}\")\n",
        "print(f\"Epochs: {epochs}\")\n",
        "print(f\"Number of Experiments: {No_exp}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8KZqToilGwW",
        "outputId": "e1cb8a1f-0557-4b4f-a764-1b3e6725da83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[30. 30. 25. 25. 25. 25. 20.]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "cyclone_id = df['No. of Cycl'][0]\n",
        "X = []\n",
        "Y = []\n",
        "start_index = 0\n",
        "end_index = 0\n",
        "\n",
        "# Iterate through the DataFrame\n",
        "for i in range(1, df.shape[0]):\n",
        "    # Check if the cyclone ID is the same as the previous row\n",
        "    if df['No. of Cycl'][i] == cyclone_id:\n",
        "        end_index += 1\n",
        "    else:\n",
        "        # Split the sequence and append to X and Y\n",
        "        x, y = multivariate_split_sequence(features[start_index:end_index + 1, :], n_steps_in)\n",
        "        X.append(x)\n",
        "        Y.append(y)\n",
        "\n",
        "        # Update start and end indices for the new cyclone\n",
        "        cyclone_id = df['No. of Cycl'][i]\n",
        "        start_index = i\n",
        "        end_index = i\n",
        "\n",
        "    # Check if it's the last row of the DataFrame\n",
        "    if i == df.shape[0] - 1:\n",
        "        # Split the sequence and append to X and Y\n",
        "        x, y = multivariate_split_sequence(features[start_index:end_index + 1, :], n_steps_in)\n",
        "        X.append(x)\n",
        "        Y.append(y)\n",
        "print(Y[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfkDNbt8lOVQ",
        "outputId": "42aa7df5-3b46-4fae-f7c2-a0341bb388a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Lengths - X: 670 Y: 670\n",
            "Flattened Lengths - X: 20153 Y: 20153\n",
            "[[11.8 86.7 20. ]\n",
            " [11.6 86.4 25. ]\n",
            " [11.3 86.2 25. ]\n",
            " [10.9 86.2 25. ]\n",
            " [10.4 86.1 25. ]\n",
            " [10.1 85.7 30. ]] 30.0\n",
            "Sample Values - Speed: [20, 25, 25, 25, 25, 30, 30, 30, 25, 25]\n"
          ]
        }
      ],
      "source": [
        "# Print the initial lengths of X and Y\n",
        "print(\"Initial Lengths - X:\", len(X), \"Y:\", len(Y))\n",
        "\n",
        "# Flattening X and Y\n",
        "X = [item for sublist in X for item in sublist]\n",
        "Y = [item for sublist in Y for item in sublist]\n",
        "\n",
        "# Print lengths of X and Y after flattening\n",
        "print(\"Flattened Lengths - X:\", len(X), \"Y:\", len(Y))\n",
        "\n",
        "# Print some initial values from X and Y\n",
        "print(X[0], Y[0])\n",
        "\n",
        "# Print some initial values from the 'speed' column\n",
        "print(\"Sample Values - Speed:\", speed[:10])\n",
        "X1 = X\n",
        "Y1 = Y\n",
        "X2 = X\n",
        "Y2 = Y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0TjLjUjWx0p",
        "outputId": "2c3712ba-6eea-431c-a07e-38e4ba1ba0ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20153\n"
          ]
        }
      ],
      "source": [
        "# Initialize 'intensify_y' with zeros\n",
        "intensify_y = [0] * len(X)\n",
        "\n",
        "# Add labels for rapid intensification\n",
        "for i in range(len(X)):\n",
        "    for j in range(len(X[0]) - 4, len(X[0])):\n",
        "        if (Y[i] - X[i][j][2]) >= 30:\n",
        "            intensify_y[i] = 1\n",
        "            break\n",
        "\n",
        "print(len(intensify_y))\n",
        "\n",
        "Y = intensify_y\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx2Za37MlalZ",
        "outputId": "c03fc572-4051-4542-cd73-ac4bc7357793"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 15114\n"
          ]
        }
      ],
      "source": [
        "# Calculate the training limit as 75% of the total length of X\n",
        "train_limit = int(len(X) * 0.75)\n",
        "print(\"Training set size:\", train_limit)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNlc4JoVlbTx",
        "outputId": "4c2dbb93-ff3f-42c6-9771-93c3f7207215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of X: 20153\n",
            "Length of Y: 20153\n",
            "Length of Test X (for evaluation): 5038\n",
            "Length of Test Y (for evaluation): 5038\n"
          ]
        }
      ],
      "source": [
        "\n",
        "test_X_original = X[train_limit + 1:]\n",
        "test_Y_original = Y[train_limit + 1:]\n",
        "\n",
        "# Display the lengths of the datasets\n",
        "print(\"Length of X:\", len(X))\n",
        "print(\"Length of Y:\", len(Y))\n",
        "print(\"Length of Test X (for evaluation):\", len(test_X_original))\n",
        "print(\"Length of Test Y (for evaluation):\", len(test_Y_original))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z3L_WUglf-P",
        "outputId": "e205bff2-1d8b-4e41-fa3a-9dbd54561cf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.55813953 0.8209785  0.06896552]\n",
            " [0.53955375 0.81986657 0.07142857]\n",
            " [0.52054795 0.81912528 0.07142857]\n",
            " [0.51119403 0.81912528 0.07142857]\n",
            " [0.5026738  0.81905821 0.07142857]\n",
            " [0.5        0.81757508 0.13793103]]\n"
          ]
        }
      ],
      "source": [
        "# Normalization\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "X = np.array(X)\n",
        "scalers = {}\n",
        "for i in range(X.shape[1]):\n",
        "    scalers[i] = MinMaxScaler()\n",
        "    X[:, i, :] = scalers[i].fit_transform(X[:, i, :])\n",
        "print(X[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4ruamx0lifI",
        "outputId": "99bd87ee-4f03-4865-8794-6c72a562a162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5038 5038\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15114, 15114)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Splitting into train and test sets\n",
        "speed_x = X\n",
        "test_X = X[train_limit+1:]\n",
        "test_X = np.asarray(test_X).astype(float)\n",
        "test_Y = Y[train_limit+1:]\n",
        "X = X[:train_limit]\n",
        "X = np.asarray(X).astype(float)\n",
        "Y = Y[:train_limit]\n",
        "print(len(test_X), len(test_Y))\n",
        "len(X), len(Y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qoy4Jz2MllFT",
        "outputId": "3893016d-7c30-46c3-836f-22c24aba1e9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution - Training Data:\n",
            "Counter({0: 14531, 1: 583})\n",
            "\n",
            "Class Distribution - Test Data:\n",
            "Counter({0: 4935, 1: 103})\n"
          ]
        }
      ],
      "source": [
        "# Calculate the class distribution for training and test data\n",
        "counter_train = Counter(Y)\n",
        "counter_test = Counter(test_Y)\n",
        "\n",
        "# Display the class distribution for training data\n",
        "print(\"Class Distribution - Training Data:\")\n",
        "print(counter_train)\n",
        "\n",
        "# Display the class distribution for test data\n",
        "print(\"\\nClass Distribution - Test Data:\")\n",
        "print(counter_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def focal_loss(alpha=0.75, gamma=2.0):\n",
        "    def loss(y_true, y_pred):\n",
        "        y_pred = K.clip(y_pred, 1e-7, 1 - 1e-7)\n",
        "        cross_entropy = -y_true * K.log(y_pred)\n",
        "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
        "        return K.sum(loss, axis=1)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "Iz28ASC9tkYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aXQPVbS7tn1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Multivariate LSTM**"
      ],
      "metadata": {
        "id": "3w_9gfNCWHV7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jr8-n795lvSr"
      },
      "outputs": [],
      "source": [
        "def multivariate_vanilla_lstm(n_steps_in, n_steps_out, n_features_in, n_features_out):\n",
        "    \"\"\"\n",
        "    Create a Multivariate LSTM model for sequence prediction.\n",
        "\n",
        "    Parameters:\n",
        "    - n_steps_in: Number of time steps in the input sequence.\n",
        "    - n_steps_out: Number of time steps in the output sequence.\n",
        "    - n_features_in: Number of input features.\n",
        "    - n_features_out: Number of output features.\n",
        "\n",
        "    Returns:\n",
        "    - model: Compiled Multivariate LSTM model.\n",
        "    \"\"\"\n",
        "    # Initialize a sequential model\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add an LSTM layer with 50 units and ReLU activation\n",
        "    model.add(LSTM(50, activation='relu', input_shape=(n_steps_in, n_features_in)))\n",
        "\n",
        "    # Add a Dense layer with a single unit and sigmoid activation for binary classification\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    # Compile the model using Adam optimizer and binary crossentropy loss\n",
        "    model.compile(optimizer='adam', loss=focal_loss(alpha=0.75, gamma=2.0), metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ctAKL5el1Gk"
      },
      "outputs": [],
      "source": [
        "\n",
        "def lstm(model_name, method, univariate, x_train, x_test, y_train, y_test, Num_Exp, n_steps_in, n_steps_out, Epochs, Hidden):\n",
        "    # Initialize arrays to store accuracy metrics\n",
        "    train_acc = np.zeros(Num_Exp)\n",
        "    test_acc = np.zeros(Num_Exp)\n",
        "\n",
        "\n",
        "    if model_name == 'vanilla':\n",
        "        model = multivariate_vanilla_lstm(n_steps_in, n_steps_out, n_features_in, n_features_out)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model_name: {model_name}\")\n",
        "\n",
        "    # Display the model summary\n",
        "    model.summary()\n",
        "\n",
        "    # Initialize arrays to store predictions and classification reports\n",
        "    y_predicttest_allruns = np.zeros([Num_Exp, x_test.shape[0], y_test.shape[1]])\n",
        "    Best_f1 = 0  # Initialize the best F1 score\n",
        "\n",
        "    # Extract the actual classes from one-hot encoded vectors for both test and train sets\n",
        "    act_test = [y_test[i].argmax() for i in range(y_test.shape[0])]\n",
        "    act_train = [y_train[i].argmax() for i in range(y_train.shape[0])]\n",
        "\n",
        "    # Initialize dictionaries to store classification reports\n",
        "    Best_report_train = dict()\n",
        "    Best_report_test = dict()\n",
        "    all_report_train = dict()\n",
        "    all_report_test = dict()\n",
        "\n",
        "    # Loop through experiment runs\n",
        "    start_time = time.time()\n",
        "    for run in range(Num_Exp):\n",
        "        print(\"Experiment\", run + 1, \"in progress\")\n",
        "\n",
        "        # Fit the model\n",
        "        model.fit(x_train, y_train, epochs=Epochs, batch_size=10, verbose=0, shuffle=False)\n",
        "        y_predicttrain = model.predict(x_train)\n",
        "        y_predicttest = model.predict(x_test)\n",
        "\n",
        "        # Extract predicted classes from one-hot encoded vectors\n",
        "        pred_test = [y_predicttest[i].argmax() for i in range(y_predicttest.shape[0])]\n",
        "        pred_train = [y_predicttrain[i].argmax() for i in range(y_predicttrain.shape[0])]\n",
        "\n",
        "        # Generate classification reports\n",
        "        report_train = classification_report(act_train, pred_train, labels=[0, 1], output_dict=True)\n",
        "        report_test = classification_report(act_test, pred_test, labels=[0, 1], output_dict=True)\n",
        "\n",
        "        # Store classification reports in dictionaries\n",
        "        all_report_train[run] = report_train\n",
        "        all_report_test[run] = report_test\n",
        "\n",
        "        # Calculate F1-score for the test set\n",
        "        test_acc[run] = report_test['1']['f1-score']\n",
        "        print(\"train acc: \", report_train['1']['f1-score'])\n",
        "        print(\"test acc: \", test_acc[run])\n",
        "\n",
        "        precision_minority = report_test['1']['precision']\n",
        "        recall_minority = report_test['1']['recall']\n",
        "        print(\"Precision (Minority Class):\", precision_minority)\n",
        "        print(\"Recall (Minority Class):\", recall_minority)\n",
        "\n",
        "        macro_avg_precision = report_test['macro avg']['precision']\n",
        "        macro_avg_recall = report_test['macro avg']['recall']\n",
        "        macro_avg_f1 = report_test['macro avg']['f1-score']\n",
        "\n",
        "        weighted_avg_precision = report_test['weighted avg']['precision']\n",
        "        weighted_avg_recall = report_test['weighted avg']['recall']\n",
        "        weighted_avg_f1 = report_test['weighted avg']['f1-score']\n",
        "\n",
        "        # Print or store Macro Avg and Weighted Avg values\n",
        "        print(\"Macro Avg Precision:\", macro_avg_precision)\n",
        "        print(\"Macro Avg Recall:\", macro_avg_recall)\n",
        "        print(\"Macro Avg F1-Score:\", macro_avg_f1)\n",
        "\n",
        "        print(\"Weighted Avg Precision:\", weighted_avg_precision)\n",
        "        print(\"Weighted Avg Recall:\", weighted_avg_recall)\n",
        "        print(\"Weighted Avg F1-Score:\", weighted_avg_f1)\n",
        "\n",
        "\n",
        "\n",
        "        # Update the best F1 score and associated predictions and reports\n",
        "        if test_acc[run] > Best_f1:\n",
        "            Best_f1 = test_acc[run]\n",
        "            Best_Predict_Test = y_predicttest\n",
        "            Best_report_train, Best_report_test = report_train, report_test\n",
        "\n",
        "    # Save the trained model\n",
        "    model.save(\"model_\" + ocean + \"_\" + model_name + \"_\" + method + '.h5')\n",
        "\n",
        "    # Calculate standard deviations of train and test accuracies\n",
        "    train_std = np.std(train_acc)\n",
        "    test_std = np.std(test_acc)\n",
        "\n",
        "    # Display experiment summary\n",
        "    print(\"Total time for\", Num_Exp, \"experiments\", time.time() - start_time)\n",
        "    print(\"F1 scores for test data: \", test_acc)\n",
        "    print(\"Mean: \", np.mean(test_acc), \"Std Dev: \", test_std)\n",
        "\n",
        "    # Return relevant information\n",
        "    return train_acc, test_acc, train_std, test_std, Best_Predict_Test, y_predicttrain, y_predicttest, all_report_train, all_report_test\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPRO55mHl9Fh",
        "outputId": "6f6c1956-21d7-4b73-9bc7-9849556c539a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15114, 6, 3)\n",
            "(15114, 2) (5038, 2)\n"
          ]
        }
      ],
      "source": [
        "# Create a random permutation of indices for shuffling\n",
        "idx = np.random.permutation(len(X))\n",
        "\n",
        "# Initialize lists to store shuffled data\n",
        "x_shuffled = []\n",
        "y_shuffled = []\n",
        "\n",
        "# Iterate through the shuffled indices\n",
        "for i in idx:\n",
        "    # Append shuffled data to the lists\n",
        "    x_shuffled.append(X[i])\n",
        "    y_shuffled.append(Y[i])\n",
        "x_a = np.array(x_shuffled)\n",
        "print(x_a.shape)\n",
        "\n",
        "\n",
        "# Convert the shuffled labels to one-hot encoded format for training data\n",
        "Y_hot_encoded_train = np.asarray(to_categorical(y_shuffled))\n",
        "\n",
        "# Convert the test labels to one-hot encoded format\n",
        "Y_hot_encoded_test = np.asarray(to_categorical(test_Y))\n",
        "\n",
        "# Print the shapes of the one-hot encoded training and test labels\n",
        "print(Y_hot_encoded_train.shape, Y_hot_encoded_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ke4YSUqBmAjO"
      },
      "outputs": [],
      "source": [
        "# Testing on all 4 different kinds of LSTMs\n",
        "models = ['vanilla']\n",
        "\n",
        "\n",
        "# Initialize dictionaries to store predictions, actual values, and metrics for training and testing\n",
        "predictions_train = dict()\n",
        "actual_train = dict()\n",
        "predictions_test = dict()\n",
        "actual_test = dict()\n",
        "metrics_train = dict()\n",
        "metrics_test = dict()\n",
        "test_acc_all = dict()\n",
        "test_stddev = dict()\n",
        "train_loss_all = dict()\n",
        "test_loss_all = dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Code to run the Multivariate LSTM**"
      ],
      "metadata": {
        "id": "iiP6IqeRW0GQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "8XBf-AoWmDvE",
        "outputId": "71d4ad65-b508-407d-d6df-74caf272f6bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------\n",
            "Number of steps out: 1\n",
            "For vanilla:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │          \u001b[38;5;34m10,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m102\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">102</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,902\u001b[0m (42.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,902</span> (42.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,902\u001b[0m (42.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,902</span> (42.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment 1 in progress\n",
            "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train acc:  0.7434656340755083\n",
            "test acc:  0.42857142857142855\n",
            "Precision (Minority Class): 0.5538461538461539\n",
            "Recall (Minority Class): 0.34951456310679613\n",
            "Macro Avg Precision: 0.7701867004903402\n",
            "Macro Avg Recall: 0.6718190849981802\n",
            "Macro Avg F1-Score: 0.7094411442413057\n",
            "Weighted Avg Precision: 0.9776812462197384\n",
            "Weighted Avg Recall: 0.980944819372767\n",
            "Weighted Avg F1-Score: 0.9788263102033633\n",
            "Total time for 1 experiments 842.9072515964508\n",
            "F1 scores for test data:  [0.42857143]\n",
            "Mean:  0.42857142857142855 Std Dev:  0.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for j in range(1):\n",
        "\n",
        "  predictions_train_per_step = dict()\n",
        "  actual_train_per_step = dict()\n",
        "  predictions_test_per_step = dict()\n",
        "  actual_test_per_step = dict()\n",
        "  metrics_train_per_step = dict()\n",
        "  metrics_test_per_step = dict()\n",
        "  test_acc_per_step = dict()\n",
        "  test_stddev_per_step = dict()\n",
        "  n_steps_out = j + 1\n",
        "\n",
        "  print('---------------------------------------------------------')\n",
        "  print('Number of steps out:', n_steps_out)\n",
        "\n",
        "  # Loop over different LSTM models\n",
        "  for i in models:\n",
        "    print(\"For \" + i + \":\")\n",
        "\n",
        "    # Reshape data based on the LSTM model type\n",
        "    if i == 'vanilla' or i == 'bidirectional' :\n",
        "        x_train, y_train = np.asarray(x_shuffled), np.asarray(Y_hot_encoded_train)\n",
        "        x_test, y_test = np.asarray(test_X), np.asarray(Y_hot_encoded_test)\n",
        "        x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], n_features_in))\n",
        "        x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], n_features_in))\n",
        "    elif i == 'cnn-lstm':\n",
        "        x_train, y_train = np.asarray(x_shuffled), np.asarray(Y_hot_encoded_train)\n",
        "        x_test, y_test = np.asarray(test_X), np.asarray(Y_hot_encoded_test)\n",
        "        x_train = x_train.reshape((x_train.shape[0], n_seq, int(n_steps_in / n_seq), n_features_in))\n",
        "        x_test = x_test.reshape((x_test.shape[0], n_seq, int(n_steps_in / n_seq), n_features_in))\n",
        "    elif i == 'conv-lstm':\n",
        "        print(\"Original shape of x_shuffled:\", np.array(x_shuffled).shape)\n",
        "        x_train, y_train = np.asarray(x_shuffled), np.asarray(Y_hot_encoded_train)\n",
        "        print(\"Shape after reshape:\", np.array(x_train).shape)\n",
        "        x_test, y_test = np.asarray(test_X), np.asarray(Y_hot_encoded_test)\n",
        "        x_train = x_train.reshape((x_train.shape[0], n_seq, 1, int(n_steps_in/n_seq), n_features_in))\n",
        "        x_test = x_test.reshape(x_test.shape[0], n_seq, 1, int(n_steps_in/n_seq), n_features_in)\n",
        "\n",
        "    # Call the LSTM function and retrieve results\n",
        "    train_acc, test_acc, train_std_dev, test_std_dev, Best_Predict_Test, y_predicttrain, y_predicttest, report_train, report_test = lstm(\n",
        "        i, 'original', univariate, x_train, x_test, y_train, y_test, No_exp, n_steps_in, n_steps_out, epochs, hidden_layers)\n",
        "\n",
        "    # Store results in respective dictionaries\n",
        "    predictions_train_per_step[i] = y_predicttrain\n",
        "    actual_train_per_step[i] = y_train\n",
        "    predictions_test_per_step[i] = Best_Predict_Test\n",
        "    actual_test_per_step[i] = y_test\n",
        "    metrics_train_per_step[i] = report_train\n",
        "    metrics_test_per_step[i] = report_test\n",
        "    test_acc_per_step[i] = test_acc\n",
        "    test_stddev_per_step[i] = test_std_dev\n",
        "\n",
        "# Store results for the current n_steps_out in the overall dictionaries\n",
        "  predictions_train[str(j + 1)] = predictions_train_per_step\n",
        "  actual_train[str(j + 1)] = actual_train_per_step\n",
        "  predictions_test[str(j + 1)] = predictions_test_per_step\n",
        "  actual_test[str(j + 1)] = actual_test_per_step\n",
        "  metrics_train[str(j + 1)] = metrics_train_per_step\n",
        "  metrics_test[str(j + 1)] = metrics_test_per_step\n",
        "  test_acc_all[str(j + 1)] = test_acc_per_step\n",
        "  test_stddev[str(j + 1)] = test_stddev_per_step\n",
        "# Note : Testing done by running on one experiment, can be run for 30 experiments successfully and those results are put in the paper"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WFCPfByNxuid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7YaCBl8mG9k"
      },
      "outputs": [],
      "source": [
        "with open(\"predictions_\" + ocean + '_original' + '.pkl', 'wb') as f:\n",
        "    pickle.dump([predictions_train,actual_train,predictions_test,actual_test,metrics_train,metrics_test,test_acc,test_stddev], f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W93WzsCymJeh"
      },
      "outputs": [],
      "source": [
        "# Function to make confusion matrix\n",
        "def make_confusion_matrix_chart(cf_matrix, name):\n",
        "\n",
        "    # Set a Seaborn style with dark grid\n",
        "    sns.set(style=\"darkgrid\", font_scale=1.5)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "    # Customize the appearance of the heatmap with green colors\n",
        "    sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Greens',\n",
        "                linewidths=.5, square=True, cbar=False,\n",
        "                annot_kws={\"size\": 16}, ax=ax)\n",
        "\n",
        "    # Set labels and title\n",
        "    plt.ylabel(\"Actual\", size=18)\n",
        "    plt.xlabel(\"Predicted\", size=18)\n",
        "    plt.title(\"Confusion Matrix\", size=20)\n",
        "\n",
        "    # Set tick parameters\n",
        "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
        "\n",
        "    # Save the plot as an image\n",
        "    plt.savefig(name + '.png', dpi=300, transparent=False, bbox_inches='tight')\n",
        "\n",
        "    # Display the plot\n",
        "    plt.show()\n",
        "\n",
        "    return None\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "id": "Ss0D1RYXmO8v",
        "outputId": "03fa398c-d32c-4743-e0f7-2d2382b1f288"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Code to display confucion matrix\n",
        "y = [i.argmax() for i in actual_test_per_step['vanilla']]\n",
        "pred = [i.argmax() for i in predictions_test_per_step['vanilla']]\n",
        "cf_matrix_test = confusion_matrix(y, pred)\n",
        "make_confusion_matrix_chart(cf_matrix_test, ocean + 'vanilla_cm_original')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EX6dlBEEmSLT"
      },
      "outputs": [],
      "source": [
        "# Code to display results\n",
        "# Initialize lists to store precision, recall, and F1-score metrics for class 0, class 1, overall accuracy,\n",
        "# macro average, and weighted average across multiple experiments\n",
        "precision0 = []\n",
        "precision1 = []\n",
        "precisionacc = []\n",
        "precisionmacavg = []\n",
        "precisionweighavg = []\n",
        "recall0 = []\n",
        "recall1 = []\n",
        "recallacc = []\n",
        "recallmacavg = []\n",
        "recallweighavg = []\n",
        "f10 = []\n",
        "f11 = []\n",
        "f1acc = []\n",
        "f1macavg = []\n",
        "f1weighavg = []\n",
        "\n",
        "\n",
        "for i in range(No_exp):\n",
        "\n",
        "    precision0.append(metrics_test_per_step['vanilla'][i]['0']['precision'])\n",
        "    precision1.append(metrics_test_per_step['vanilla'][i]['1']['precision'])\n",
        "    precisionacc.append(metrics_test_per_step['vanilla'][i]['accuracy'])\n",
        "    precisionmacavg.append(metrics_test_per_step['vanilla'][i]['macro avg']['precision'])\n",
        "    precisionweighavg.append(metrics_test_per_step['vanilla'][i]['weighted avg']['precision'])\n",
        "\n",
        "    recall0.append(metrics_test_per_step['vanilla'][i]['0']['recall'])\n",
        "    recall1.append(metrics_test_per_step['vanilla'][i]['1']['recall'])\n",
        "    recallacc.append(metrics_test_per_step['vanilla'][i]['accuracy'])\n",
        "    recallmacavg.append(metrics_test_per_step['vanilla'][i]['macro avg']['recall'])\n",
        "    recallweighavg.append(metrics_test_per_step['vanilla'][i]['weighted avg']['recall'])\n",
        "\n",
        "    f10.append(metrics_test_per_step['vanilla'][i]['0']['f1-score'])\n",
        "    f11.append(metrics_test_per_step['vanilla'][i]['1']['f1-score'])\n",
        "    f1acc.append(metrics_test_per_step['vanilla'][i]['accuracy'])\n",
        "    f1macavg.append(metrics_test_per_step['vanilla'][i]['macro avg']['f1-score'])\n",
        "    f1weighavg.append(metrics_test_per_step['vanilla'][i]['weighted avg']['f1-score'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrm67mDvmcQm",
        "outputId": "51696046-f1f9-4c5a-f173-7688aff6da94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9865±0.0  & 0.9941±0.0  & 0.9903±0.0\n",
            "0.5538±0.0  & 0.3495±0.0  & 0.4286±0.0\n",
            "0.9809±0.0  & 0.9809±0.0  & 0.9809±0.0\n",
            "0.7702±0.0  & 0.6718±0.0  & 0.7094±0.0\n",
            "0.9777±0.0  & 0.9809±0.0  & 0.9788±0.0\n"
          ]
        }
      ],
      "source": [
        "print(str(round(np.mean(precision0),4)) + \"±\" + str(round(np.std(precision0),4)),\" & \" + str(round(np.mean(recall0),4)) + \"±\" + str(round(np.std(recall0),4)), \" & \" + str(round(np.mean(f10),4)) + \"±\" + str(round(np.std(f10),4)))\n",
        "print(str(round(np.mean(precision1),4)) + \"±\" + str(round(np.std(precision1),4)),\" & \" + str(round(np.mean(recall1),4)) + \"±\" + str(round(np.std(recall1),4)), \" & \" + str(round(np.mean(f11),4)) + \"±\" + str(round(np.std(f11),4)))\n",
        "print(str(round(np.mean(precisionacc),4)) + \"±\" + str(round(np.std(precisionacc),4)),\" & \" + str(round(np.mean(recallacc),4)) + \"±\" + str(round(np.std(recallacc),4)), \" & \" + str(round(np.mean(f1acc),4)) + \"±\" + str(round(np.std(f1acc),4)))\n",
        "print(str(round(np.mean(precisionmacavg),4)) + \"±\" + str(round(np.std(precisionmacavg),4)),\" & \" + str(round(np.mean(recallmacavg),4)) + \"±\" + str(round(np.std(recallmacavg),4)), \" & \" + str(round(np.mean(f1macavg),4)) + \"±\" + str(round(np.std(f1macavg),4)))\n",
        "print(str(round(np.mean(precisionweighavg),4)) + \"±\" + str(round(np.std(precisionweighavg),4)),\" & \" + str(round(np.mean(recallweighavg),4)) + \"±\" + str(round(np.std(recallweighavg),4)), \" & \" + str(round(np.mean(f1weighavg),4)) + \"±\" + str(round(np.std(f1weighavg),4)))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87fw0a-_5lBu"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "import sklearn\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Activation\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "from numpy import hstack\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import datetime\n",
        "import time\n",
        "import joblib\n",
        "from datetime import timedelta, date\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from numpy import array\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import time\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import time\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import seaborn as sns; sns.set_theme()\n",
        "import errno\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import ConvLSTM2D\n",
        "from keras.models import load_model\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score, roc_curve, auc, classification_report, confusion_matrix\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "import imblearn\n",
        "import collections\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import f1_score\n",
        "from matplotlib import pyplot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZM8Z7JQ5xeu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_data_south_indian(url):\n",
        "    \"\"\"\n",
        "    Load and preprocess data for South Indian region.\n",
        "\n",
        "    Parameters:\n",
        "    - url (str): URL or file path to the CSV file.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: Processed DataFrame with a 'category' column.\n",
        "    \"\"\"\n",
        "    # Load data from CSV\n",
        "    df = pd.read_csv(url)\n",
        "\n",
        "    # Add a 'category' column based on speed ranges\n",
        "    df['category'] = df['Speed(knots)'].apply(lambda x:\n",
        "        0 if x <= 33 else\n",
        "        1 if 34 <= x <= 47 else\n",
        "        2 if 48 <= x <= 63 else\n",
        "        3 if 64 <= x <= 89 else\n",
        "        4 if 90 <= x <= 115 else\n",
        "        5\n",
        "    )\n",
        "\n",
        "    return df\n",
        "\n",
        "def load_data_south_pacific(url):\n",
        "    \"\"\"\n",
        "    Load and preprocess data for South Pacific region.\n",
        "\n",
        "    Parameters:\n",
        "    - url (str): URL or file path to the CSV file.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: Processed DataFrame with a 'category' column.\n",
        "    \"\"\"\n",
        "    # Load data from CSV\n",
        "    df = pd.read_csv(url)\n",
        "\n",
        "    # Add a 'category' column based on speed ranges\n",
        "    df['category'] = df['Speed(knots)'].apply(lambda x:\n",
        "        0 if x <= 33 else\n",
        "        1 if 34 <= x <= 47 else\n",
        "        2 if 48 <= x <= 63 else\n",
        "        3 if 64 <= x <= 85 else\n",
        "        4 if 86 <= x <= 107 else\n",
        "        5\n",
        "    )\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prDSQ_bV50WX",
        "outputId": "a4444d3a-9e4e-4bad-d118-852d20be7546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected ocean: south_pacific\n",
            "Data URL: https://raw.githubusercontent.com/sydney-machine-learning/cyclonedatasets/main/SouthIndian-SouthPacific-Ocean/South_pacific_hurricane.csv\n",
            "Hot-encoded result file name: south_pacific\n",
            "Category result file name: roc_data_south_pacific\n"
          ]
        }
      ],
      "source": [
        "ocean = 'south_pacific'\n",
        "\n",
        "# Display the selected ocean\n",
        "print(f\"Selected ocean: {ocean}\")\n",
        "\n",
        "# Set the data URL and function based on the selected ocean\n",
        "if ocean == 'south_indian':\n",
        "    url_data = 'https://raw.githubusercontent.com/sydney-machine-learning/cyclonedatasets/main/SouthIndian-SouthPacific-Ocean/South_indian_hurricane.csv'\n",
        "    data_loading_function = load_data_south_indian\n",
        "    hot_encoded_result_file_name = 'south_indian'\n",
        "    category_result_file_name = 'roc_data_south_indian'\n",
        "else:\n",
        "    url_data = 'https://raw.githubusercontent.com/sydney-machine-learning/cyclonedatasets/main/SouthIndian-SouthPacific-Ocean/South_pacific_hurricane.csv'\n",
        "    data_loading_function = load_data_south_pacific\n",
        "    hot_encoded_result_file_name = 'south_pacific'\n",
        "    category_result_file_name = 'roc_data_south_pacific'\n",
        "\n",
        "# Display the data URL for verification\n",
        "print(f\"Data URL: {url_data}\")\n",
        "\n",
        "# Display the result file names\n",
        "print(f\"Hot-encoded result file name: {hot_encoded_result_file_name}\")\n",
        "print(f\"Category result file name: {category_result_file_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdvDdXTl52tZ",
        "outputId": "0fcc8aa3-65e2-41cf-b0b1-c897a4c449f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame Head:\n",
            "  Basin  No. of Cycl        Time     V5  V6   Lat    Lon  Speed(knots)  \\\n",
            "0    SP           14  1982012518   BEST   0  18.0  154.1            25   \n",
            "1    SP           14  1982012600   BEST   0  19.1  154.8            25   \n",
            "2    SP           14  1982012606   BEST   0  19.7  155.7            25   \n",
            "3    SP           14  1982012612   BEST   0  19.9  156.7            30   \n",
            "4    SP           14  1982012618   BEST   0  20.1  157.8            35   \n",
            "\n",
            "   lat_tenth  lon_tenth  category  \n",
            "0       18.0      154.1         0  \n",
            "1       19.1      154.8         0  \n",
            "2       19.7      155.7         0  \n",
            "3       19.9      156.7         0  \n",
            "4       20.1      157.8         1  \n"
          ]
        }
      ],
      "source": [
        "# Load data using the specified function and URL\n",
        "df = data_loading_function(url_data)\n",
        "\n",
        "df['Lat'] = df['Lat'].apply(lambda x: -int(x[:-1]) * 0.1 if x.endswith('N') else int(x[:-1]) * 0.1 if x.endswith('S') else 0)\n",
        "df['Lon'] = df['Lon'].apply(lambda x: -int(x[:-1]) * 0.1 if x.endswith('W') else int(x[:-1]) * 0.1 if x.endswith('E') else 0)\n",
        "\n",
        "# Extract 'Speed(knots)' and 'category' columns as lists\n",
        "speed = df['Speed(knots)'].tolist()\n",
        "categories = df['category'].tolist()\n",
        "latitude = df['Lat'].tolist()\n",
        "longitude = df['Lon'].tolist()\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "df_head = df.head()\n",
        "print(\"DataFrame Head:\")\n",
        "print(df_head)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HQ-VySG54lt"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "def split_sequence(sequences, n_steps_in, n_steps_out):\n",
        "    \"\"\"\n",
        "    Split multivariate sequences into input and output parts.\n",
        "\n",
        "    Parameters:\n",
        "    - sequences (numpy.ndarray): Multivariate time series data.\n",
        "    - n_steps_in (int): Number of input time steps.\n",
        "    - n_steps_out (int): Number of output time steps.\n",
        "\n",
        "    Returns:\n",
        "    - tuple: Input sequences (X) and output sequences (y) as numpy arrays.\n",
        "    \"\"\"\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(sequences)):\n",
        "        end_ix = i + n_steps_in\n",
        "        out_end_ix = end_ix + n_steps_out\n",
        "        if out_end_ix > len(sequences):\n",
        "            break\n",
        "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, -1]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def uni_split_sequence(sequence, n_steps):\n",
        "    \"\"\"\n",
        "    Split univariate sequence into input and output parts.\n",
        "\n",
        "    Parameters:\n",
        "    - sequence (list): Univariate time series data.\n",
        "    - n_steps (int): Number of input time steps.\n",
        "\n",
        "    Returns:\n",
        "    - tuple: Input sequences (X) and output sequences (y) as numpy arrays.\n",
        "    \"\"\"\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(sequence)):\n",
        "        end_ix = i + n_steps\n",
        "        if end_ix > len(sequence) - 1:\n",
        "            break\n",
        "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def rmse(pred, actual):\n",
        "    \"\"\"\n",
        "    Calculate the Root Mean Squared Error (RMSE) between two arrays.\n",
        "\n",
        "    Parameters:\n",
        "    - pred (numpy.ndarray): Predicted values.\n",
        "    - actual (numpy.ndarray): Actual values.\n",
        "\n",
        "    Returns:\n",
        "    - float: Root Mean Squared Error.\n",
        "    \"\"\"\n",
        "    return np.sqrt(((pred - actual) ** 2).mean())\n",
        "\n",
        "def categorical(pred, actual):\n",
        "    \"\"\"\n",
        "    Compute classification metrics for categorical values.\n",
        "\n",
        "    Parameters:\n",
        "    - pred (numpy.ndarray): Predicted categorical values.\n",
        "    - actual (numpy.ndarray): Actual categorical values.\n",
        "\n",
        "    Returns:\n",
        "    - tuple: Accuracy, AUC, Confusion Matrix, Precision, Recall, F1 Score.\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(pred, actual)\n",
        "    acc = accuracy_score(actual, pred, normalize=True, sample_weight=None)\n",
        "    ps1 = precision_score(pred, actual, average='micro')\n",
        "    rs1 = recall_score(pred, actual, average='micro')\n",
        "    f11 = f1_score(pred, actual, average='micro')\n",
        "    auc = roc_auc_score(actual, pred)\n",
        "    return acc, auc, cm, ps1, rs1, f11\n",
        "\n",
        "def make_confusion_matrix_chart(cf_matrix_test, cmap='Blues', annot_kws=None):\n",
        "    \"\"\"\n",
        "    Generate and display a heatmap-style confusion matrix chart.\n",
        "\n",
        "    Parameters:\n",
        "    - cf_matrix_test (numpy.ndarray): Confusion matrix.\n",
        "    - cmap (str): Colormap for the heatmap.\n",
        "    - annot_kws (dict): Additional keyword arguments for annotation customization.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    # Set up the figure and axes\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Customize the heatmap using seaborn\n",
        "    sns.heatmap(cf_matrix_test, annot=True, cmap=cmap,\n",
        "                yticklabels=['0', '1'], xticklabels=['0', '1'],\n",
        "                fmt='g', annot_kws=annot_kws)\n",
        "\n",
        "    # Customize axis labels and title\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.title('Confusion Matrix - Test Data')\n",
        "\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7ku6gTT575v",
        "outputId": "0c18c14d-71d4-469b-f2d2-62cdfe204fbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration:\n",
            "Univariate: True\n",
            "Number of Input Time Steps: 6\n",
            "Number of Input Sequences: 2\n",
            "Number of Output Time Steps: 1\n",
            "Number of Input Features: 1\n",
            "Number of Output Features: 2\n",
            "Number of Hidden Layers: 50\n",
            "Epochs: 100\n",
            "Number of Experiments: 30\n"
          ]
        }
      ],
      "source": [
        "# Define whether it's a univariate or multivariate case\n",
        "univariate = True  # If False, it's a multivariate case\n",
        "\n",
        "# Define sequence and time step parameters\n",
        "n_steps_in = 6\n",
        "n_seq = 2\n",
        "n_steps_out = 1\n",
        "\n",
        "# Define the number of features for input and output\n",
        "n_features_in = 1  # Speed\n",
        "n_features_out = 2  # One-hot encoding of category\n",
        "\n",
        "# Define the number of hidden layers in the model\n",
        "hidden_layers = 50\n",
        "\n",
        "# Define training parameters\n",
        "epochs = 100\n",
        "No_exp = 30 # Number of experiments\n",
        "\n",
        "# Display the configuration\n",
        "print(\"Configuration:\")\n",
        "print(f\"Univariate: {univariate}\")\n",
        "print(f\"Number of Input Time Steps: {n_steps_in}\")\n",
        "print(f\"Number of Input Sequences: {n_seq}\")\n",
        "print(f\"Number of Output Time Steps: {n_steps_out}\")\n",
        "print(f\"Number of Input Features: {n_features_in}\")\n",
        "print(f\"Number of Output Features: {n_features_out}\")\n",
        "print(f\"Number of Hidden Layers: {hidden_layers}\")\n",
        "print(f\"Epochs: {epochs}\")\n",
        "print(f\"Number of Experiments: {No_exp}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A00eqkeT5-3S",
        "outputId": "f43448e6-9243-4a50-e4b6-fb960017031b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[25 25 25 30 35 40]\n",
            " [25 25 30 35 40 40]\n",
            " [25 30 35 40 40 40]\n",
            " [30 35 40 40 40 40]\n",
            " [35 40 40 40 40 40]\n",
            " [40 40 40 40 40 40]\n",
            " [40 40 40 40 40 40]\n",
            " [40 40 40 40 40 40]\n",
            " [40 40 40 40 40 40]\n",
            " [40 40 40 40 40 35]\n",
            " [40 40 40 40 35 35]\n",
            " [40 40 40 35 35 40]\n",
            " [40 40 35 35 40 40]\n",
            " [40 35 35 40 40 40]\n",
            " [35 35 40 40 40 40]\n",
            " [35 40 40 40 40 40]\n",
            " [40 40 40 40 40 35]\n",
            " [40 40 40 40 35 35]\n",
            " [40 40 40 35 35 40]\n",
            " [40 40 35 35 40 45]\n",
            " [40 35 35 40 45 45]\n",
            " [35 35 40 45 45 50]\n",
            " [35 40 45 45 50 50]\n",
            " [40 45 45 50 50 55]\n",
            " [45 45 50 50 55 55]\n",
            " [45 50 50 55 55 50]\n",
            " [50 50 55 55 50 55]\n",
            " [50 55 55 50 55 60]\n",
            " [55 55 50 55 60 65]\n",
            " [55 50 55 60 65 65]\n",
            " [50 55 60 65 65 65]\n",
            " [55 60 65 65 65 60]\n",
            " [60 65 65 65 60 50]\n",
            " [65 65 65 60 50 45]\n",
            " [65 65 60 50 45 45]\n",
            " [65 60 50 45 45 40]\n",
            " [60 50 45 45 40 40]\n",
            " [50 45 45 40 40 35]\n",
            " [45 45 40 40 35 35]\n",
            " [45 40 40 35 35 30]\n",
            " [40 40 35 35 30 30]]\n"
          ]
        }
      ],
      "source": [
        "# Initialize variables\n",
        "cyclone_id = df['No. of Cycl'][0]\n",
        "X = []\n",
        "Y = []\n",
        "start_index = 0\n",
        "end_index = 0\n",
        "\n",
        "# Iterate through the DataFrame\n",
        "for i in range(1, df.shape[0]):\n",
        "    # Check if the cyclone ID is the same as the previous row\n",
        "    if df['No. of Cycl'][i] == cyclone_id:\n",
        "        end_index += 1\n",
        "    else:\n",
        "        # Split the sequence and append to X and Y\n",
        "        x, y = uni_split_sequence(speed[start_index:end_index + 1], n_steps_in)\n",
        "        X.append(x)\n",
        "        Y.append(y)\n",
        "\n",
        "        # Update start and end indices for the new cyclone\n",
        "        cyclone_id = df['No. of Cycl'][i]\n",
        "        start_index = i\n",
        "        end_index = i\n",
        "\n",
        "    # Check if it's the last row of the DataFrame\n",
        "    if i == df.shape[0] - 1:\n",
        "        # Split the sequence and append to X and Y\n",
        "        x, y = uni_split_sequence(speed[start_index:end_index + 1], n_steps_in)\n",
        "        X.append(x)\n",
        "        Y.append(y)\n",
        "print(X[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGCUDLJF6BMz"
      },
      "outputs": [],
      "source": [
        "# Initialize variables\n",
        "cyclone_id = df['No. of Cycl'][0]\n",
        "X_lat = []\n",
        "Y_lat = []\n",
        "start_index_lat = 0\n",
        "end_index_lat = 0\n",
        "\n",
        "# Iterate through the DataFrame\n",
        "for i in range(1, df.shape[0]):\n",
        "    # Check if the cyclone ID is the same as the previous row\n",
        "    if df['No. of Cycl'][i] == cyclone_id:\n",
        "        end_index_lat += 1\n",
        "    else:\n",
        "        # Split the sequence and append to X_lat and Y_lat\n",
        "        x_lat, y_lat = uni_split_sequence(latitude[start_index_lat:end_index_lat + 1], n_steps_in)\n",
        "        X_lat.append(x_lat)\n",
        "        Y_lat.append(y_lat)\n",
        "\n",
        "        # Update start and end indices for the new cyclone\n",
        "        cyclone_id = df['No. of Cycl'][i]\n",
        "        start_index_lat = i\n",
        "        end_index_lat = i\n",
        "\n",
        "    # Check if it's the last row of the DataFrame\n",
        "    if i == df.shape[0] - 1:\n",
        "        # Split the sequence and append to X_lat and Y_lat\n",
        "        x_lat, y_lat = uni_split_sequence(latitude[start_index_lat:end_index_lat + 1], n_steps_in)\n",
        "        X_lat.append(x_lat)\n",
        "        Y_lat.append(y_lat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weya7rFI6D1R"
      },
      "outputs": [],
      "source": [
        "# Initialize variables\n",
        "cyclone_id = df['No. of Cycl'][0]\n",
        "X_lon = []\n",
        "Y_lon = []\n",
        "start_index_lon = 0\n",
        "end_index_lon = 0\n",
        "\n",
        "# Iterate through the DataFrame\n",
        "for i in range(1, df.shape[0]):\n",
        "    # Check if the cyclone ID is the same as the previous row\n",
        "    if df['No. of Cycl'][i] == cyclone_id:\n",
        "        end_index_lon += 1\n",
        "    else:\n",
        "        # Split the sequence and append to X_lon and Y_lon\n",
        "        x_lon, y_lon = uni_split_sequence(longitude[start_index_lon:end_index_lon + 1], n_steps_in)\n",
        "        X_lon.append(x_lon)\n",
        "        Y_lon.append(y_lon)\n",
        "\n",
        "        # Update start and end indices for the new cyclone\n",
        "        cyclone_id = df['No. of Cycl'][i]\n",
        "        start_index_lon = i\n",
        "        end_index_lon = i\n",
        "\n",
        "    # Check if it's the last row of the DataFrame\n",
        "    if i == df.shape[0] - 1:\n",
        "        # Split the sequence and append to X_lon and Y_lon\n",
        "        x_lon, y_lon = uni_split_sequence(longitude[start_index_lon:end_index_lon + 1], n_steps_in)\n",
        "        X_lon.append(x_lon)\n",
        "        Y_lon.append(y_lon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBTOx8NP6GIY",
        "outputId": "d45ee8af-6c7e-49f1-8b83-a1231a307d18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "391 391\n",
            "9697 9697\n",
            "[25 25 25 30 35 40] 40 [25 25 30 35 40 40] 40\n",
            "[25, 25, 25, 30, 35, 40, 40, 40, 40, 40]\n"
          ]
        }
      ],
      "source": [
        "# Print the initial lengths of X and Y\n",
        "print(len(X), len(Y))\n",
        "# Flattening X and Y\n",
        "X = [item for sublist in X for item in sublist]\n",
        "Y = [item for sublist in Y for item in sublist]\n",
        "#Print lengths of X and Y after flattening\n",
        "print(len(X), len(Y))\n",
        "print(X[0], Y[0], X[1], Y[1])\n",
        "print(speed[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFyPhkdb6H9F",
        "outputId": "94843bd0-d311-49a8-de03-77889db02a31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "391 391\n",
            "9697 9697\n",
            "[18.  19.1 19.7 19.9 20.1 20.4] 20.700000000000003 [19.1 19.7 19.9 20.1 20.4 20.7] 21.0\n",
            "[18.0, 19.1, 19.700000000000003, 19.900000000000002, 20.1, 20.400000000000002, 20.700000000000003, 21.0, 21.200000000000003, 21.5]\n"
          ]
        }
      ],
      "source": [
        "# Print the initial lengths of X_lat and Y_lat\n",
        "print(len(X_lat), len(Y_lat))\n",
        "\n",
        "# Flattening X_lat and Y_lat\n",
        "X_lat = [item for sublist in X_lat for item in sublist]\n",
        "Y_lat = [item for sublist in Y_lat for item in sublist]\n",
        "\n",
        "# Print lengths of X_lat and Y_lat after flattening\n",
        "print(len(X_lat), len(Y_lat))\n",
        "print(X_lat[0], Y_lat[0], X_lat[1], Y_lat[1])\n",
        "print(latitude[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuZLAQyjFms7",
        "outputId": "c5b025ee-a16e-4a26-84fb-3f916c6ace99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "391 391\n",
            "9697 9697\n",
            "[154.1 154.8 155.7 156.7 157.8 158.6] 159.10000000000002 [154.8 155.7 156.7 157.8 158.6 159.1] 159.5\n",
            "[154.10000000000002, 154.8, 155.70000000000002, 156.70000000000002, 157.8, 158.60000000000002, 159.10000000000002, 159.5, 159.60000000000002, 159.5]\n"
          ]
        }
      ],
      "source": [
        "# Print the initial lengths of X_lat and Y_lat\n",
        "print(len(X_lon), len(Y_lon))\n",
        "\n",
        "# Flattening X_lat and Y_lat\n",
        "X_lon = [item for sublist in X_lon for item in sublist]\n",
        "Y_lon = [item for sublist in Y_lon for item in sublist]\n",
        "\n",
        "# Print lengths of X_lat and Y_lat after flattening\n",
        "print(len(X_lon), len(Y_lon))\n",
        "print(X_lon[0], Y_lon[0], X_lon[1], Y_lon[1])\n",
        "print(longitude[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRS59-TA6J63",
        "outputId": "e8449a0a-3d93-4166-a9e7-d929b6efbfd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9697\n"
          ]
        }
      ],
      "source": [
        "# Initialize 'intensify_y' with zeros\n",
        "intensify_y = [0] * len(X)\n",
        "\n",
        "# Iterate through each row in X and update intensify_y based on the condition\n",
        "for i in range(len(X)):\n",
        "    for j in range(len(X[0]) - 4, len(X[0])):\n",
        "        if (Y[i] - X[i][j]) >= 30:\n",
        "            intensify_y[i] = 1\n",
        "            break\n",
        "\n",
        "print(len(intensify_y))\n",
        "\n",
        "# Use 'intensify_y' as the updated target variable\n",
        "Y = intensify_y\n",
        "Y_lon = intensify_y\n",
        "Y_lat = intensify_y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiaJU9O86O_W",
        "outputId": "94ba1e55-6248-4b9c-a154-c38cb0ddf6e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Limit: 7272\n"
          ]
        }
      ],
      "source": [
        "# Calculate the training limit as 75% of the total length of X\n",
        "train_limit = int(len(X) * 0.75)\n",
        "\n",
        "# Display the calculated training limit\n",
        "print(\"Training Limit:\", train_limit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngkjGn-36VDZ",
        "outputId": "82f3a361-da4d-462b-f403-cf16ac0a9153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Limit (Latitude): 7272\n"
          ]
        }
      ],
      "source": [
        "# Calculate the training limit based on latitude\n",
        "train_limit_lat = int(len(X_lat) * 0.75)\n",
        "\n",
        "# Display the calculated training limit for latitude\n",
        "print(\"Training Limit (Latitude):\", train_limit_lat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHCKBCS26XCd",
        "outputId": "d892ea89-7c24-45a6-9fac-0480fae75e89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Limit (Longitude): 7272\n"
          ]
        }
      ],
      "source": [
        "# Calculate the training limit based on longitude\n",
        "train_limit_lon = int(len(X_lon) * 0.75)\n",
        "\n",
        "# Display the calculated training limit for longitude\n",
        "print(\"Training Limit (Longitude):\", train_limit_lon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsLUBUNr6Y11",
        "outputId": "8ce8b350-628e-4f57-f751-ebeabf48071b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of X: 9697\n",
            "Length of Y: 9697\n",
            "Length of Test X (for evaluation): 2424\n",
            "Length of Test Y (for evaluation): 2424\n"
          ]
        }
      ],
      "source": [
        "# Extract test data for evaluation\n",
        "test_X_original = X[train_limit + 1:]\n",
        "test_Y_original = Y[train_limit + 1:]\n",
        "\n",
        "# Display the lengths of the datasets\n",
        "print(\"Length of X:\", len(X))\n",
        "print(\"Length of Y:\", len(Y))\n",
        "print(\"Length of Test X (for evaluation):\", len(test_X_original))\n",
        "print(\"Length of Test Y (for evaluation):\", len(test_Y_original))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnH5kla26a1Z",
        "outputId": "aa8ea9b9-f990-4e75-fa28-bb523317fd81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of X (Latitude): 9697\n",
            "Length of Y (Latitude): 9697\n",
            "Length of Test X (for evaluation, Latitude): 2424\n",
            "Length of Test Y (for evaluation, Latitude): 2424\n"
          ]
        }
      ],
      "source": [
        "# Extract test data for evaluation based on latitude\n",
        "test_X_original_lat = X_lat[train_limit_lat + 1:]\n",
        "test_Y_original_lat = Y_lat[train_limit_lat + 1:]\n",
        "\n",
        "# Display the lengths of the datasets for latitude\n",
        "print(\"Length of X (Latitude):\", len(X_lat))\n",
        "print(\"Length of Y (Latitude):\", len(Y_lat))\n",
        "print(\"Length of Test X (for evaluation, Latitude):\", len(test_X_original_lat))\n",
        "print(\"Length of Test Y (for evaluation, Latitude):\", len(test_Y_original_lat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7FGZoZ86dXc",
        "outputId": "306d9db8-06c1-4089-c4c3-184e9194325c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of X (Longitude): 9697\n",
            "Length of Y (Longitude): 9697\n",
            "Length of Test X (for evaluation, Longitude): 2424\n",
            "Length of Test Y (for evaluation, Longitude): 2424\n"
          ]
        }
      ],
      "source": [
        "# Extract test data for evaluation based on longitude\n",
        "test_X_original_lon = X_lon[train_limit_lon + 1:]\n",
        "test_Y_original_lon = Y_lon[train_limit_lon + 1:]\n",
        "\n",
        "# Display the lengths of the datasets for longitude\n",
        "print(\"Length of X (Longitude):\", len(X_lon))\n",
        "print(\"Length of Y (Longitude):\", len(Y_lon))\n",
        "print(\"Length of Test X (for evaluation, Longitude):\", len(test_X_original_lon))\n",
        "print(\"Length of Test Y (for evaluation, Longitude):\", len(test_Y_original_lon))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpuJ3u3v6geo"
      },
      "outputs": [],
      "source": [
        "# Normalize the sequences in X using Min-Max scaling\n",
        "X = MinMaxScaler().fit_transform(np.asarray(X))\n",
        "# Apply MinMaxScaler to latitude\n",
        "X_lat = MinMaxScaler().fit_transform(np.asarray(X_lat))\n",
        "# Apply MinMaxScaler to longitude\n",
        "X_lon = MinMaxScaler().fit_transform(np.asarray(X_lon))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9K-Yp8H6izm",
        "outputId": "d1a6f2c2-db62-4e7c-b618-6a32ad42a881"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(7272, 7272)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the original X (speed) values before splitting\n",
        "speed_x = X\n",
        "test_X = X[train_limit+1:]\n",
        "test_X = np.asarray(test_X).astype(float)\n",
        "test_Y = Y[train_limit+1:]\n",
        "X = X[:train_limit]\n",
        "X = np.asarray(X).astype(float)\n",
        "Y = Y[:train_limit]\n",
        "print(test_Y)\n",
        "len(X), len(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WX2vcy0h6k7V",
        "outputId": "a17f1f1b-d9e3-46dc-f70b-fe8e80844b64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7272, 7272)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Assign latitude data to latitude_x\n",
        "latitude_x = X_lat\n",
        "\n",
        "# Extract test data for latitude\n",
        "test_X_lat = X_lat[train_limit_lat + 1:]\n",
        "test_X_lat = np.asarray(test_X_lat).astype(float)\n",
        "test_Y_lat = Y_lat[train_limit_lat + 1:]\n",
        "X_lat = X_lat[:train_limit_lat]\n",
        "X_lat = np.asarray(X_lat).astype(float)\n",
        "Y_lat = Y_lat[:train_limit_lat]\n",
        "test_Y_lat\n",
        "len(X_lat), len(Y_lat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUwNJ4bQ6nQf",
        "outputId": "d281b195-6fbd-40c3-ae8d-1b822c1d48c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7272, 7272)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Assign latitude data to latitude_x\n",
        "longitude_x = X_lon\n",
        "\n",
        "# Extract test data for latitude\n",
        "test_X_lon = X_lon[train_limit_lon + 1:]\n",
        "test_X_lon = np.asarray(test_X_lon).astype(float)\n",
        "test_Y_lon = Y_lon[train_limit_lon + 1:]\n",
        "X_lon = X_lon[:train_limit_lat]\n",
        "X_lon = np.asarray(X_lon).astype(float)\n",
        "Y_lon = Y_lon[:train_limit_lon]\n",
        "test_Y_lon\n",
        "len(X_lon), len(Y_lon)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpEZKMO_6pSs",
        "outputId": "1d4a97f9-8445-44ee-dd1c-f97a983e7da9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Distribution - Training Data:\n",
            "Counter({0: 6897, 1: 375})\n",
            "\n",
            "Class Distribution - Test Data:\n",
            "Counter({0: 2396, 1: 28})\n"
          ]
        }
      ],
      "source": [
        "# Calculate the class distribution for training and test data\n",
        "counter_train = Counter(Y)\n",
        "counter_test = Counter(test_Y)\n",
        "\n",
        "# Display the class distribution for training data\n",
        "print(\"Class Distribution - Training Data:\")\n",
        "print(counter_train)\n",
        "\n",
        "# Display the class distribution for test data\n",
        "print(\"\\nClass Distribution - Test Data:\")\n",
        "print(counter_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hnZDkm66rSm",
        "outputId": "a70d4787-038d-46b6-f76d-1007e2ecf207"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Distribution - Training Data (Latitude):\n",
            "Counter({0: 6897, 1: 375})\n",
            "\n",
            "Class Distribution - Test Data (Latitude):\n",
            "Counter({0: 2396, 1: 28})\n"
          ]
        }
      ],
      "source": [
        "# Calculate the class distribution for training and test data for latitude\n",
        "counter_train_lat = Counter(Y_lat)\n",
        "counter_test_lat = Counter(test_Y_lat)\n",
        "\n",
        "# Display the class distribution for training data for latitude\n",
        "print(\"Class Distribution - Training Data (Latitude):\")\n",
        "print(counter_train_lat)\n",
        "\n",
        "# Display the class distribution for test data for latitude\n",
        "print(\"\\nClass Distribution - Test Data (Latitude):\")\n",
        "print(counter_test_lat)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yepr6Tbi6tRi",
        "outputId": "c5dc0519-0854-4a18-91c5-df7b8faeeaaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Distribution - Training Data (Longitude):\n",
            "Counter({0: 6897, 1: 375})\n",
            "\n",
            "Class Distribution - Test Data (Longitude):\n",
            "Counter({0: 2396, 1: 28})\n"
          ]
        }
      ],
      "source": [
        "# Calculate the class distribution for training and test data for longitude\n",
        "counter_train_lon = Counter(Y_lon)\n",
        "counter_test_lon = Counter(test_Y_lon)\n",
        "\n",
        "# Display the class distribution for training data for longitude\n",
        "print(\"Class Distribution - Training Data (Longitude):\")\n",
        "print(counter_train_lon)\n",
        "\n",
        "# Display the class distribution for test data for longitude\n",
        "print(\"\\nClass Distribution - Test Data (Longitude):\")\n",
        "print(counter_test_lon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZzxLLxs6x9K"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, concatenate\n",
        "\n",
        "\n",
        "def stacked_lstm(n_steps_in, n_features_in):\n",
        "    input_1 = Input(shape=(n_steps_in, n_features_in))\n",
        "    lstm_1 = LSTM(50, activation='relu')(input_1)\n",
        "\n",
        "    input_2 = Input(shape=(n_steps_in, n_features_in))\n",
        "    lstm_2 = LSTM(50, activation='relu')(input_2)\n",
        "\n",
        "    input_3 = Input(shape=(n_steps_in, n_features_in))\n",
        "    lstm_3 = LSTM(50, activation='relu')(input_3)\n",
        "\n",
        "    concat = concatenate([lstm_1, lstm_2, lstm_3])\n",
        "    output = Dense(2, activation='softmax')(concat)\n",
        "\n",
        "    model = Model(inputs=[input_1, input_2, input_3], outputs=output)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvqrguvH60by"
      },
      "outputs": [],
      "source": [
        "n_features_in_speed = 1\n",
        "n_features_in_latitude = 1\n",
        "n_features_in_longitude = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhch-3lu62Wr"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import time\n",
        "\n",
        "def lstm(stacked_model,  x_train_lat, x_train_lon, x_train, y_train, x_test_lat, x_test_lon, x_test, y_test, Num_Exp, n_steps_in, n_steps_out, Epochs):\n",
        "    # Initialize arrays to store accuracy metrics\n",
        "    train_acc = np.zeros(Num_Exp)\n",
        "    test_acc = np.zeros(Num_Exp)\n",
        "\n",
        "    # Initialize arrays to store predictions and classification reports\n",
        "    y_predicttest_allruns = np.zeros([Num_Exp, x_test_lat.shape[0], y_test.shape[1]])\n",
        "    Best_f1 = 0  # Initialize the best F1 score\n",
        "    Best_Predict_Test = 0\n",
        "\n",
        "    # Extract the actual classes from one-hot encoded vectors for both test and train sets\n",
        "    act_test = [y_test[i].argmax() for i in range(y_test.shape[0])]\n",
        "    act_train = [y_train[i].argmax() for i in range(y_train.shape[0])]\n",
        "\n",
        "    # Initialize dictionaries to store classification reports\n",
        "    Best_report_train = dict()\n",
        "    Best_report_test = dict()\n",
        "    all_report_train = dict()\n",
        "    all_report_test = dict()\n",
        "\n",
        "    # Loop through experiment runs\n",
        "    start_time = time.time()\n",
        "    for run in range(Num_Exp):\n",
        "        print(\"Experiment\", run + 1, \"in progress\")\n",
        "\n",
        "        # Fit the stacked model\n",
        "        stacked_model.fit([x_train_lat, x_train_lon, x_train], y_train, epochs=Epochs, batch_size=10, verbose=1, shuffle=False)\n",
        "        y_predicttrain = stacked_model.predict([x_train_lat, x_train_lon, x_train])\n",
        "        y_predicttest = stacked_model.predict([x_test_lat, x_test_lon, x_test])\n",
        "        print(y_predicttrain[0])\n",
        "        print(y_predicttest[0])\n",
        "\n",
        "        # Extract predicted classes from one-hot encoded vectors\n",
        "        pred_test = [y_predicttest[i].argmax() for i in range(y_predicttest.shape[0])]\n",
        "        pred_train = [y_predicttrain[i].argmax() for i in range(y_predicttrain.shape[0])]\n",
        "\n",
        "        c = 0\n",
        "        for i in pred_test:\n",
        "          if(i==1):\n",
        "            c = c+1\n",
        "        print(c)\n",
        "        d = 0\n",
        "        for i in pred_train:\n",
        "          if(i==1):\n",
        "            d = d+1\n",
        "        print(d)\n",
        "\n",
        "\n",
        "        # Generate classification reports\n",
        "        report_train = classification_report(act_train, pred_train, labels=[0, 1], output_dict=True)\n",
        "        report_test = classification_report(act_test, pred_test, labels=[0, 1], output_dict=True)\n",
        "\n",
        "        # Store classification reports in dictionaries\n",
        "        all_report_train[run] = report_train\n",
        "        all_report_test[run] = report_test\n",
        "\n",
        "        # Calculate F1-score for the test set\n",
        "        train_acc[run] = report_train['1']['f1-score']\n",
        "        test_acc[run] = report_test['1']['f1-score']\n",
        "        print(\"train acc: \", train_acc[run])\n",
        "        print(\"test acc: \", test_acc[run])\n",
        "\n",
        "    # Update the best F1 score and associated predictions and reports\n",
        "    if test_acc[run] > Best_f1:\n",
        "        Best_f1 = test_acc[run]\n",
        "        Best_Predict_Test = y_predicttest\n",
        "        Best_report_train, Best_report_test = report_train, report_test\n",
        "\n",
        "    # Save the trained model (assuming you have the 'ocean' variable)\n",
        "    stacked_model.save(\"model_\" + ocean + \"_stacked_lstm.h5\")\n",
        "\n",
        "    # Calculate standard deviations of train and test accuracies\n",
        "    train_std = np.std(train_acc)\n",
        "    test_std = np.std(test_acc)\n",
        "\n",
        "    # Display experiment summary\n",
        "    print(\"Total time for\", Num_Exp, \"experiments\", time.time() - start_time)\n",
        "    print(\"F1 scores for test data: \", test_acc)\n",
        "    print(\"Mean: \", np.mean(test_acc), \"Std Dev: \", test_std)\n",
        "\n",
        "    # Return relevant information\n",
        "    return train_acc, test_acc, train_std, test_std, Best_Predict_Test, y_predicttrain, y_predicttest, all_report_train, all_report_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF1RHzVH66oI",
        "outputId": "76003612-9ac9-47d9-847e-a13395b7bbc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7272\n"
          ]
        }
      ],
      "source": [
        "# Create a random permutation of indices for shuffling\n",
        "# idx = np.random.permutation(len(X_smote))\n",
        "idx = np.random.permutation(len(X))\n",
        "print(len(idx))\n",
        "\n",
        "# Initialize lists to store shuffled data\n",
        "x_shuffled = []\n",
        "y_shuffled = []\n",
        "\n",
        "# Iterate through the shuffled indices\n",
        "for i in idx:\n",
        "    # Append shuffled data to the lists\n",
        "    # x_shuffled.append(X_smote[i])\n",
        "    # y_shuffled.append(Y_smote[i])\n",
        "    x_shuffled.append(X[i])\n",
        "    y_shuffled.append(Y[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFgBndlc69uU",
        "outputId": "84e00c96-c220-43a0-b96e-5351caa578a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7272\n"
          ]
        }
      ],
      "source": [
        "# Create a random permutation of indices for shuffling\n",
        "# idx = np.random.permutation(len(X_smote))\n",
        "idx = np.random.permutation(len(X_lat))\n",
        "print(len(idx))\n",
        "\n",
        "# Initialize lists to store shuffled data\n",
        "x_shuffled_lat = []\n",
        "y_shuffled_lat = []\n",
        "\n",
        "# Iterate through the shuffled indices\n",
        "for i in idx:\n",
        "    # Append shuffled data to the lists\n",
        "    # x_shuffled.append(X_smote[i])\n",
        "    # y_shuffled.append(Y_smote[i])\n",
        "    x_shuffled_lat.append(X_lat[i])\n",
        "    y_shuffled_lat.append(Y_lat[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnEFMTSv6_lj",
        "outputId": "bb668fb8-9170-4bbd-b958-eebd160dc870"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7272\n"
          ]
        }
      ],
      "source": [
        "# Create a random permutation of indices for shuffling\n",
        "# idx = np.random.permutation(len(X_smote))\n",
        "idx = np.random.permutation(len(X_lon))\n",
        "print(len(idx))\n",
        "\n",
        "# Initialize lists to store shuffled data\n",
        "x_shuffled_lon = []\n",
        "y_shuffled_lon = []\n",
        "\n",
        "# Iterate through the shuffled indices\n",
        "for i in idx:\n",
        "    # Append shuffled data to the lists\n",
        "    # x_shuffled.append(X_smote[i])\n",
        "    # y_shuffled.append(Y_smote[i])\n",
        "    x_shuffled_lon.append(X_lon[i])\n",
        "    y_shuffled_lon.append(Y_lon[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUq8_EBA7B7U",
        "outputId": "9aab38b8-2a27-441e-f31d-7c03f5b44f7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7272, 2) (2424, 2)\n"
          ]
        }
      ],
      "source": [
        "# Convert the shuffled labels to one-hot encoded format for training data\n",
        "Y_hot_encoded_train = np.asarray(to_categorical(y_shuffled))\n",
        "\n",
        "# Convert the test labels to one-hot encoded format\n",
        "Y_hot_encoded_test = np.asarray(to_categorical(test_Y))\n",
        "\n",
        "# Print the shapes of the one-hot encoded training and test labels\n",
        "print(Y_hot_encoded_train.shape, Y_hot_encoded_test.shape)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thHIjzH-7DzN",
        "outputId": "5ef1a287-a403-4c32-dd3f-9364e845083d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1., 0.])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_hot_encoded_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAGr3izb7JuE",
        "outputId": "5fb22d57-e62c-4ca4-f561-f4f959a51610"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7272, 2) (2424, 2)\n"
          ]
        }
      ],
      "source": [
        "Y_hot_encoded_train_lat = np.asarray(to_categorical(y_shuffled_lat))\n",
        "\n",
        "# Convert the test labels to one-hot encoded format\n",
        "Y_hot_encoded_test_lat = np.asarray(to_categorical(test_Y_lat))\n",
        "\n",
        "# Print the shapes of the one-hot encoded training and test labels\n",
        "print(Y_hot_encoded_train_lat.shape, Y_hot_encoded_test_lat.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0dM2ZhT7Lg3",
        "outputId": "c6167e57-340c-4c4c-bb1e-ef65b4c5299c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7272, 2) (2424, 2)\n"
          ]
        }
      ],
      "source": [
        "Y_hot_encoded_train_lon = np.asarray(to_categorical(y_shuffled_lon))\n",
        "\n",
        "# Convert the test labels to one-hot encoded format\n",
        "Y_hot_encoded_test_lon = np.asarray(to_categorical(test_Y_lon))\n",
        "\n",
        "# Print the shapes of the one-hot encoded training and test labels\n",
        "print(Y_hot_encoded_train_lon.shape, Y_hot_encoded_test_lon.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3ufMyhb7VhP"
      },
      "outputs": [],
      "source": [
        "predictions_train = dict()\n",
        "actual_train = dict()\n",
        "predictions_test = dict()\n",
        "actual_test = dict()\n",
        "metrics_train = dict()\n",
        "metrics_test = dict()\n",
        "test_acc_all = dict()\n",
        "test_stddev = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEnhZp4P7YVf",
        "outputId": "33080564-877f-4ed1-b0f0-fe1d85ff27c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------\n",
            "Number of steps out: 1\n",
            "Experiment 1 in progress\n",
            "Epoch 1/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9403 - loss: 0.2961\n",
            "Epoch 2/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9496 - loss: 0.1934\n",
            "Epoch 3/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9496 - loss: 0.1691\n",
            "Epoch 4/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9497 - loss: 0.1497\n",
            "Epoch 5/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9515 - loss: 0.1381\n",
            "Epoch 6/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9508 - loss: 0.1293\n",
            "Epoch 7/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9521 - loss: 0.1227\n",
            "Epoch 8/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9547 - loss: 0.1177\n",
            "Epoch 9/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.9554 - loss: 0.1135\n",
            "Epoch 10/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9581 - loss: 0.1099\n",
            "Epoch 11/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9590 - loss: 0.1065\n",
            "Epoch 12/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9596 - loss: 0.1031\n",
            "Epoch 13/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9615 - loss: 0.0998\n",
            "Epoch 14/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9631 - loss: 0.0963\n",
            "Epoch 15/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9649 - loss: 0.0930\n",
            "Epoch 16/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.0898\n",
            "Epoch 17/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9681 - loss: 0.0872\n",
            "Epoch 18/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9675 - loss: 0.0845\n",
            "Epoch 19/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9673 - loss: 0.0826\n",
            "Epoch 20/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9687 - loss: 0.0812\n",
            "Epoch 21/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9690 - loss: 0.0797\n",
            "Epoch 22/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9697 - loss: 0.0786\n",
            "Epoch 23/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9707 - loss: 0.0780\n",
            "Epoch 24/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.0770\n",
            "Epoch 25/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9702 - loss: 0.0762\n",
            "Epoch 26/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9706 - loss: 0.0756\n",
            "Epoch 27/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9718 - loss: 0.0749\n",
            "Epoch 28/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9703 - loss: 0.0746\n",
            "Epoch 29/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9706 - loss: 0.0740\n",
            "Epoch 30/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9705 - loss: 0.0736\n",
            "Epoch 31/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9706 - loss: 0.0733\n",
            "Epoch 32/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9702 - loss: 0.0728\n",
            "Epoch 33/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9707 - loss: 0.0727\n",
            "Epoch 34/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9714 - loss: 0.0723\n",
            "Epoch 35/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9710 - loss: 0.0720\n",
            "Epoch 36/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9712 - loss: 0.0717\n",
            "Epoch 37/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9713 - loss: 0.0713\n",
            "Epoch 38/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9711 - loss: 0.0712\n",
            "Epoch 39/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9713 - loss: 0.0709\n",
            "Epoch 40/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9713 - loss: 0.0708\n",
            "Epoch 41/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9716 - loss: 0.0706\n",
            "Epoch 42/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9710 - loss: 0.0704\n",
            "Epoch 43/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9715 - loss: 0.0704\n",
            "Epoch 44/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9715 - loss: 0.0699\n",
            "Epoch 45/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9717 - loss: 0.0700\n",
            "Epoch 46/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9713 - loss: 0.0697\n",
            "Epoch 47/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9716 - loss: 0.0694\n",
            "Epoch 48/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9722 - loss: 0.0691\n",
            "Epoch 49/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9720 - loss: 0.0689\n",
            "Epoch 50/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9730 - loss: 0.0687\n",
            "Epoch 51/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9735 - loss: 0.0688\n",
            "Epoch 52/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9724 - loss: 0.0684\n",
            "Epoch 53/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9729 - loss: 0.0683\n",
            "Epoch 54/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9742 - loss: 0.0686\n",
            "Epoch 55/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9730 - loss: 0.0680\n",
            "Epoch 56/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9733 - loss: 0.0678\n",
            "Epoch 57/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9737 - loss: 0.0677\n",
            "Epoch 58/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9743 - loss: 0.0679\n",
            "Epoch 59/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9743 - loss: 0.0676\n",
            "Epoch 60/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9745 - loss: 0.0676\n",
            "Epoch 61/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9736 - loss: 0.0671\n",
            "Epoch 62/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9739 - loss: 0.0668\n",
            "Epoch 63/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9746 - loss: 0.0671\n",
            "Epoch 64/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9749 - loss: 0.0671\n",
            "Epoch 65/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9743 - loss: 0.0665\n",
            "Epoch 66/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9745 - loss: 0.0667\n",
            "Epoch 67/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9750 - loss: 0.0669\n",
            "Epoch 68/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9749 - loss: 0.0664\n",
            "Epoch 69/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9745 - loss: 0.0660\n",
            "Epoch 70/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9751 - loss: 0.0662\n",
            "Epoch 71/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9751 - loss: 0.0659\n",
            "Epoch 72/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9747 - loss: 0.0654\n",
            "Epoch 73/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9754 - loss: 0.0657\n",
            "Epoch 74/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9746 - loss: 0.0652\n",
            "Epoch 75/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9749 - loss: 0.0652\n",
            "Epoch 76/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9755 - loss: 0.0653\n",
            "Epoch 77/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9754 - loss: 0.0651\n",
            "Epoch 78/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9754 - loss: 0.0655\n",
            "Epoch 79/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9758 - loss: 0.0649\n",
            "Epoch 80/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9752 - loss: 0.0644\n",
            "Epoch 81/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9756 - loss: 0.0644\n",
            "Epoch 82/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9754 - loss: 0.0642\n",
            "Epoch 83/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9757 - loss: 0.0640\n",
            "Epoch 84/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9758 - loss: 0.0638\n",
            "Epoch 85/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9759 - loss: 0.0639\n",
            "Epoch 86/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9753 - loss: 0.0630\n",
            "Epoch 87/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9757 - loss: 0.0632\n",
            "Epoch 88/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9759 - loss: 0.0629\n",
            "Epoch 89/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9761 - loss: 0.0625\n",
            "Epoch 90/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9764 - loss: 0.0620\n",
            "Epoch 91/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9753 - loss: 0.0619\n",
            "Epoch 92/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9752 - loss: 0.0615\n",
            "Epoch 93/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9769 - loss: 0.0612\n",
            "Epoch 94/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9764 - loss: 0.0611\n",
            "Epoch 95/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9765 - loss: 0.0607\n",
            "Epoch 96/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9772 - loss: 0.0604\n",
            "Epoch 97/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9777 - loss: 0.0603\n",
            "Epoch 98/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9786 - loss: 0.0601\n",
            "Epoch 99/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9784 - loss: 0.0599\n",
            "Epoch 100/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9782 - loss: 0.0599\n",
            "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "[9.9999994e-01 1.4633344e-16]\n",
            "[9.9915987e-01 8.4005116e-04]\n",
            "60\n",
            "490\n",
            "train acc:  0.7514450867052023\n",
            "test acc:  0.36363636363636365\n",
            "Experiment 2 in progress\n",
            "Epoch 1/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9785 - loss: 0.0597\n",
            "Epoch 2/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9792 - loss: 0.0595\n",
            "Epoch 3/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9784 - loss: 0.0594\n",
            "Epoch 4/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9786 - loss: 0.0592\n",
            "Epoch 5/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9793 - loss: 0.0591\n",
            "Epoch 6/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9787 - loss: 0.0591\n",
            "Epoch 7/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9791 - loss: 0.0589\n",
            "Epoch 8/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9786 - loss: 0.0588\n",
            "Epoch 9/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9784 - loss: 0.0587\n",
            "Epoch 10/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9786 - loss: 0.0584\n",
            "Epoch 11/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9789 - loss: 0.0587\n",
            "Epoch 12/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9789 - loss: 0.0586\n",
            "Epoch 13/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9789 - loss: 0.0581\n",
            "Epoch 14/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9789 - loss: 0.0582\n",
            "Epoch 15/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9795 - loss: 0.0583\n",
            "Epoch 16/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9792 - loss: 0.0583\n",
            "Epoch 17/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9789 - loss: 0.0582\n",
            "Epoch 18/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9790 - loss: 0.0578\n",
            "Epoch 19/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9797 - loss: 0.0578\n",
            "Epoch 20/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9789 - loss: 0.0577\n",
            "Epoch 21/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9792 - loss: 0.0574\n",
            "Epoch 22/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9790 - loss: 0.0575\n",
            "Epoch 23/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9788 - loss: 0.0573\n",
            "Epoch 24/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9793 - loss: 0.0572\n",
            "Epoch 25/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9788 - loss: 0.0571\n",
            "Epoch 26/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9798 - loss: 0.0569\n",
            "Epoch 27/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9791 - loss: 0.0568\n",
            "Epoch 28/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9793 - loss: 0.0567\n",
            "Epoch 29/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9785 - loss: 0.0567\n",
            "Epoch 30/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9784 - loss: 0.0566\n",
            "Epoch 31/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9789 - loss: 0.0563\n",
            "Epoch 32/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9799 - loss: 0.0565\n",
            "Epoch 33/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9789 - loss: 0.0563\n",
            "Epoch 34/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9791 - loss: 0.0559\n",
            "Epoch 35/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9788 - loss: 0.0559\n",
            "Epoch 36/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9790 - loss: 0.0558\n",
            "Epoch 37/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9793 - loss: 0.0557\n",
            "Epoch 38/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9791 - loss: 0.0558\n",
            "Epoch 39/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9794 - loss: 0.0555\n",
            "Epoch 40/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9792 - loss: 0.0555\n",
            "Epoch 41/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9787 - loss: 0.0555\n",
            "Epoch 42/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9788 - loss: 0.0553\n",
            "Epoch 43/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9788 - loss: 0.0552\n",
            "Epoch 44/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9791 - loss: 0.0551\n",
            "Epoch 45/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9788 - loss: 0.0549\n",
            "Epoch 46/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9792 - loss: 0.0548\n",
            "Epoch 47/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9792 - loss: 0.0548\n",
            "Epoch 48/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9791 - loss: 0.0548\n",
            "Epoch 49/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9788 - loss: 0.0547\n",
            "Epoch 50/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9789 - loss: 0.0546\n",
            "Epoch 51/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9788 - loss: 0.0546\n",
            "Epoch 52/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9784 - loss: 0.0544\n",
            "Epoch 53/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9788 - loss: 0.0542\n",
            "Epoch 54/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9786 - loss: 0.0541\n",
            "Epoch 55/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9795 - loss: 0.0541\n",
            "Epoch 56/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9796 - loss: 0.0541\n",
            "Epoch 57/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9795 - loss: 0.0540\n",
            "Epoch 58/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9795 - loss: 0.0538\n",
            "Epoch 59/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9797 - loss: 0.0537\n",
            "Epoch 60/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9797 - loss: 0.0537\n",
            "Epoch 61/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9798 - loss: 0.0536\n",
            "Epoch 62/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9799 - loss: 0.0538\n",
            "Epoch 63/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9800 - loss: 0.0535\n",
            "Epoch 64/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9802 - loss: 0.0535\n",
            "Epoch 65/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9803 - loss: 0.0534\n",
            "Epoch 66/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9802 - loss: 0.0533\n",
            "Epoch 67/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9803 - loss: 0.0533\n",
            "Epoch 68/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9808 - loss: 0.0535\n",
            "Epoch 69/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9809 - loss: 0.0534\n",
            "Epoch 70/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9809 - loss: 0.0534\n",
            "Epoch 71/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9807 - loss: 0.0531\n",
            "Epoch 72/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9808 - loss: 0.0531\n",
            "Epoch 73/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9809 - loss: 0.0531\n",
            "Epoch 74/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9811 - loss: 0.0530\n",
            "Epoch 75/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9809 - loss: 0.0531\n",
            "Epoch 76/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9809 - loss: 0.0531\n",
            "Epoch 77/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9808 - loss: 0.0530\n",
            "Epoch 78/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9811 - loss: 0.0531\n",
            "Epoch 79/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9810 - loss: 0.0530\n",
            "Epoch 80/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9805 - loss: 0.0529\n",
            "Epoch 81/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9814 - loss: 0.0527\n",
            "Epoch 82/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9803 - loss: 0.0529\n",
            "Epoch 83/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9812 - loss: 0.0527\n",
            "Epoch 84/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9807 - loss: 0.0526\n",
            "Epoch 85/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9806 - loss: 0.0529\n",
            "Epoch 86/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9808 - loss: 0.0526\n",
            "Epoch 87/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9804 - loss: 0.0529\n",
            "Epoch 88/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9803 - loss: 0.0526\n",
            "Epoch 89/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9810 - loss: 0.0524\n",
            "Epoch 90/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9808 - loss: 0.0525\n",
            "Epoch 91/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9806 - loss: 0.0525\n",
            "Epoch 92/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9807 - loss: 0.0523\n",
            "Epoch 93/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9807 - loss: 0.0523\n",
            "Epoch 94/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9808 - loss: 0.0524\n",
            "Epoch 95/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9812 - loss: 0.0522\n",
            "Epoch 96/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9808 - loss: 0.0523\n",
            "Epoch 97/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9804 - loss: 0.0524\n",
            "Epoch 98/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9803 - loss: 0.0525\n",
            "Epoch 99/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9814 - loss: 0.0523\n",
            "Epoch 100/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9808 - loss: 0.0521\n",
            "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "[0.99999994 0.        ]\n",
            "[9.9999970e-01 2.7726009e-07]\n",
            "30\n",
            "321\n",
            "train acc:  0.7873563218390804\n",
            "test acc:  0.4482758620689655\n",
            "Experiment 3 in progress\n",
            "Epoch 1/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9804 - loss: 0.0522\n",
            "Epoch 2/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9806 - loss: 0.0521\n",
            "Epoch 3/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9804 - loss: 0.0519\n",
            "Epoch 4/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9806 - loss: 0.0521\n",
            "Epoch 5/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9809 - loss: 0.0519\n",
            "Epoch 6/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9808 - loss: 0.0520\n",
            "Epoch 7/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9802 - loss: 0.0518\n",
            "Epoch 8/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9806 - loss: 0.0519\n",
            "Epoch 9/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9804 - loss: 0.0519\n",
            "Epoch 10/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9810 - loss: 0.0519\n",
            "Epoch 11/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9806 - loss: 0.0517\n",
            "Epoch 12/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9809 - loss: 0.0517\n",
            "Epoch 13/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9810 - loss: 0.0518\n",
            "Epoch 14/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9808 - loss: 0.0517\n",
            "Epoch 15/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9805 - loss: 0.0520\n",
            "Epoch 16/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9806 - loss: 0.0518\n",
            "Epoch 17/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9811 - loss: 0.0514\n",
            "Epoch 18/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9814 - loss: 0.0515\n",
            "Epoch 19/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9818 - loss: 0.0513\n",
            "Epoch 20/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9818 - loss: 0.0514\n",
            "Epoch 21/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9817 - loss: 0.0512\n",
            "Epoch 22/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9821 - loss: 0.0511\n",
            "Epoch 23/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9812 - loss: 0.0514\n",
            "Epoch 24/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9814 - loss: 0.0513\n",
            "Epoch 25/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9815 - loss: 0.0512\n",
            "Epoch 26/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9815 - loss: 0.0513\n",
            "Epoch 27/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9810 - loss: 0.0512\n",
            "Epoch 28/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9813 - loss: 0.0512\n",
            "Epoch 29/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9813 - loss: 0.0507\n",
            "Epoch 30/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9818 - loss: 0.0509\n",
            "Epoch 31/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9825 - loss: 0.0515\n",
            "Epoch 32/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9815 - loss: 0.0509\n",
            "Epoch 33/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9817 - loss: 0.0512\n",
            "Epoch 34/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9816 - loss: 0.0509\n",
            "Epoch 35/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9814 - loss: 0.0513\n",
            "Epoch 36/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9817 - loss: 0.0512\n",
            "Epoch 37/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9809 - loss: 0.0513\n",
            "Epoch 38/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9819 - loss: 0.0508\n",
            "Epoch 39/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9820 - loss: 0.0507\n",
            "Epoch 40/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9822 - loss: 0.0511\n",
            "Epoch 41/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9813 - loss: 0.0509\n",
            "Epoch 42/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9805 - loss: 0.0521\n",
            "Epoch 43/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9817 - loss: 0.0503\n",
            "Epoch 44/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9820 - loss: 0.0507\n",
            "Epoch 45/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9814 - loss: 0.0510\n",
            "Epoch 46/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9819 - loss: 0.0502\n",
            "Epoch 47/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9821 - loss: 0.0501\n",
            "Epoch 48/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.9818 - loss: 0.0501\n",
            "Epoch 49/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9816 - loss: 0.0506\n",
            "Epoch 50/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9821 - loss: 0.0502\n",
            "Epoch 51/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9822 - loss: 0.0500\n",
            "Epoch 52/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9807 - loss: 0.0510\n",
            "Epoch 53/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9812 - loss: 0.0502\n",
            "Epoch 54/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9820 - loss: 0.0501\n",
            "Epoch 55/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9821 - loss: 0.0507\n",
            "Epoch 56/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9810 - loss: 0.0515\n",
            "Epoch 57/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9816 - loss: 0.0505\n",
            "Epoch 58/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9826 - loss: 0.0499\n",
            "Epoch 59/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9813 - loss: 0.0501\n",
            "Epoch 60/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9819 - loss: 0.0505\n",
            "Epoch 61/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9814 - loss: 0.0500\n",
            "Epoch 62/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9814 - loss: 0.0504\n",
            "Epoch 63/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9821 - loss: 0.0509\n",
            "Epoch 64/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9810 - loss: 0.0496\n",
            "Epoch 65/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9816 - loss: 0.0501\n",
            "Epoch 66/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9814 - loss: 0.0498\n",
            "Epoch 67/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9815 - loss: 0.0499\n",
            "Epoch 68/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9825 - loss: 0.0502\n",
            "Epoch 69/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9820 - loss: 0.0497\n",
            "Epoch 70/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9816 - loss: 0.0502\n",
            "Epoch 71/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9827 - loss: 0.0496\n",
            "Epoch 72/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9820 - loss: 0.0498\n",
            "Epoch 73/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9817 - loss: 0.0498\n",
            "Epoch 74/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9821 - loss: 0.0498\n",
            "Epoch 75/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9828 - loss: 0.0498\n",
            "Epoch 76/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9828 - loss: 0.0498\n",
            "Epoch 77/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9817 - loss: 0.0500\n",
            "Epoch 78/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9819 - loss: 0.0497\n",
            "Epoch 79/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9814 - loss: 0.0502\n",
            "Epoch 80/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.9829 - loss: 0.0496\n",
            "Epoch 81/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9829 - loss: 0.0493\n",
            "Epoch 82/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0497\n",
            "Epoch 83/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9817 - loss: 0.0496\n",
            "Epoch 84/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9832 - loss: 0.0499\n",
            "Epoch 85/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9823 - loss: 0.0497\n",
            "Epoch 86/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9829 - loss: 0.0492\n",
            "Epoch 87/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9818 - loss: 0.0491\n",
            "Epoch 88/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9829 - loss: 0.0488\n",
            "Epoch 89/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9829 - loss: 0.0489\n",
            "Epoch 90/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9822 - loss: 0.0490\n",
            "Epoch 91/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9830 - loss: 0.0489\n",
            "Epoch 92/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9831 - loss: 0.0489\n",
            "Epoch 93/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9837 - loss: 0.0486\n",
            "Epoch 94/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9833 - loss: 0.0486\n",
            "Epoch 95/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9811 - loss: 0.0496\n",
            "Epoch 96/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9823 - loss: 0.0502\n",
            "Epoch 97/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9832 - loss: 0.0478\n",
            "Epoch 98/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9822 - loss: 0.0480\n",
            "Epoch 99/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9824 - loss: 0.0487\n",
            "Epoch 100/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9833 - loss: 0.0493\n",
            "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "[0.99999994 0.        ]\n",
            "[9.9999994e-01 5.2052424e-14]\n",
            "24\n",
            "290\n",
            "train acc:  0.7819548872180451\n",
            "test acc:  0.38461538461538464\n",
            "Experiment 4 in progress\n",
            "Epoch 1/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9823 - loss: 0.0481\n",
            "Epoch 2/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9826 - loss: 0.0478\n",
            "Epoch 3/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9807 - loss: 0.0491\n",
            "Epoch 4/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9834 - loss: 0.0473\n",
            "Epoch 5/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9816 - loss: 0.0480\n",
            "Epoch 6/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9842 - loss: 0.0472\n",
            "Epoch 7/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9834 - loss: 0.0466\n",
            "Epoch 8/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9826 - loss: 0.0469\n",
            "Epoch 9/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9830 - loss: 0.0468\n",
            "Epoch 10/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9831 - loss: 0.0527\n",
            "Epoch 11/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9827 - loss: 0.0466\n",
            "Epoch 12/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9827 - loss: 0.0471\n",
            "Epoch 13/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9836 - loss: 0.0461\n",
            "Epoch 14/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.9831 - loss: 0.0461\n",
            "Epoch 15/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9835 - loss: 0.0461\n",
            "Epoch 16/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9822 - loss: 0.0471\n",
            "Epoch 17/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9831 - loss: 0.0462\n",
            "Epoch 18/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9838 - loss: 0.0463\n",
            "Epoch 19/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9831 - loss: 0.0466\n",
            "Epoch 20/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9840 - loss: 0.0469\n",
            "Epoch 21/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9832 - loss: 0.0469\n",
            "Epoch 22/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9836 - loss: 0.0464\n",
            "Epoch 23/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9836 - loss: 0.0456\n",
            "Epoch 24/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9830 - loss: 0.0477\n",
            "Epoch 25/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9824 - loss: 0.0476\n",
            "Epoch 26/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9838 - loss: 0.0459\n",
            "Epoch 27/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9824 - loss: 0.0493\n",
            "Epoch 28/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9826 - loss: 0.0464\n",
            "Epoch 29/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9833 - loss: 0.0449\n",
            "Epoch 30/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9829 - loss: 0.0451\n",
            "Epoch 31/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9837 - loss: 0.0468\n",
            "Epoch 32/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9839 - loss: 0.0455\n",
            "Epoch 33/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9834 - loss: 0.0460\n",
            "Epoch 34/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9835 - loss: 0.0452\n",
            "Epoch 35/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9834 - loss: 0.0458\n",
            "Epoch 36/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9818 - loss: 0.0481\n",
            "Epoch 37/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9835 - loss: 0.0461\n",
            "Epoch 38/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9847 - loss: 0.0445\n",
            "Epoch 39/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9835 - loss: 0.0452\n",
            "Epoch 40/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9828 - loss: 0.0501\n",
            "Epoch 41/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9840 - loss: 0.0442\n",
            "Epoch 42/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9838 - loss: 0.0461\n",
            "Epoch 43/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9842 - loss: 0.0455\n",
            "Epoch 44/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9839 - loss: 0.0456\n",
            "Epoch 45/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9843 - loss: 0.0452\n",
            "Epoch 46/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9845 - loss: 0.0449\n",
            "Epoch 47/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9840 - loss: 0.0447\n",
            "Epoch 48/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9842 - loss: 0.0449\n",
            "Epoch 49/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9834 - loss: 0.0472\n",
            "Epoch 50/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9833 - loss: 0.0451\n",
            "Epoch 51/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9849 - loss: 0.0443\n",
            "Epoch 52/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9832 - loss: 0.0463\n",
            "Epoch 53/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9843 - loss: 0.0440\n",
            "Epoch 54/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9838 - loss: 0.0454\n",
            "Epoch 55/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9803 - loss: 0.0524\n",
            "Epoch 56/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9838 - loss: 0.0460\n",
            "Epoch 57/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9841 - loss: 0.0450\n",
            "Epoch 58/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9833 - loss: 0.0450\n",
            "Epoch 59/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9835 - loss: 0.0445\n",
            "Epoch 60/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9837 - loss: 0.0448\n",
            "Epoch 61/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9844 - loss: 0.0452\n",
            "Epoch 62/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9837 - loss: 0.0467\n",
            "Epoch 63/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9832 - loss: 0.0441\n",
            "Epoch 64/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9833 - loss: 0.0450\n",
            "Epoch 65/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9838 - loss: 0.0458\n",
            "Epoch 66/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9844 - loss: 0.0439\n",
            "Epoch 67/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9835 - loss: 0.0441\n",
            "Epoch 68/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9842 - loss: 0.0444\n",
            "Epoch 69/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.9830 - loss: 0.0483\n",
            "Epoch 70/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9843 - loss: 0.0443\n",
            "Epoch 71/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9840 - loss: 0.0434\n",
            "Epoch 72/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9809 - loss: 0.0540\n",
            "Epoch 73/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9842 - loss: 0.0447\n",
            "Epoch 74/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9851 - loss: 0.0430\n",
            "Epoch 75/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9843 - loss: 0.0437\n",
            "Epoch 76/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9842 - loss: 0.0444\n",
            "Epoch 77/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9845 - loss: 0.0439\n",
            "Epoch 78/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9842 - loss: 0.0440\n",
            "Epoch 79/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9833 - loss: 0.0456\n",
            "Epoch 80/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9836 - loss: 0.0444\n",
            "Epoch 81/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9840 - loss: 0.0446\n",
            "Epoch 82/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9833 - loss: 0.0474\n",
            "Epoch 83/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9847 - loss: 0.0421\n",
            "Epoch 84/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9846 - loss: 0.0426\n",
            "Epoch 85/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9846 - loss: 0.0434\n",
            "Epoch 86/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9849 - loss: 0.0440\n",
            "Epoch 87/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9840 - loss: 0.0432\n",
            "Epoch 88/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9845 - loss: 0.0437\n",
            "Epoch 89/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9850 - loss: 0.0423\n",
            "Epoch 90/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9833 - loss: 0.0483\n",
            "Epoch 91/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9824 - loss: 0.0528\n",
            "Epoch 92/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9838 - loss: 0.0468\n",
            "Epoch 93/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9846 - loss: 0.0447\n",
            "Epoch 94/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9850 - loss: 0.0438\n",
            "Epoch 95/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9848 - loss: 0.0433\n",
            "Epoch 96/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9842 - loss: 0.0435\n",
            "Epoch 97/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9856 - loss: 0.0423\n",
            "Epoch 98/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9840 - loss: 0.0435\n",
            "Epoch 99/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9853 - loss: 0.0421\n",
            "Epoch 100/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.9857 - loss: 0.0428\n",
            "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "[0.99999994 0.        ]\n",
            "[9.9999994e-01 3.0847510e-14]\n",
            "19\n",
            "292\n",
            "train acc:  0.8095952023988006\n",
            "test acc:  0.46808510638297873\n",
            "Experiment 5 in progress\n",
            "Epoch 1/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9853 - loss: 0.0424\n",
            "Epoch 2/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9844 - loss: 0.0435\n",
            "Epoch 3/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9856 - loss: 0.0431\n",
            "Epoch 4/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9850 - loss: 0.0431\n",
            "Epoch 5/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9825 - loss: 0.0499\n",
            "Epoch 6/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9830 - loss: 0.0489\n",
            "Epoch 7/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9855 - loss: 0.0447\n",
            "Epoch 8/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9851 - loss: 0.0425\n",
            "Epoch 9/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9855 - loss: 0.0415\n",
            "Epoch 10/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9858 - loss: 0.0427\n",
            "Epoch 11/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9855 - loss: 0.0418\n",
            "Epoch 12/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9855 - loss: 0.0418\n",
            "Epoch 13/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9851 - loss: 0.0426\n",
            "Epoch 14/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.9854 - loss: 0.0417\n",
            "Epoch 15/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9855 - loss: 0.0424\n",
            "Epoch 16/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9836 - loss: 0.0434\n",
            "Epoch 17/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9830 - loss: 0.0466\n",
            "Epoch 18/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9850 - loss: 0.0429\n",
            "Epoch 19/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9853 - loss: 0.0425\n",
            "Epoch 20/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9852 - loss: 0.0410\n",
            "Epoch 21/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9865 - loss: 0.0409\n",
            "Epoch 22/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9857 - loss: 0.0412\n",
            "Epoch 23/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9865 - loss: 0.0410\n",
            "Epoch 24/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9819 - loss: 0.0513\n",
            "Epoch 25/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9819 - loss: 0.0488\n",
            "Epoch 26/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9852 - loss: 0.0424\n",
            "Epoch 27/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9852 - loss: 0.0413\n",
            "Epoch 28/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9854 - loss: 0.0414\n",
            "Epoch 29/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9860 - loss: 0.0411\n",
            "Epoch 30/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9867 - loss: 0.0406\n",
            "Epoch 31/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9866 - loss: 0.0406\n",
            "Epoch 32/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9855 - loss: 0.0413\n",
            "Epoch 33/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9842 - loss: 0.0449\n",
            "Epoch 34/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9855 - loss: 0.0429\n",
            "Epoch 35/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9845 - loss: 0.0423\n",
            "Epoch 36/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9852 - loss: 0.0407\n",
            "Epoch 37/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9870 - loss: 0.0406\n",
            "Epoch 38/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.9826 - loss: 0.0473\n",
            "Epoch 39/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9861 - loss: 0.0431\n",
            "Epoch 40/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9861 - loss: 0.0406\n",
            "Epoch 41/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9864 - loss: 0.0400\n",
            "Epoch 42/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9857 - loss: 0.0426\n",
            "Epoch 43/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9850 - loss: 0.0442\n",
            "Epoch 44/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9854 - loss: 0.0410\n",
            "Epoch 45/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9865 - loss: 0.0404\n",
            "Epoch 46/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9862 - loss: 0.0400\n",
            "Epoch 47/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9853 - loss: 0.0410\n",
            "Epoch 48/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9848 - loss: 0.0426\n",
            "Epoch 49/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9861 - loss: 0.0412\n",
            "Epoch 50/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9822 - loss: 0.0457\n",
            "Epoch 51/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9859 - loss: 0.0422\n",
            "Epoch 52/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9850 - loss: 0.0404\n",
            "Epoch 53/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9856 - loss: 0.0398\n",
            "Epoch 54/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9864 - loss: 0.0397\n",
            "Epoch 55/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9863 - loss: 0.0396\n",
            "Epoch 56/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9851 - loss: 0.0408\n",
            "Epoch 57/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9863 - loss: 0.0397\n",
            "Epoch 58/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9842 - loss: 0.0450\n",
            "Epoch 59/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9857 - loss: 0.0388\n",
            "Epoch 60/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9857 - loss: 0.0391\n",
            "Epoch 61/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9867 - loss: 0.0392\n",
            "Epoch 62/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9862 - loss: 0.0393\n",
            "Epoch 63/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9858 - loss: 0.0406\n",
            "Epoch 64/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9853 - loss: 0.0403\n",
            "Epoch 65/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9863 - loss: 0.0389\n",
            "Epoch 66/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9824 - loss: 0.0485\n",
            "Epoch 67/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9858 - loss: 0.0414\n",
            "Epoch 68/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9853 - loss: 0.0414\n",
            "Epoch 69/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.9859 - loss: 0.0405\n",
            "Epoch 70/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9863 - loss: 0.0399\n",
            "Epoch 71/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9859 - loss: 0.0394\n",
            "Epoch 72/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9865 - loss: 0.0388\n",
            "Epoch 73/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9831 - loss: 0.0442\n",
            "Epoch 74/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9862 - loss: 0.0384\n",
            "Epoch 75/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9864 - loss: 0.0391\n",
            "Epoch 76/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9854 - loss: 0.0394\n",
            "Epoch 77/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9856 - loss: 0.0390\n",
            "Epoch 78/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9871 - loss: 0.0388\n",
            "Epoch 79/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9857 - loss: 0.0387\n",
            "Epoch 80/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9845 - loss: 0.0412\n",
            "Epoch 81/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9860 - loss: 0.0428\n",
            "Epoch 82/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9865 - loss: 0.0385\n",
            "Epoch 83/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9872 - loss: 0.0378\n",
            "Epoch 84/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9868 - loss: 0.0381\n",
            "Epoch 85/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9863 - loss: 0.0376\n",
            "Epoch 86/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9855 - loss: 0.0395\n",
            "Epoch 87/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9858 - loss: 0.0387\n",
            "Epoch 88/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9848 - loss: 0.0472\n",
            "Epoch 89/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9859 - loss: 0.0403\n",
            "Epoch 90/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9856 - loss: 0.0382\n",
            "Epoch 91/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9865 - loss: 0.0373\n",
            "Epoch 92/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9858 - loss: 0.0388\n",
            "Epoch 93/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9866 - loss: 0.0383\n",
            "Epoch 94/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9858 - loss: 0.0383\n",
            "Epoch 95/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9875 - loss: 0.0378\n",
            "Epoch 96/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9867 - loss: 0.0379\n",
            "Epoch 97/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9868 - loss: 0.0381\n",
            "Epoch 98/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9862 - loss: 0.0389\n",
            "Epoch 99/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9864 - loss: 0.0389\n",
            "Epoch 100/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9866 - loss: 0.0374\n",
            "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "[0.99999994 0.        ]\n",
            "[9.9999994e-01 2.9071498e-22]\n",
            "15\n",
            "300\n",
            "train acc:  0.8237037037037037\n",
            "test acc:  0.5116279069767442\n",
            "Experiment 6 in progress\n",
            "Epoch 1/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9861 - loss: 0.0388\n",
            "Epoch 2/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9863 - loss: 0.0382\n",
            "Epoch 3/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9865 - loss: 0.0374\n",
            "Epoch 4/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9867 - loss: 0.0378\n",
            "Epoch 5/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9860 - loss: 0.0384\n",
            "Epoch 6/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9862 - loss: 0.0374\n",
            "Epoch 7/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9861 - loss: 0.0410\n",
            "Epoch 8/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9860 - loss: 0.0377\n",
            "Epoch 9/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9836 - loss: 0.0453\n",
            "Epoch 10/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9862 - loss: 0.0396\n",
            "Epoch 11/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9872 - loss: 0.0378\n",
            "Epoch 12/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9859 - loss: 0.0388\n",
            "Epoch 13/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9866 - loss: 0.0376\n",
            "Epoch 14/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9862 - loss: 0.0371\n",
            "Epoch 15/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9860 - loss: 0.0382\n",
            "Epoch 16/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9859 - loss: 0.0375\n",
            "Epoch 17/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9864 - loss: 0.0377\n",
            "Epoch 18/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9853 - loss: 0.0376\n",
            "Epoch 19/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9860 - loss: 0.0376\n",
            "Epoch 20/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9845 - loss: 0.0420\n",
            "Epoch 21/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9855 - loss: 0.0373\n",
            "Epoch 22/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9876 - loss: 0.0357\n",
            "Epoch 23/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9832 - loss: 0.0434\n",
            "Epoch 24/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9865 - loss: 0.0364\n",
            "Epoch 25/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9874 - loss: 0.0363\n",
            "Epoch 26/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9832 - loss: 0.0505\n",
            "Epoch 27/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9858 - loss: 0.0419\n",
            "Epoch 28/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9851 - loss: 0.0417\n",
            "Epoch 29/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9865 - loss: 0.0376\n",
            "Epoch 30/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9873 - loss: 0.0366\n",
            "Epoch 31/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9876 - loss: 0.0369\n",
            "Epoch 32/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9874 - loss: 0.0358\n",
            "Epoch 33/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9871 - loss: 0.0368\n",
            "Epoch 34/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9862 - loss: 0.0379\n",
            "Epoch 35/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9873 - loss: 0.0368\n",
            "Epoch 36/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9879 - loss: 0.0358\n",
            "Epoch 37/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9863 - loss: 0.0391\n",
            "Epoch 38/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9869 - loss: 0.0356\n",
            "Epoch 39/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9854 - loss: 0.0384\n",
            "Epoch 40/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9863 - loss: 0.0362\n",
            "Epoch 41/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9873 - loss: 0.0357\n",
            "Epoch 42/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9859 - loss: 0.0372\n",
            "Epoch 43/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9840 - loss: 0.0415\n",
            "Epoch 44/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9851 - loss: 0.0386\n",
            "Epoch 45/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9847 - loss: 0.0480\n",
            "Epoch 46/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9859 - loss: 0.0416\n",
            "Epoch 47/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9843 - loss: 0.0437\n",
            "Epoch 48/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9864 - loss: 0.0384\n",
            "Epoch 49/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9866 - loss: 0.0405\n",
            "Epoch 50/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9877 - loss: 0.0352\n",
            "Epoch 51/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9877 - loss: 0.0350\n",
            "Epoch 52/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9860 - loss: 0.0365\n",
            "Epoch 53/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9877 - loss: 0.0351\n",
            "Epoch 54/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9876 - loss: 0.0353\n",
            "Epoch 55/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9875 - loss: 0.0352\n",
            "Epoch 56/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9872 - loss: 0.0350\n",
            "Epoch 57/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9866 - loss: 0.0379\n",
            "Epoch 58/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9857 - loss: 0.0385\n",
            "Epoch 59/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9862 - loss: 0.0359\n",
            "Epoch 60/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9876 - loss: 0.0346\n",
            "Epoch 61/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9879 - loss: 0.0347\n",
            "Epoch 62/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9881 - loss: 0.0344\n",
            "Epoch 63/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9871 - loss: 0.0349\n",
            "Epoch 64/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9873 - loss: 0.0349\n",
            "Epoch 65/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9870 - loss: 0.0419\n",
            "Epoch 66/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9885 - loss: 0.0351\n",
            "Epoch 67/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9874 - loss: 0.0348\n",
            "Epoch 68/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9887 - loss: 0.0338\n",
            "Epoch 69/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9876 - loss: 0.0353\n",
            "Epoch 70/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9890 - loss: 0.0337\n",
            "Epoch 71/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9886 - loss: 0.0337\n",
            "Epoch 72/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9875 - loss: 0.0351\n",
            "Epoch 73/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9883 - loss: 0.0340\n",
            "Epoch 74/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9882 - loss: 0.0340\n",
            "Epoch 75/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.9868 - loss: 0.0359\n",
            "Epoch 76/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9864 - loss: 0.0344\n",
            "Epoch 77/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9864 - loss: 0.0361\n",
            "Epoch 78/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9880 - loss: 0.0345\n",
            "Epoch 79/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9878 - loss: 0.0340\n",
            "Epoch 80/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9874 - loss: 0.0341\n",
            "Epoch 81/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9885 - loss: 0.0334\n",
            "Epoch 82/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9879 - loss: 0.0341\n",
            "Epoch 83/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9878 - loss: 0.0332\n",
            "Epoch 84/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9878 - loss: 0.0335\n",
            "Epoch 85/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9886 - loss: 0.0354\n",
            "Epoch 86/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9861 - loss: 0.0418\n",
            "Epoch 87/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9892 - loss: 0.0364\n",
            "Epoch 88/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9881 - loss: 0.0339\n",
            "Epoch 89/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9892 - loss: 0.0333\n",
            "Epoch 90/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9882 - loss: 0.0330\n",
            "Epoch 91/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9890 - loss: 0.0325\n",
            "Epoch 92/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9885 - loss: 0.0331\n",
            "Epoch 93/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9889 - loss: 0.0325\n",
            "Epoch 94/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9878 - loss: 0.0335\n",
            "Epoch 95/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9890 - loss: 0.0328\n",
            "Epoch 96/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0358\n",
            "Epoch 97/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9887 - loss: 0.0327\n",
            "Epoch 98/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9880 - loss: 0.0322\n",
            "Epoch 99/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9869 - loss: 0.0357\n",
            "Epoch 100/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9895 - loss: 0.0326\n",
            "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "[0.99999994 0.        ]\n",
            "[9.9999994e-01 2.7086661e-22]\n",
            "14\n",
            "298\n",
            "train acc:  0.8380386329866271\n",
            "test acc:  0.47619047619047616\n",
            "Experiment 7 in progress\n",
            "Epoch 1/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9895 - loss: 0.0325\n",
            "Epoch 2/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9883 - loss: 0.0329\n",
            "Epoch 3/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9866 - loss: 0.0492\n",
            "Epoch 4/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9872 - loss: 0.0359\n",
            "Epoch 5/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9891 - loss: 0.0323\n",
            "Epoch 6/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9888 - loss: 0.0339\n",
            "Epoch 7/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9896 - loss: 0.0323\n",
            "Epoch 8/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9866 - loss: 0.0344\n",
            "Epoch 9/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9884 - loss: 0.0327\n",
            "Epoch 10/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9878 - loss: 0.0364\n",
            "Epoch 11/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9880 - loss: 0.0327\n",
            "Epoch 12/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9886 - loss: 0.0318\n",
            "Epoch 13/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9896 - loss: 0.0312\n",
            "Epoch 14/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9880 - loss: 0.0329\n",
            "Epoch 15/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9903 - loss: 0.0321\n",
            "Epoch 16/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9885 - loss: 0.0323\n",
            "Epoch 17/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9891 - loss: 0.0319\n",
            "Epoch 18/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9896 - loss: 0.0319\n",
            "Epoch 19/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.9897 - loss: 0.0320\n",
            "Epoch 20/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9874 - loss: 0.0340\n",
            "Epoch 21/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9862 - loss: 0.0501\n",
            "Epoch 22/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9883 - loss: 0.0332\n",
            "Epoch 23/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9887 - loss: 0.0322\n",
            "Epoch 24/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9894 - loss: 0.0314\n",
            "Epoch 25/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9888 - loss: 0.0308\n",
            "Epoch 26/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9884 - loss: 0.0334\n",
            "Epoch 27/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9899 - loss: 0.0315\n",
            "Epoch 28/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9891 - loss: 0.0321\n",
            "Epoch 29/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9870 - loss: 0.0396\n",
            "Epoch 30/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9888 - loss: 0.0322\n",
            "Epoch 31/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9897 - loss: 0.0307\n",
            "Epoch 32/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9885 - loss: 0.0317\n",
            "Epoch 33/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9897 - loss: 0.0312\n",
            "Epoch 34/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9892 - loss: 0.0318\n",
            "Epoch 35/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9894 - loss: 0.0316\n",
            "Epoch 36/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9902 - loss: 0.0304\n",
            "Epoch 37/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9894 - loss: 0.0323\n",
            "Epoch 38/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9887 - loss: 0.0355\n",
            "Epoch 39/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9896 - loss: 0.0320\n",
            "Epoch 40/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.9899 - loss: 0.0311\n",
            "Epoch 41/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9891 - loss: 0.0304\n",
            "Epoch 42/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9901 - loss: 0.0304\n",
            "Epoch 43/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9895 - loss: 0.0314\n",
            "Epoch 44/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9881 - loss: 0.0367\n",
            "Epoch 45/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9883 - loss: 0.0350\n",
            "Epoch 46/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9902 - loss: 0.0311\n",
            "Epoch 47/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.9894 - loss: 0.0305\n",
            "Epoch 48/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9909 - loss: 0.0301\n",
            "Epoch 49/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9884 - loss: 0.0352\n",
            "Epoch 50/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9871 - loss: 0.0420\n",
            "Epoch 51/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9876 - loss: 0.0328\n",
            "Epoch 52/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9904 - loss: 0.0303\n",
            "Epoch 53/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9901 - loss: 0.0296\n",
            "Epoch 54/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9901 - loss: 0.0301\n",
            "Epoch 55/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9893 - loss: 0.0296\n",
            "Epoch 56/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9905 - loss: 0.0314\n",
            "Epoch 57/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9913 - loss: 0.0300\n",
            "Epoch 58/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9899 - loss: 0.0302\n",
            "Epoch 59/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9906 - loss: 0.0304\n",
            "Epoch 60/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9895 - loss: 0.0320\n",
            "Epoch 61/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9890 - loss: 0.0299\n",
            "Epoch 62/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9873 - loss: 0.0400\n",
            "Epoch 63/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9906 - loss: 0.0299\n",
            "Epoch 64/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9912 - loss: 0.0296\n",
            "Epoch 65/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9897 - loss: 0.0299\n",
            "Epoch 66/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9893 - loss: 0.0312\n",
            "Epoch 67/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9903 - loss: 0.0303\n",
            "Epoch 68/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9889 - loss: 0.0330\n",
            "Epoch 69/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9913 - loss: 0.0290\n",
            "Epoch 70/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9901 - loss: 0.0298\n",
            "Epoch 71/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9896 - loss: 0.0324\n",
            "Epoch 72/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9897 - loss: 0.0306\n",
            "Epoch 73/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9885 - loss: 0.0303\n",
            "Epoch 74/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9908 - loss: 0.0312\n",
            "Epoch 75/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9863 - loss: 0.0443\n",
            "Epoch 76/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9890 - loss: 0.0308\n",
            "Epoch 77/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9902 - loss: 0.0292\n",
            "Epoch 78/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9901 - loss: 0.0290\n",
            "Epoch 79/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9912 - loss: 0.0286\n",
            "Epoch 80/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9911 - loss: 0.0288\n",
            "Epoch 81/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9910 - loss: 0.0291\n",
            "Epoch 82/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9898 - loss: 0.0325\n",
            "Epoch 83/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9903 - loss: 0.0299\n",
            "Epoch 84/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9909 - loss: 0.0296\n",
            "Epoch 85/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9882 - loss: 0.0368\n",
            "Epoch 86/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9906 - loss: 0.0284\n",
            "Epoch 87/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9895 - loss: 0.0309\n",
            "Epoch 88/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9895 - loss: 0.0300\n",
            "Epoch 89/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9903 - loss: 0.0308\n",
            "Epoch 90/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9905 - loss: 0.0294\n",
            "Epoch 91/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9910 - loss: 0.0299\n",
            "Epoch 92/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9900 - loss: 0.0295\n",
            "Epoch 93/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9898 - loss: 0.0296\n",
            "Epoch 94/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9849 - loss: 0.0404\n",
            "Epoch 95/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9904 - loss: 0.0296\n",
            "Epoch 96/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9903 - loss: 0.0293\n",
            "Epoch 97/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9911 - loss: 0.0286\n",
            "Epoch 98/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9903 - loss: 0.0302\n",
            "Epoch 99/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9857 - loss: 0.0418\n",
            "Epoch 100/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9886 - loss: 0.0341\n",
            "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "[0.99999994 0.        ]\n",
            "[9.9999994e-01 6.2727662e-27]\n",
            "16\n",
            "316\n",
            "train acc:  0.85383502170767\n",
            "test acc:  0.45454545454545453\n",
            "Experiment 8 in progress\n",
            "Epoch 1/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9897 - loss: 0.0319\n",
            "Epoch 2/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9900 - loss: 0.0292\n",
            "Epoch 3/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9889 - loss: 0.0305\n",
            "Epoch 4/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9894 - loss: 0.0311\n",
            "Epoch 5/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9894 - loss: 0.0311\n",
            "Epoch 6/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9903 - loss: 0.0306\n",
            "Epoch 7/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9880 - loss: 0.0345\n",
            "Epoch 8/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9893 - loss: 0.0301\n",
            "Epoch 9/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9894 - loss: 0.0305\n",
            "Epoch 10/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9898 - loss: 0.0289\n",
            "Epoch 11/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9892 - loss: 0.0314\n",
            "Epoch 12/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9891 - loss: 0.0314\n",
            "Epoch 13/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9890 - loss: 0.0300\n",
            "Epoch 14/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9903 - loss: 0.0284\n",
            "Epoch 15/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9887 - loss: 0.0302\n",
            "Epoch 16/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9894 - loss: 0.0289\n",
            "Epoch 17/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9862 - loss: 0.0381\n",
            "Epoch 18/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9908 - loss: 0.0297\n",
            "Epoch 19/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9907 - loss: 0.0292\n",
            "Epoch 20/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9893 - loss: 0.0291\n",
            "Epoch 21/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9898 - loss: 0.0293\n",
            "Epoch 22/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9901 - loss: 0.0308\n",
            "Epoch 23/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9901 - loss: 0.0288\n",
            "Epoch 24/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9898 - loss: 0.0309\n",
            "Epoch 25/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9883 - loss: 0.0313\n",
            "Epoch 26/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9906 - loss: 0.0313\n",
            "Epoch 27/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9901 - loss: 0.0296\n",
            "Epoch 28/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9904 - loss: 0.0288\n",
            "Epoch 29/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9909 - loss: 0.0286\n",
            "Epoch 30/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9894 - loss: 0.0311\n",
            "Epoch 31/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9909 - loss: 0.0288\n",
            "Epoch 32/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9894 - loss: 0.0291\n",
            "Epoch 33/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9910 - loss: 0.0280\n",
            "Epoch 34/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9903 - loss: 0.0283\n",
            "Epoch 35/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9899 - loss: 0.0295\n",
            "Epoch 36/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9892 - loss: 0.0349\n",
            "Epoch 37/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9883 - loss: 0.0313\n",
            "Epoch 38/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9916 - loss: 0.0286\n",
            "Epoch 39/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9912 - loss: 0.0284\n",
            "Epoch 40/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9903 - loss: 0.0293\n",
            "Epoch 41/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9897 - loss: 0.0296\n",
            "Epoch 42/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9883 - loss: 0.0324\n",
            "Epoch 43/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9896 - loss: 0.0284\n",
            "Epoch 44/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9898 - loss: 0.0292\n",
            "Epoch 45/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9908 - loss: 0.0277\n",
            "Epoch 46/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9906 - loss: 0.0282\n",
            "Epoch 47/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9909 - loss: 0.0287\n",
            "Epoch 48/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.9903 - loss: 0.0282\n",
            "Epoch 49/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9892 - loss: 0.0289\n",
            "Epoch 50/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9906 - loss: 0.0269\n",
            "Epoch 51/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9900 - loss: 0.0298\n",
            "Epoch 52/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9896 - loss: 0.0288\n",
            "Epoch 53/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9882 - loss: 0.0333\n",
            "Epoch 54/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9902 - loss: 0.0287\n",
            "Epoch 55/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9905 - loss: 0.0280\n",
            "Epoch 56/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9915 - loss: 0.0279\n",
            "Epoch 57/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9907 - loss: 0.0287\n",
            "Epoch 58/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9884 - loss: 0.0322\n",
            "Epoch 59/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9909 - loss: 0.0311\n",
            "Epoch 60/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9899 - loss: 0.0332\n",
            "Epoch 61/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9911 - loss: 0.0295\n",
            "Epoch 62/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9916 - loss: 0.0265\n",
            "Epoch 63/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9905 - loss: 0.0287\n",
            "Epoch 64/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9914 - loss: 0.0274\n",
            "Epoch 65/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9912 - loss: 0.0275\n",
            "Epoch 66/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9915 - loss: 0.0282\n",
            "Epoch 67/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9921 - loss: 0.0273\n",
            "Epoch 68/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9915 - loss: 0.0262\n",
            "Epoch 69/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9904 - loss: 0.0288\n",
            "Epoch 70/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9908 - loss: 0.0302\n",
            "Epoch 71/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9914 - loss: 0.0276\n",
            "Epoch 72/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9910 - loss: 0.0268\n",
            "Epoch 73/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.9914 - loss: 0.0278\n",
            "Epoch 74/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9908 - loss: 0.0280\n",
            "Epoch 75/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9912 - loss: 0.0280\n",
            "Epoch 76/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9920 - loss: 0.0279\n",
            "Epoch 77/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9901 - loss: 0.0313\n",
            "Epoch 78/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9910 - loss: 0.0303\n",
            "Epoch 79/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9890 - loss: 0.0305\n",
            "Epoch 80/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9912 - loss: 0.0269\n",
            "Epoch 81/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9912 - loss: 0.0273\n",
            "Epoch 82/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9909 - loss: 0.0275\n",
            "Epoch 83/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9896 - loss: 0.0293\n",
            "Epoch 84/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9899 - loss: 0.0278\n",
            "Epoch 85/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9900 - loss: 0.0289\n",
            "Epoch 86/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9898 - loss: 0.0362\n",
            "Epoch 87/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9918 - loss: 0.0273\n",
            "Epoch 88/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9923 - loss: 0.0274\n",
            "Epoch 89/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9912 - loss: 0.0261\n",
            "Epoch 90/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9912 - loss: 0.0307\n",
            "Epoch 91/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9918 - loss: 0.0280\n",
            "Epoch 92/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9915 - loss: 0.0279\n",
            "Epoch 93/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9905 - loss: 0.0270\n",
            "Epoch 94/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9911 - loss: 0.0282\n",
            "Epoch 95/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9902 - loss: 0.0278\n",
            "Epoch 96/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9849 - loss: 0.0445\n",
            "Epoch 97/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9884 - loss: 0.0343\n",
            "Epoch 98/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9916 - loss: 0.0271\n",
            "Epoch 99/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9909 - loss: 0.0265\n",
            "Epoch 100/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9913 - loss: 0.0271\n",
            "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "[0.99999994 0.        ]\n",
            "[9.9999994e-01 8.4429969e-18]\n",
            "21\n",
            "326\n",
            "train acc:  0.8587731811697575\n",
            "test acc:  0.40816326530612246\n",
            "Experiment 9 in progress\n",
            "Epoch 1/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9913 - loss: 0.0270\n",
            "Epoch 2/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9914 - loss: 0.0253\n",
            "Epoch 3/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9903 - loss: 0.0332\n",
            "Epoch 4/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9910 - loss: 0.0307\n",
            "Epoch 5/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9900 - loss: 0.0309\n",
            "Epoch 6/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9911 - loss: 0.0298\n",
            "Epoch 7/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9896 - loss: 0.0269\n",
            "Epoch 8/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9914 - loss: 0.0257\n",
            "Epoch 9/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9917 - loss: 0.0270\n",
            "Epoch 10/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9906 - loss: 0.0265\n",
            "Epoch 11/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9908 - loss: 0.0269\n",
            "Epoch 12/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9904 - loss: 0.0288\n",
            "Epoch 13/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9915 - loss: 0.0274\n",
            "Epoch 14/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9903 - loss: 0.0261\n",
            "Epoch 15/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9912 - loss: 0.0272\n",
            "Epoch 16/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9909 - loss: 0.0265\n",
            "Epoch 17/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9896 - loss: 0.0292\n",
            "Epoch 18/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9886 - loss: 0.0300\n",
            "Epoch 19/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9910 - loss: 0.0269\n",
            "Epoch 20/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9904 - loss: 0.0277\n",
            "Epoch 21/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9909 - loss: 0.0267\n",
            "Epoch 22/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9910 - loss: 0.0257\n",
            "Epoch 23/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9904 - loss: 0.0269\n",
            "Epoch 24/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9909 - loss: 0.0260\n",
            "Epoch 25/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9904 - loss: 0.0267\n",
            "Epoch 26/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9919 - loss: 0.0241\n",
            "Epoch 27/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9898 - loss: 0.0339\n",
            "Epoch 28/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9893 - loss: 0.0312\n",
            "Epoch 29/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9893 - loss: 0.0289\n",
            "Epoch 30/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9898 - loss: 0.0297\n",
            "Epoch 31/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9903 - loss: 0.0270\n",
            "Epoch 32/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9911 - loss: 0.0261\n",
            "Epoch 33/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9915 - loss: 0.0267\n",
            "Epoch 34/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9902 - loss: 0.0302\n",
            "Epoch 35/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9916 - loss: 0.0303\n",
            "Epoch 36/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9903 - loss: 0.0290\n",
            "Epoch 37/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9903 - loss: 0.0281\n",
            "Epoch 38/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9907 - loss: 0.0272\n",
            "Epoch 39/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9907 - loss: 0.0266\n",
            "Epoch 40/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9914 - loss: 0.0259\n",
            "Epoch 41/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9917 - loss: 0.0248\n",
            "Epoch 42/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9917 - loss: 0.0267\n",
            "Epoch 43/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9893 - loss: 0.0301\n",
            "Epoch 44/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9909 - loss: 0.0287\n",
            "Epoch 45/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9908 - loss: 0.0273\n",
            "Epoch 46/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9909 - loss: 0.0289\n",
            "Epoch 47/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9903 - loss: 0.0287\n",
            "Epoch 48/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9907 - loss: 0.0259\n",
            "Epoch 49/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9907 - loss: 0.0257\n",
            "Epoch 50/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9888 - loss: 0.0299\n",
            "Epoch 51/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9903 - loss: 0.0306\n",
            "Epoch 52/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9915 - loss: 0.0278\n",
            "Epoch 53/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9912 - loss: 0.0273\n",
            "Epoch 54/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9906 - loss: 0.0281\n",
            "Epoch 55/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9912 - loss: 0.0271\n",
            "Epoch 56/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9914 - loss: 0.0273\n",
            "Epoch 57/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9914 - loss: 0.0303\n",
            "Epoch 58/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9891 - loss: 0.0305\n",
            "Epoch 59/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9903 - loss: 0.0291\n",
            "Epoch 60/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9877 - loss: 0.0331\n",
            "Epoch 61/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.9894 - loss: 0.0287\n",
            "Epoch 62/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9898 - loss: 0.0269\n",
            "Epoch 63/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9908 - loss: 0.0279\n",
            "Epoch 64/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.9899 - loss: 0.0285\n",
            "Epoch 65/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9884 - loss: 0.0325\n",
            "Epoch 66/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9890 - loss: 0.0320\n",
            "Epoch 67/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9907 - loss: 0.0282\n",
            "Epoch 68/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9915 - loss: 0.0281\n",
            "Epoch 69/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9889 - loss: 0.0314\n",
            "Epoch 70/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9905 - loss: 0.0290\n",
            "Epoch 71/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9903 - loss: 0.0296\n",
            "Epoch 72/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9899 - loss: 0.0288\n",
            "Epoch 73/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9882 - loss: 0.0325\n",
            "Epoch 74/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9855 - loss: 0.0374\n",
            "Epoch 75/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9900 - loss: 0.0295\n",
            "Epoch 76/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9906 - loss: 0.0290\n",
            "Epoch 77/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.9889 - loss: 0.0339\n",
            "Epoch 78/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9903 - loss: 0.0297\n",
            "Epoch 79/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9894 - loss: 0.0297\n",
            "Epoch 80/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9897 - loss: 0.0298\n",
            "Epoch 81/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9890 - loss: 0.0338\n",
            "Epoch 82/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9902 - loss: 0.0283\n",
            "Epoch 83/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9910 - loss: 0.0277\n",
            "Epoch 84/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9902 - loss: 0.0283\n",
            "Epoch 85/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9868 - loss: 0.0373\n",
            "Epoch 86/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9893 - loss: 0.0325\n",
            "Epoch 87/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9900 - loss: 0.0286\n",
            "Epoch 88/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9899 - loss: 0.0303\n",
            "Epoch 89/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9911 - loss: 0.0287\n",
            "Epoch 90/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9900 - loss: 0.0304\n",
            "Epoch 91/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9890 - loss: 0.0319\n",
            "Epoch 92/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9896 - loss: 0.0299\n",
            "Epoch 93/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9890 - loss: 0.0295\n",
            "Epoch 94/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9899 - loss: 0.0303\n",
            "Epoch 95/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9888 - loss: 0.0301\n",
            "Epoch 96/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.9867 - loss: 0.0342\n",
            "Epoch 97/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9903 - loss: 0.0282\n",
            "Epoch 98/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9913 - loss: 0.0273\n",
            "Epoch 99/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9892 - loss: 0.0329\n",
            "Epoch 100/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9901 - loss: 0.0294\n",
            "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "[0.99999994 0.        ]\n",
            "[9.9999994e-01 5.8627303e-23]\n",
            "24\n",
            "332\n",
            "train acc:  0.8656294200848657\n",
            "test acc:  0.38461538461538464\n",
            "Experiment 10 in progress\n",
            "Epoch 1/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9909 - loss: 0.0284\n",
            "Epoch 2/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9885 - loss: 0.0309\n",
            "Epoch 3/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9905 - loss: 0.0298\n",
            "Epoch 4/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9906 - loss: 0.0277\n",
            "Epoch 5/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.9902 - loss: 0.0306\n",
            "Epoch 6/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9895 - loss: 0.0291\n",
            "Epoch 7/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9904 - loss: 0.0298\n",
            "Epoch 8/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9894 - loss: 0.0285\n",
            "Epoch 9/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9899 - loss: 0.0306\n",
            "Epoch 10/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9906 - loss: 0.0302\n",
            "Epoch 11/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9907 - loss: 0.0279\n",
            "Epoch 12/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9898 - loss: 0.0286\n",
            "Epoch 13/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9900 - loss: 0.0300\n",
            "Epoch 14/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9863 - loss: 0.0378\n",
            "Epoch 15/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9906 - loss: 0.0300\n",
            "Epoch 16/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9910 - loss: 0.0273\n",
            "Epoch 17/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9893 - loss: 0.0273\n",
            "Epoch 18/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9890 - loss: 0.0289\n",
            "Epoch 19/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9908 - loss: 0.0286\n",
            "Epoch 20/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9894 - loss: 0.0275\n",
            "Epoch 21/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9896 - loss: 0.0292\n",
            "Epoch 22/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9912 - loss: 0.0284\n",
            "Epoch 23/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9893 - loss: 0.0287\n",
            "Epoch 24/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9887 - loss: 0.0329\n",
            "Epoch 25/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9890 - loss: 0.0323\n",
            "Epoch 26/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9918 - loss: 0.0279\n",
            "Epoch 27/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9899 - loss: 0.0329\n",
            "Epoch 28/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9900 - loss: 0.0267\n",
            "Epoch 29/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9906 - loss: 0.0287\n",
            "Epoch 30/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9896 - loss: 0.0285\n",
            "Epoch 31/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9900 - loss: 0.0278\n",
            "Epoch 32/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.9900 - loss: 0.0279\n",
            "Epoch 33/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.9904 - loss: 0.0268\n",
            "Epoch 34/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9906 - loss: 0.0274\n",
            "Epoch 35/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9887 - loss: 0.0317\n",
            "Epoch 36/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9915 - loss: 0.0274\n",
            "Epoch 37/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9899 - loss: 0.0267\n",
            "Epoch 38/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9905 - loss: 0.0274\n",
            "Epoch 39/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9875 - loss: 0.0329\n",
            "Epoch 40/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9894 - loss: 0.0342\n",
            "Epoch 41/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9910 - loss: 0.0273\n",
            "Epoch 42/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9896 - loss: 0.0288\n",
            "Epoch 43/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9906 - loss: 0.0275\n",
            "Epoch 44/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9890 - loss: 0.0309\n",
            "Epoch 45/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9880 - loss: 0.0355\n",
            "Epoch 46/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9914 - loss: 0.0274\n",
            "Epoch 47/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9908 - loss: 0.0276\n",
            "Epoch 48/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9903 - loss: 0.0278\n",
            "Epoch 49/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9889 - loss: 0.0279\n",
            "Epoch 50/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.9913 - loss: 0.0274\n",
            "Epoch 51/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9898 - loss: 0.0281\n",
            "Epoch 52/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9898 - loss: 0.0289\n",
            "Epoch 53/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9895 - loss: 0.0312\n",
            "Epoch 54/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9908 - loss: 0.0276\n",
            "Epoch 55/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9886 - loss: 0.0295\n",
            "Epoch 56/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9904 - loss: 0.0267\n",
            "Epoch 57/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9897 - loss: 0.0288\n",
            "Epoch 58/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9885 - loss: 0.0321\n",
            "Epoch 59/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9907 - loss: 0.0294\n",
            "Epoch 60/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9921 - loss: 0.0275\n",
            "Epoch 61/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9904 - loss: 0.0298\n",
            "Epoch 62/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9895 - loss: 0.0280\n",
            "Epoch 63/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9891 - loss: 0.0324\n",
            "Epoch 64/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9904 - loss: 0.0301\n",
            "Epoch 65/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9909 - loss: 0.0285\n",
            "Epoch 66/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9916 - loss: 0.0273\n",
            "Epoch 67/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.9910 - loss: 0.0294\n",
            "Epoch 68/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9897 - loss: 0.0322\n",
            "Epoch 69/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9906 - loss: 0.0302\n",
            "Epoch 70/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9883 - loss: 0.0313\n",
            "Epoch 71/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9914 - loss: 0.0273\n",
            "Epoch 72/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9909 - loss: 0.0280\n",
            "Epoch 73/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.9917 - loss: 0.0264\n",
            "Epoch 74/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9906 - loss: 0.0265\n",
            "Epoch 75/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9903 - loss: 0.0289\n",
            "Epoch 76/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9905 - loss: 0.0289\n",
            "Epoch 77/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9897 - loss: 0.0303\n",
            "Epoch 78/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9913 - loss: 0.0269\n",
            "Epoch 79/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9892 - loss: 0.0299\n",
            "Epoch 80/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9914 - loss: 0.0264\n",
            "Epoch 81/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9910 - loss: 0.0264\n",
            "Epoch 82/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9903 - loss: 0.0300\n",
            "Epoch 83/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9897 - loss: 0.0304\n",
            "Epoch 84/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9908 - loss: 0.0285\n",
            "Epoch 85/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9925 - loss: 0.0263\n",
            "Epoch 86/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9907 - loss: 0.0268\n",
            "Epoch 87/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9904 - loss: 0.0268\n",
            "Epoch 88/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9898 - loss: 0.0265\n",
            "Epoch 89/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9893 - loss: 0.0290\n",
            "Epoch 90/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9896 - loss: 0.0300\n",
            "Epoch 91/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9922 - loss: 0.0280\n",
            "Epoch 92/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9915 - loss: 0.0263\n",
            "Epoch 93/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9917 - loss: 0.0261\n",
            "Epoch 94/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9914 - loss: 0.0271\n",
            "Epoch 95/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9896 - loss: 0.0302\n",
            "Epoch 96/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9904 - loss: 0.0274\n",
            "Epoch 97/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9907 - loss: 0.0267\n",
            "Epoch 98/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9896 - loss: 0.0268\n",
            "Epoch 99/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9919 - loss: 0.0264\n",
            "Epoch 100/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9908 - loss: 0.0264\n",
            "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "[0.99999994 0.        ]\n",
            "[9.9999994e-01 8.3464880e-16]\n",
            "22\n",
            "355\n",
            "train acc:  0.8821917808219178\n",
            "test acc:  0.36\n",
            "Experiment 11 in progress\n",
            "Epoch 1/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9911 - loss: 0.0270\n",
            "Epoch 2/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9892 - loss: 0.0330\n",
            "Epoch 3/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9901 - loss: 0.0309\n",
            "Epoch 4/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9914 - loss: 0.0267\n",
            "Epoch 5/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9925 - loss: 0.0258\n",
            "Epoch 6/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9922 - loss: 0.0252\n",
            "Epoch 7/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9915 - loss: 0.0255\n",
            "Epoch 8/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9916 - loss: 0.0263\n",
            "Epoch 9/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9922 - loss: 0.0262\n",
            "Epoch 10/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.9918 - loss: 0.0259\n",
            "Epoch 11/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9907 - loss: 0.0280\n",
            "Epoch 12/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9924 - loss: 0.0255\n",
            "Epoch 13/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9920 - loss: 0.0293\n",
            "Epoch 14/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9897 - loss: 0.0300\n",
            "Epoch 15/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9929 - loss: 0.0248\n",
            "Epoch 16/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9924 - loss: 0.0263\n",
            "Epoch 17/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9911 - loss: 0.0257\n",
            "Epoch 18/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9925 - loss: 0.0247\n",
            "Epoch 19/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9913 - loss: 0.0261\n",
            "Epoch 20/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9927 - loss: 0.0251\n",
            "Epoch 21/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9912 - loss: 0.0282\n",
            "Epoch 22/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9911 - loss: 0.0265\n",
            "Epoch 23/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9920 - loss: 0.0245\n",
            "Epoch 24/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9919 - loss: 0.0257\n",
            "Epoch 25/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9915 - loss: 0.0270\n",
            "Epoch 26/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9902 - loss: 0.0284\n",
            "Epoch 27/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.9918 - loss: 0.0259\n",
            "Epoch 28/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9908 - loss: 0.0285\n",
            "Epoch 29/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9918 - loss: 0.0261\n",
            "Epoch 30/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9919 - loss: 0.0256\n",
            "Epoch 31/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9916 - loss: 0.0276\n",
            "Epoch 32/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9911 - loss: 0.0259\n",
            "Epoch 33/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9927 - loss: 0.0249\n",
            "Epoch 34/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9913 - loss: 0.0256\n",
            "Epoch 35/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.9907 - loss: 0.0301\n",
            "Epoch 36/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9901 - loss: 0.0284\n",
            "Epoch 37/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9928 - loss: 0.0243\n",
            "Epoch 38/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9935 - loss: 0.0233\n",
            "Epoch 39/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9918 - loss: 0.0248\n",
            "Epoch 40/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9915 - loss: 0.0266\n",
            "Epoch 41/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9920 - loss: 0.0251\n",
            "Epoch 42/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9919 - loss: 0.0258\n",
            "Epoch 43/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.9920 - loss: 0.0289\n",
            "Epoch 44/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.9896 - loss: 0.0317\n",
            "Epoch 45/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9920 - loss: 0.0268\n",
            "Epoch 46/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9916 - loss: 0.0251\n",
            "Epoch 47/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9926 - loss: 0.0262\n",
            "Epoch 48/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9924 - loss: 0.0253\n",
            "Epoch 49/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9911 - loss: 0.0293\n",
            "Epoch 50/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9914 - loss: 0.0271\n",
            "Epoch 51/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9933 - loss: 0.0239\n",
            "Epoch 52/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9927 - loss: 0.0248\n",
            "Epoch 53/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9923 - loss: 0.0261\n",
            "Epoch 54/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9915 - loss: 0.0264\n",
            "Epoch 55/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9915 - loss: 0.0265\n",
            "Epoch 56/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9915 - loss: 0.0251\n",
            "Epoch 57/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.9876 - loss: 0.0453\n",
            "Epoch 58/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.9904 - loss: 0.0290\n",
            "Epoch 59/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9914 - loss: 0.0292\n",
            "Epoch 60/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9920 - loss: 0.0260\n",
            "Epoch 61/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.9904 - loss: 0.0285\n",
            "Epoch 62/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9891 - loss: 0.0319\n",
            "Epoch 63/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.9919 - loss: 0.0254\n",
            "Epoch 64/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.9924 - loss: 0.0256\n",
            "Epoch 65/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9917 - loss: 0.0279\n",
            "Epoch 66/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9917 - loss: 0.0254\n",
            "Epoch 67/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9912 - loss: 0.0254\n",
            "Epoch 68/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.9912 - loss: 0.0275\n",
            "Epoch 69/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.9918 - loss: 0.0258\n",
            "Epoch 70/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9919 - loss: 0.0247\n",
            "Epoch 71/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.9902 - loss: 0.0270\n",
            "Epoch 72/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.9923 - loss: 0.0257\n",
            "Epoch 73/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9923 - loss: 0.0245\n",
            "Epoch 74/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9921 - loss: 0.0261\n",
            "Epoch 75/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9909 - loss: 0.0266\n",
            "Epoch 76/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9879 - loss: 0.0312\n",
            "Epoch 77/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9918 - loss: 0.0265\n",
            "Epoch 78/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9903 - loss: 0.0316\n",
            "Epoch 79/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9897 - loss: 0.0278\n",
            "Epoch 80/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.9921 - loss: 0.0249\n",
            "Epoch 81/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9921 - loss: 0.0237\n",
            "Epoch 82/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9921 - loss: 0.0239\n",
            "Epoch 83/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9913 - loss: 0.0246\n",
            "Epoch 84/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9910 - loss: 0.0259\n",
            "Epoch 85/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9920 - loss: 0.0246\n",
            "Epoch 86/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9914 - loss: 0.0257\n",
            "Epoch 87/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9923 - loss: 0.0254\n",
            "Epoch 88/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9926 - loss: 0.0244\n",
            "Epoch 89/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9911 - loss: 0.0261\n",
            "Epoch 90/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9893 - loss: 0.0285\n",
            "Epoch 91/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9851 - loss: 0.0404\n",
            "Epoch 92/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9916 - loss: 0.0267\n",
            "Epoch 93/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9922 - loss: 0.0244\n",
            "Epoch 94/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9919 - loss: 0.0250\n",
            "Epoch 95/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.9918 - loss: 0.0246\n",
            "Epoch 96/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9906 - loss: 0.0279\n",
            "Epoch 97/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9892 - loss: 0.0288\n",
            "Epoch 98/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9916 - loss: 0.0252\n",
            "Epoch 99/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9919 - loss: 0.0242\n",
            "Epoch 100/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.9919 - loss: 0.0239\n",
            "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "[0.99999994 0.        ]\n",
            "[9.9999994e-01 1.3157815e-12]\n",
            "19\n",
            "315\n",
            "train acc:  0.8608695652173913\n",
            "test acc:  0.425531914893617\n",
            "Experiment 12 in progress\n",
            "Epoch 1/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9909 - loss: 0.0260\n",
            "Epoch 2/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9915 - loss: 0.0261\n",
            "Epoch 3/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9903 - loss: 0.0300\n",
            "Epoch 4/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9921 - loss: 0.0235\n",
            "Epoch 5/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9916 - loss: 0.0231\n",
            "Epoch 6/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.9909 - loss: 0.0255\n",
            "Epoch 7/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.9916 - loss: 0.0237\n",
            "Epoch 8/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9910 - loss: 0.0253\n",
            "Epoch 9/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9923 - loss: 0.0241\n",
            "Epoch 10/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9906 - loss: 0.0262\n",
            "Epoch 11/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9918 - loss: 0.0257\n",
            "Epoch 12/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9910 - loss: 0.0256\n",
            "Epoch 13/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9909 - loss: 0.0280\n",
            "Epoch 14/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9899 - loss: 0.0342\n",
            "Epoch 15/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9871 - loss: 0.0417\n",
            "Epoch 16/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9905 - loss: 0.0267\n",
            "Epoch 17/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9913 - loss: 0.0241\n",
            "Epoch 18/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9922 - loss: 0.0236\n",
            "Epoch 19/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.9890 - loss: 0.0408\n",
            "Epoch 20/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9911 - loss: 0.0265\n",
            "Epoch 21/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9909 - loss: 0.0243\n",
            "Epoch 22/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9910 - loss: 0.0258\n",
            "Epoch 23/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9920 - loss: 0.0238\n",
            "Epoch 24/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9887 - loss: 0.0364\n",
            "Epoch 25/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9913 - loss: 0.0255\n",
            "Epoch 26/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9921 - loss: 0.0240\n",
            "Epoch 27/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9908 - loss: 0.0251\n",
            "Epoch 28/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9917 - loss: 0.0251\n",
            "Epoch 29/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9915 - loss: 0.0259\n",
            "Epoch 30/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9914 - loss: 0.0251\n",
            "Epoch 31/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9919 - loss: 0.0242\n",
            "Epoch 32/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.9890 - loss: 0.0341\n",
            "Epoch 33/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9923 - loss: 0.0251\n",
            "Epoch 34/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9908 - loss: 0.0258\n",
            "Epoch 35/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9918 - loss: 0.0244\n",
            "Epoch 36/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9923 - loss: 0.0236\n",
            "Epoch 37/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9901 - loss: 0.0339\n",
            "Epoch 38/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9901 - loss: 0.0344\n",
            "Epoch 39/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9889 - loss: 0.0323\n",
            "Epoch 40/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9910 - loss: 0.0264\n",
            "Epoch 41/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9890 - loss: 0.0298\n",
            "Epoch 42/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9918 - loss: 0.0243\n",
            "Epoch 43/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9913 - loss: 0.0244\n",
            "Epoch 44/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9924 - loss: 0.0250\n",
            "Epoch 45/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9915 - loss: 0.0244\n",
            "Epoch 46/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.9909 - loss: 0.0273\n",
            "Epoch 47/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.9914 - loss: 0.0257\n",
            "Epoch 48/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9900 - loss: 0.0262\n",
            "Epoch 49/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9904 - loss: 0.0281\n",
            "Epoch 50/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9909 - loss: 0.0260\n",
            "Epoch 51/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9913 - loss: 0.0266\n",
            "Epoch 52/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.9917 - loss: 0.0262\n",
            "Epoch 53/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9909 - loss: 0.0263\n",
            "Epoch 54/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9914 - loss: 0.0255\n",
            "Epoch 55/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9923 - loss: 0.0256\n",
            "Epoch 56/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9918 - loss: 0.0265\n",
            "Epoch 57/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9909 - loss: 0.0252\n",
            "Epoch 58/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9912 - loss: 0.0278\n",
            "Epoch 59/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9919 - loss: 0.0264\n",
            "Epoch 60/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9920 - loss: 0.0249\n",
            "Epoch 61/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9922 - loss: 0.0267\n",
            "Epoch 62/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9891 - loss: 0.0288\n",
            "Epoch 63/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9913 - loss: 0.0263\n",
            "Epoch 64/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9916 - loss: 0.0236\n",
            "Epoch 65/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.9909 - loss: 0.0252\n",
            "Epoch 66/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9915 - loss: 0.0270\n",
            "Epoch 67/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.9920 - loss: 0.0260\n",
            "Epoch 68/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9920 - loss: 0.0244\n",
            "Epoch 69/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9916 - loss: 0.0250\n",
            "Epoch 70/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.9911 - loss: 0.0242\n",
            "Epoch 71/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9922 - loss: 0.0246\n",
            "Epoch 72/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9922 - loss: 0.0255\n",
            "Epoch 73/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9915 - loss: 0.0272\n",
            "Epoch 74/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9912 - loss: 0.0278\n",
            "Epoch 75/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9929 - loss: 0.0236\n",
            "Epoch 76/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9929 - loss: 0.0238\n",
            "Epoch 77/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9910 - loss: 0.0255\n",
            "Epoch 78/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9909 - loss: 0.0250\n",
            "Epoch 79/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9913 - loss: 0.0312\n",
            "Epoch 80/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.9882 - loss: 0.0298\n",
            "Epoch 81/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9926 - loss: 0.0256\n",
            "Epoch 82/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9909 - loss: 0.0256\n",
            "Epoch 83/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9918 - loss: 0.0248\n",
            "Epoch 84/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.9925 - loss: 0.0242\n",
            "Epoch 85/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9924 - loss: 0.0251\n",
            "Epoch 86/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9920 - loss: 0.0250\n",
            "Epoch 87/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9931 - loss: 0.0239\n",
            "Epoch 88/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9916 - loss: 0.0244\n",
            "Epoch 89/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9904 - loss: 0.0271\n",
            "Epoch 90/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9903 - loss: 0.0286\n",
            "Epoch 91/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.9917 - loss: 0.0252\n",
            "Epoch 92/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9928 - loss: 0.0244\n",
            "Epoch 93/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9894 - loss: 0.0360\n",
            "Epoch 94/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9922 - loss: 0.0254\n",
            "Epoch 95/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9921 - loss: 0.0255\n",
            "Epoch 96/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9921 - loss: 0.0257\n",
            "Epoch 97/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9923 - loss: 0.0247\n",
            "Epoch 98/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9887 - loss: 0.0313\n",
            "Epoch 99/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.9920 - loss: 0.0259\n",
            "Epoch 100/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9925 - loss: 0.0236\n",
            "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "[0.99999994 0.        ]\n",
            "[9.9999994e-01 2.1199312e-17]\n",
            "24\n",
            "330\n",
            "train acc:  0.8964539007092198\n",
            "test acc:  0.38461538461538464\n",
            "Experiment 13 in progress\n",
            "Epoch 1/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9919 - loss: 0.0236\n",
            "Epoch 2/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9926 - loss: 0.0225\n",
            "Epoch 3/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9921 - loss: 0.0236\n",
            "Epoch 4/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9910 - loss: 0.0270\n",
            "Epoch 5/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9913 - loss: 0.0242\n",
            "Epoch 6/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9916 - loss: 0.0252\n",
            "Epoch 7/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9913 - loss: 0.0245\n",
            "Epoch 8/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9909 - loss: 0.0262\n",
            "Epoch 9/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9923 - loss: 0.0245\n",
            "Epoch 10/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.9913 - loss: 0.0276\n",
            "Epoch 11/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9918 - loss: 0.0260\n",
            "Epoch 12/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9926 - loss: 0.0250\n",
            "Epoch 13/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9910 - loss: 0.0250\n",
            "Epoch 14/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9905 - loss: 0.0252\n",
            "Epoch 15/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9845 - loss: 0.0445\n",
            "Epoch 16/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9904 - loss: 0.0277\n",
            "Epoch 17/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9916 - loss: 0.0242\n",
            "Epoch 18/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9914 - loss: 0.0231\n",
            "Epoch 19/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9921 - loss: 0.0243\n",
            "Epoch 20/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9921 - loss: 0.0246\n",
            "Epoch 21/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9902 - loss: 0.0257\n",
            "Epoch 22/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9910 - loss: 0.0253\n",
            "Epoch 23/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.9925 - loss: 0.0234\n",
            "Epoch 24/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9900 - loss: 0.0310\n",
            "Epoch 25/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9908 - loss: 0.0267\n",
            "Epoch 26/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9919 - loss: 0.0237\n",
            "Epoch 27/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9918 - loss: 0.0240\n",
            "Epoch 28/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9906 - loss: 0.0251\n",
            "Epoch 29/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9925 - loss: 0.0226\n",
            "Epoch 30/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9918 - loss: 0.0225\n",
            "Epoch 31/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9923 - loss: 0.0242\n",
            "Epoch 32/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9923 - loss: 0.0232\n",
            "Epoch 33/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9911 - loss: 0.0251\n",
            "Epoch 34/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9907 - loss: 0.0244\n",
            "Epoch 35/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9915 - loss: 0.0253\n",
            "Epoch 36/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9881 - loss: 0.0318\n",
            "Epoch 37/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9915 - loss: 0.0244\n",
            "Epoch 38/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9910 - loss: 0.0252\n",
            "Epoch 39/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9927 - loss: 0.0240\n",
            "Epoch 40/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9923 - loss: 0.0235\n",
            "Epoch 41/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9889 - loss: 0.0298\n",
            "Epoch 42/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9905 - loss: 0.0265\n",
            "Epoch 43/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9916 - loss: 0.0234\n",
            "Epoch 44/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.9915 - loss: 0.0246\n",
            "Epoch 45/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9924 - loss: 0.0247\n",
            "Epoch 46/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9911 - loss: 0.0263\n",
            "Epoch 47/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9914 - loss: 0.0227\n",
            "Epoch 48/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9912 - loss: 0.0250\n",
            "Epoch 49/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9929 - loss: 0.0245\n",
            "Epoch 50/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.9896 - loss: 0.0262\n",
            "Epoch 51/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.9931 - loss: 0.0246\n",
            "Epoch 52/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9930 - loss: 0.0244\n",
            "Epoch 53/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9914 - loss: 0.0284\n",
            "Epoch 54/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9912 - loss: 0.0237\n",
            "Epoch 55/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9927 - loss: 0.0231\n",
            "Epoch 56/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9908 - loss: 0.0261\n",
            "Epoch 57/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9919 - loss: 0.0263\n",
            "Epoch 58/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9924 - loss: 0.0217\n",
            "Epoch 59/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9918 - loss: 0.0233\n",
            "Epoch 60/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9901 - loss: 0.0268\n",
            "Epoch 61/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9927 - loss: 0.0240\n",
            "Epoch 62/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9908 - loss: 0.0257\n",
            "Epoch 63/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.9908 - loss: 0.0255\n",
            "Epoch 64/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9908 - loss: 0.0296\n",
            "Epoch 65/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9895 - loss: 0.0323\n",
            "Epoch 66/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9925 - loss: 0.0242\n",
            "Epoch 67/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9916 - loss: 0.0243\n",
            "Epoch 68/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9917 - loss: 0.0230\n",
            "Epoch 69/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9916 - loss: 0.0232\n",
            "Epoch 70/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9913 - loss: 0.0239\n",
            "Epoch 71/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9908 - loss: 0.0242\n",
            "Epoch 72/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9901 - loss: 0.0233\n",
            "Epoch 73/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9914 - loss: 0.0251\n",
            "Epoch 74/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9918 - loss: 0.0240\n",
            "Epoch 75/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9923 - loss: 0.0235\n",
            "Epoch 76/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9918 - loss: 0.0253\n",
            "Epoch 77/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9907 - loss: 0.0271\n",
            "Epoch 78/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9917 - loss: 0.0250\n",
            "Epoch 79/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9904 - loss: 0.0253\n",
            "Epoch 80/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9919 - loss: 0.0250\n",
            "Epoch 81/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9918 - loss: 0.0232\n",
            "Epoch 82/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9914 - loss: 0.0234\n",
            "Epoch 83/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9897 - loss: 0.0291\n",
            "Epoch 84/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9913 - loss: 0.0243\n",
            "Epoch 85/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9914 - loss: 0.0251\n",
            "Epoch 86/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9930 - loss: 0.0245\n",
            "Epoch 87/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.9918 - loss: 0.0242\n",
            "Epoch 88/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9912 - loss: 0.0248\n",
            "Epoch 89/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9914 - loss: 0.0268\n",
            "Epoch 90/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9917 - loss: 0.0245\n",
            "Epoch 91/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9917 - loss: 0.0249\n",
            "Epoch 92/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9924 - loss: 0.0227\n",
            "Epoch 93/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.9917 - loss: 0.0233\n",
            "Epoch 94/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9913 - loss: 0.0239\n",
            "Epoch 95/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9926 - loss: 0.0248\n",
            "Epoch 96/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9923 - loss: 0.0229\n",
            "Epoch 97/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9911 - loss: 0.0255\n",
            "Epoch 98/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9910 - loss: 0.0243\n",
            "Epoch 99/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9912 - loss: 0.0268\n",
            "Epoch 100/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9910 - loss: 0.0261\n",
            "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "[0.99999994 0.        ]\n",
            "[9.9999994e-01 1.2296225e-22]\n",
            "21\n",
            "347\n",
            "train acc:  0.8836565096952909\n",
            "test acc:  0.32653061224489793\n",
            "Experiment 14 in progress\n",
            "Epoch 1/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9915 - loss: 0.0254\n",
            "Epoch 2/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.9925 - loss: 0.0236\n",
            "Epoch 3/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9923 - loss: 0.0256\n",
            "Epoch 4/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9917 - loss: 0.0256\n",
            "Epoch 5/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9921 - loss: 0.0236\n",
            "Epoch 6/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9927 - loss: 0.0229\n",
            "Epoch 7/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9919 - loss: 0.0236\n",
            "Epoch 8/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9918 - loss: 0.0250\n",
            "Epoch 9/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.9913 - loss: 0.0300\n",
            "Epoch 10/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9886 - loss: 0.0383\n",
            "Epoch 11/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9857 - loss: 0.0397\n",
            "Epoch 12/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9928 - loss: 0.0238\n",
            "Epoch 13/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9920 - loss: 0.0237\n",
            "Epoch 14/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9931 - loss: 0.0225\n",
            "Epoch 15/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9923 - loss: 0.0233\n",
            "Epoch 16/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9923 - loss: 0.0231\n",
            "Epoch 17/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9923 - loss: 0.0229\n",
            "Epoch 18/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9918 - loss: 0.0230\n",
            "Epoch 19/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9921 - loss: 0.0233\n",
            "Epoch 20/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9907 - loss: 0.0240\n",
            "Epoch 21/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9913 - loss: 0.0241\n",
            "Epoch 22/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9916 - loss: 0.0241\n",
            "Epoch 23/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9907 - loss: 0.0242\n",
            "Epoch 24/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9907 - loss: 0.0247\n",
            "Epoch 25/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9919 - loss: 0.0232\n",
            "Epoch 26/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.9919 - loss: 0.0248\n",
            "Epoch 27/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9914 - loss: 0.0248\n",
            "Epoch 28/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9917 - loss: 0.0232\n",
            "Epoch 29/100\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9886 - loss: 0.0301\n",
            "Epoch 30/100\n",
            "\u001b[1m590/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9923 - loss: 0.0214"
          ]
        }
      ],
      "source": [
        "# Loop over different values of n_steps_out (in this case, only 1)\n",
        "for j in range(1):\n",
        "    # Initialize dictionaries to store results for the ensemble model\n",
        "    predictions_train_per_step = dict()\n",
        "    actual_train_per_step = dict()\n",
        "    predictions_test_per_step = dict()\n",
        "    actual_test_per_step = dict()\n",
        "    metrics_train_per_step = dict()\n",
        "    metrics_test_per_step = dict()\n",
        "    test_acc_per_step = dict()\n",
        "    test_stddev_per_step = dict()\n",
        "    n_steps_out = j + 1\n",
        "\n",
        "    print('---------------------------------------------------------')\n",
        "    print('Number of steps out:', n_steps_out)\n",
        "\n",
        "    # Reshape data based on the ensemble model type\n",
        "    x_train, y_train = np.asarray(x_shuffled), np.asarray(Y_hot_encoded_train)\n",
        "    x_test, y_test = np.asarray(test_X), np.asarray(Y_hot_encoded_test)\n",
        "\n",
        "    x_train_lat, y_train_lat = np.asarray(x_shuffled_lat), np.asarray(Y_hot_encoded_train_lat)\n",
        "    x_test_lat, y_test_lat = np.asarray(test_X_lat), np.asarray(Y_hot_encoded_test_lat)\n",
        "\n",
        "    x_train_lon, y_train_lon = np.asarray(x_shuffled_lon), np.asarray(Y_hot_encoded_train_lon)\n",
        "    x_test_lon, y_test_lon = np.asarray(test_X_lon), np.asarray(Y_hot_encoded_test_lon)\n",
        "\n",
        "    # Call ensemble_lstm to create the ensemble model\n",
        "\n",
        "    stacked_model = stacked_lstm(n_steps_in, n_features_in)\n",
        "    # Call the lstm function with the ensemble model and retrieve results\n",
        "    train_acc, test_acc, train_std_dev, test_std_dev, Best_Predict_Test, y_predicttrain, y_predicttest, report_train, report_test = lstm(stacked_model,  x_train_lat, x_train_lon, x_train, y_train, x_test_lat, x_test_lon, x_test, y_test, No_exp, n_steps_in, n_steps_out, epochs)\n",
        "\n",
        "    # Store results in respective dictionaries\n",
        "    predictions_train_per_step['ensemble'] = Best_Predict_Test\n",
        "    actual_train_per_step['ensemble'] = y_train\n",
        "    predictions_test_per_step['ensemble'] = Best_Predict_Test\n",
        "    actual_test_per_step['ensemble'] = y_test\n",
        "    metrics_train_per_step['ensemble'] = report_train\n",
        "    metrics_test_per_step['ensemble'] = report_test\n",
        "    test_acc_per_step['ensemble'] = test_acc\n",
        "    test_stddev_per_step['ensemble'] = test_std_dev\n",
        "\n",
        "    # Store results for the current n_steps_out in the overall dictionaries\n",
        "    predictions_train[str(j + 1)] = predictions_train_per_step\n",
        "    actual_train[str(j + 1)] = actual_train_per_step\n",
        "    predictions_test[str(j + 1)] = predictions_test_per_step\n",
        "    actual_test[str(j + 1)] = actual_test_per_step\n",
        "    metrics_train[str(j + 1)] = metrics_train_per_step\n",
        "    metrics_test[str(j + 1)] = metrics_test_per_step\n",
        "    test_acc_all[str(j + 1)] = test_acc_per_step\n",
        "    test_stddev[str(j + 1)] = test_stddev_per_step\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "YZLtzuIj7pDj",
        "outputId": "f8e12783-ab29-43b8-8a8a-d21fc8f79f81"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'ocean' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-77b9a717c827>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predictions_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mocean\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_original'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictions_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactual_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactual_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_stddev\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ocean' is not defined"
          ]
        }
      ],
      "source": [
        "with open(\"predictions_\" + ocean + '_original' + '.pkl', 'wb') as f:\n",
        "    pickle.dump([predictions_train,actual_train,predictions_test,actual_test,metrics_train,metrics_test,test_acc,test_stddev], f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqRNVNvu7tbR"
      },
      "outputs": [],
      "source": [
        "def make_confusion_matrix_chart(cf_matrix, name):\n",
        "    \"\"\"\n",
        "    Create and save a well-formatted confusion matrix heatmap.\n",
        "\n",
        "    Parameters:\n",
        "    - cf_matrix: Confusion matrix\n",
        "    - name: Name of the file to save the plot\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "\n",
        "    # Set a Seaborn style with dark grid\n",
        "    sns.set(style=\"darkgrid\", font_scale=1.5)\n",
        "\n",
        "    # Create a figure and axis\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "    # Customize the appearance of the heatmap with green colors\n",
        "    sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Greens',\n",
        "                linewidths=.5, square=True, cbar=False,\n",
        "                annot_kws={\"size\": 16}, ax=ax)\n",
        "\n",
        "    # Set labels and title\n",
        "    plt.ylabel(\"Actual\", size=18)\n",
        "    plt.xlabel(\"Predicted\", size=18)\n",
        "    plt.title(\"Confusion Matrix\", size=20)\n",
        "\n",
        "    # Set tick parameters\n",
        "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
        "\n",
        "    # Save the plot as an image\n",
        "    plt.savefig(name + '.png', dpi=300, transparent=False, bbox_inches='tight')\n",
        "\n",
        "    # Display the plot\n",
        "    plt.show()\n",
        "\n",
        "    # Return None\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "id": "0UYHHqzl7wXy",
        "outputId": "484cb9db-c04a-4d88-cbc2-8a5a4de39cfc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y = [i.argmax() for i in actual_test_per_step['ensemble']]\n",
        "pred = [i.argmax() for i in predictions_test_per_step['ensemble']]\n",
        "cf_matrix_test = confusion_matrix(y, pred)\n",
        "make_confusion_matrix_chart(cf_matrix_test, ocean + '_ensemble_cm_original')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htlPVBJB7yn0"
      },
      "outputs": [],
      "source": [
        "# Initialize lists to store precision, recall, and F1-score metrics for class 0, class 1, overall accuracy,\n",
        "# macro average, and weighted average across multiple experiments\n",
        "precision0 = []\n",
        "precision1 = []\n",
        "precisionacc = []\n",
        "precisionmacavg = []\n",
        "precisionweighavg = []\n",
        "recall0 = []\n",
        "recall1 = []\n",
        "recallacc = []\n",
        "recallmacavg = []\n",
        "recallweighavg = []\n",
        "f10 = []\n",
        "f11 = []\n",
        "f1acc = []\n",
        "f1macavg = []\n",
        "f1weighavg = []\n",
        "\n",
        "# Loop through the results of multiple experiments\n",
        "for i in range(No_exp):\n",
        "    # Append precision, recall, and F1-score metrics for class 0, class 1, overall accuracy,\n",
        "    # macro average, and weighted average from the 'vanilla' model results\n",
        "    precision0.append(metrics_test_per_step['ensemble'][i]['0']['precision'])\n",
        "    precision1.append(metrics_test_per_step['ensemble'][i]['1']['precision'])\n",
        "    precisionacc.append(metrics_test_per_step['ensemble'][i]['accuracy'])\n",
        "    precisionmacavg.append(metrics_test_per_step['ensemble'][i]['macro avg']['precision'])\n",
        "    precisionweighavg.append(metrics_test_per_step['ensemble'][i]['weighted avg']['precision'])\n",
        "\n",
        "    recall0.append(metrics_test_per_step['ensemble'][i]['0']['recall'])\n",
        "    recall1.append(metrics_test_per_step['ensemble'][i]['1']['recall'])\n",
        "    recallacc.append(metrics_test_per_step['ensemble'][i]['accuracy'])\n",
        "    recallmacavg.append(metrics_test_per_step['ensemble'][i]['macro avg']['recall'])\n",
        "    recallweighavg.append(metrics_test_per_step['ensemble'][i]['weighted avg']['recall'])\n",
        "\n",
        "    f10.append(metrics_test_per_step['ensemble'][i]['0']['f1-score'])\n",
        "    f11.append(metrics_test_per_step['ensemble'][i]['1']['f1-score'])\n",
        "    f1acc.append(metrics_test_per_step['ensemble'][i]['accuracy'])\n",
        "    f1macavg.append(metrics_test_per_step['ensemble'][i]['macro avg']['f1-score'])\n",
        "    f1weighavg.append(metrics_test_per_step['ensemble'][i]['weighted avg']['f1-score'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCMxk6Mj71M7",
        "outputId": "f46b7879-be50-4443-fef6-d7b874f45df7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9885±0.0011  & 0.9914±0.0028  & 0.99±0.0009\n",
            "0.5074±0.0644  & 0.4196±0.0598  & 0.4519±0.0275\n",
            "0.9803±0.0017  & 0.9803±0.0017  & 0.9803±0.0017\n",
            "0.7479±0.0318  & 0.7055±0.0287  & 0.7209±0.0137\n",
            "0.9791±0.0008  & 0.9803±0.0017  & 0.9795±0.0009\n"
          ]
        }
      ],
      "source": [
        "print(str(round(np.mean(precision0),4)) + \"±\" + str(round(np.std(precision0),4)),\" & \" + str(round(np.mean(recall0),4)) + \"±\" + str(round(np.std(recall0),4)), \" & \" + str(round(np.mean(f10),4)) + \"±\" + str(round(np.std(f10),4)))\n",
        "print(str(round(np.mean(precision1),4)) + \"±\" + str(round(np.std(precision1),4)),\" & \" + str(round(np.mean(recall1),4)) + \"±\" + str(round(np.std(recall1),4)), \" & \" + str(round(np.mean(f11),4)) + \"±\" + str(round(np.std(f11),4)))\n",
        "print(str(round(np.mean(precisionacc),4)) + \"±\" + str(round(np.std(precisionacc),4)),\" & \" + str(round(np.mean(recallacc),4)) + \"±\" + str(round(np.std(recallacc),4)), \" & \" + str(round(np.mean(f1acc),4)) + \"±\" + str(round(np.std(f1acc),4)))\n",
        "print(str(round(np.mean(precisionmacavg),4)) + \"±\" + str(round(np.std(precisionmacavg),4)),\" & \" + str(round(np.mean(recallmacavg),4)) + \"±\" + str(round(np.std(recallmacavg),4)), \" & \" + str(round(np.mean(f1macavg),4)) + \"±\" + str(round(np.std(f1macavg),4)))\n",
        "print(str(round(np.mean(precisionweighavg),4)) + \"±\" + str(round(np.std(precisionweighavg),4)),\" & \" + str(round(np.mean(recallweighavg),4)) + \"±\" + str(round(np.std(recallweighavg),4)), \" & \" + str(round(np.mean(f1weighavg),4)) + \"±\" + str(round(np.std(f1weighavg),4)))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}